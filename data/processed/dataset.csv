Identifier,APA Citation,Title,Orientation,Primary Pattern(s) / Pathway(s),Domain Categories,Pipeline Stage,Pipeline Sub-stage,Historical Era,Triange coverage (AI + data production + community impacts),Rationale,Source type,How source was found,Keywords,Geographic region of focus,"Author affiliations (majority grouping if multiple, full details in note on positionality)",Geographic area of author (lead author if multiple),"Institution / Country
(lead author)",Authorship & positionality context,Summary,Additional Notes
"Abazajian, 2021","Mozilla Insights, & Abazajian, K. (2021). (rep.). What Helps? Understanding Needs and the Ecosystem for Support. Mozilla. Retrieved from https://foundation.mozilla.org/en/data-futures-lab/data-for-empowerment/what-helps-the-ecosystem-for-needs-and-support/",What Helps? | Understanding Needs and the Ecosystem for Support,Principles less-extractive,Participatory data ownership & governance,Data practices,Problem Understanding & Formulation,Institutional Prioritization & Funding,Era 2,ADC,A: examines experiments in data-governance models; D: analyzes participatory ownership and user control mechanisms; C: stresses community agency and collective benefit via support orgs,"Grey (Reports, blogs, white papers, policy documents, theses, conference papers)",Iterative keyword search,"alternative data governance, user control, Mozilla, supporting entities, collective benefit",Not regionally specific,NGO/Non-profit,North America,"Mozilla Foundation, Houston, Texas
USA",,"Maps organizations enabling alternative data governance (co-ops, trusts, intermediaries). Identifies needs around communication, funding, and safe experimentation. Argues governance should prioritize user control and collective benefit, guiding technologists toward less-extractive data ecosystems aligned with community interests.",
"Abbass et al., 2022","Abbass, H. A., Petraki, E., & Hunjet, R. (2022). JSwarm: A Jingulu-Inspired Human-AI-Teaming Language for Context-Aware Swarm Guidance. Frontiers in Physics, 10. https://doi.org/10.3389/fphy.2022.944064 
",JSwarm: A Jingulu-Inspired Human-AI-Teaming Language for Context-Aware Swarm Guidance,Principles less-extractive,Decentering Western ontologies,Data practices,ML System Design & Development,Model Architecture Selection & Design,Era 3,ADC,A: develops a new communication language for human–AI teaming; D: designs language structure informed by computational and linguistic principles; C: draws on Jingulu to decenter Western epistemologies and situate AI design in Indigenous knowledge.,"White (published journal papers, conference proceedings, books)",Citation/reference snowballing,Australia; Jingulu; swarm guidance; communication,Oceania,Academic,Oceania,"School of Engineering and IT, University of New South Wales, Canberra, NSW, Australia","Faculty of Education, University of Canberra, Canberra, Australia; Defence Science and Technology Group, Canberra, Australia","Proposes JSwarm, a human–AI teaming language inspired by Jingulu, an Australian Aboriginal language. Specifies criteria for bi-directional communication in swarm systems and explores design grounded in Indigenous knowledge. Positions linguistic diversity as an alternative to Western-centric system design for AI teaming.",
"Abdul-Mageed et al., 2021","Abdul-Mageed, M., Elmadany, A., & Nagoudi, E. M. B. (2021). ARBERT & MARBERT: Deep Bidirectional Transformers for Arabic. In C. Zong, F. Xia, W. Li, & R. Navigli (Eds.), Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers) (pp. 7088–7105). Association for Computational Linguistics. https://doi.org/10.18653/v1/2021.acl-long.551 
",ARBERT & MARBERT: Deep Bidirectional Transformers for Arabic,Practices less-extractive,Creating culturally inclusive datasets,"Data practices, Community impacts and relations",ML System Design & Development,Model Architecture Selection & Design,Era 3,ADC,A: develops new Arabic transformer models; D: constructs ARLUE benchmark from diverse datasets; C: expands linguistic resources and access for Arabic-speaking communities,"White (published journal papers, conference proceedings, books)","Existing networks, relevant organizations and conferences","MENA, Arabic NLP, transformers, benchmark",MENA,Academic,North America,"University of British Columbia, Canada","Natural Language Processing Lab, University of British Columbia, Canada; Muhammad Abdul-Mageed†; AbdelRahim Elmadany†; El Moatez Billah Nagoudi† [Equal contributions]","Introduces ARBERT and MARBERT, two deep transformers for Arabic and dialects. Builds ARLUE benchmark covering 42 datasets to evaluate performance. Achieves state-of-the-art results and fills major inclusivity gap in NLP for Arabic speakers. Demonstrates how model and benchmark development expand linguistic access and representation.",
"Abebe et al., 2021","Abebe, R., Aruleba, K., Birhane, A., Kingsley, S., Obaido, G., Remy, S. L., & Sadagopan, S. (2021). Narratives and Counternarratives on Data Sharing in Africa. Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency, 329–341. https://doi.org/10.1145/3442188.3445897",Narratives and Counternarratives on Data Sharing in Africa,Extractive,Soliciting data without reciprocal benefits,"Community impacts and relations, Critical theory/Historical background",Problem Understanding & Formulation,Product Conception & Design,Era 3,ADC,A: discusses implications of data sharing for ML and data science systems; D: analyzes practices of data access and governance in Africa; C: centers African perspectives on inequities and trust in data ecosystems,"White (published journal papers, conference proceedings, books)",Database search,"Africa, data sharing, counternarratives, colonial legacies, trust",Africa,Academic,North America,"University of California, Berkeley, USA","University of California, Berkeley, USA; University of the Witwatersrand, South Africa; University College Dublin & Lero, Ireland; Carnegie Mellon University, USA; IBM Research – Africa, Kenya; Deloitte, USA","Uses expert interviews and personas to show how deficit narratives justify extractive data sharing. Provides counternarratives highlighting expertise, mistrust rooted in colonial legacies, and lack of benefit-sharing. Points to equitable governance pathways that respect local control and redistribute value.",
"Abena AI, n.d.","Abena AI. (n.d.). Abena AI - African Language TTS, ASR & Translation. Retrieved September 7, 2025, from https://abena.mobobi.com/","Abena AI - African Language TTS, ASR & Translation",Practices less-extractive,"Creating culturally inclusive datasets, Community engaged data production, Crowdsourcing data collection",Community impacts and relations,ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,ADC,A: provides African language speech and translation systems; D: uses crowdsourcing and community-engaged data collection; C: addresses access and inclusion for African language speakers,"Grey (Reports, blogs, white papers, policy documents, theses, conference papers)","Existing networks, relevant organizations and conferences","African languages, TTS, ASR, translation, community data production",Africa,Mixed,Africa,"Abena AI, Ghana",,"Describes a suite of privacy-first, offline-capable speech and translation tools for African languages. Emphasizes crowdsourced and community-engaged data pipelines to expand linguistic coverage beyond dominant languages. Positions local data production and governance as prerequisites for inclusive speech technologies that reduce dependence on external, unrepresentative corpora.",
"Abraham et al., 2020","Abraham, B., Goel, D., Siddarth, D., Bali, K., Chopra, M., Choudhury, M., Joshi, P., Jyoti, P., Sitaram, S., & Seshadri, V. (2020). Crowdsourcing Speech Data for Low-Resource Languages from Low-Income Workers. In N. Calzolari, F. Béchet, P. Blache, K. Choukri, C. Cieri, T. Declerck, S. Goggi, H. Isahara, B. Maegaard, J. Mariani, H. Mazo, A. Moreno, J. Odijk, & S. Piperidis (Eds.), Proceedings of the Twelfth Language Resources and Evaluation Conference (pp. 2819–2826). European Language Resources Association. https://aclanthology.org/2020.lrec-1.343/",Crowdsourcing Speech Data for Low-Resource Languages from Low-Income Workers,Practices less-extractive,Crowdsourcing data collection,"Data practices, Community impacts and relations",ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,ADC,A: expands speech resources for low-resource languages; D: tests crowdsourcing quality vs. student labor; C: engages low-income rural and urban workers,"White (published journal papers, conference proceedings, books)",Database search,"India, speech data, crowdsourcing",APAC (Asia-Pacific Region),Industry,APAC (Asia-Pacific Region),"Microsoft India Development Center, India","Microsoft Research India; IIT Bombay, India","Collects a 109-hour Marathi corpus from workers and students, showing comparable quality and feasibility of paid crowd speech collection. Demonstrates that recruiting underrepresented speakers broadens linguistic coverage and provides supplemental earnings. Links inclusive data sourcing to more representative models and practical pathways for scaling low-resource speech technologies in India.",
"Ada Lovelace Institute, 2021",Ada Lovelace Institute. (2021). Participatory data stewardship: A framework for involving people in the use of data. https://www.adalovelaceinstitute.org/report/participatory-data-stewardship/,Participatory data stewardship: A framework for involving people in the use of data,Principles less-extractive,Participatory data ownership & governance,Ethics frameworks,Problem Understanding & Formulation,Institutional Prioritization & Funding,Multi-era,ADC,A: proposes stewardship approaches applicable to AI data use; D: outlines participatory governance mechanisms and accountability; C: centers beneficiaries and impacted groups in decision-making,"Grey (Reports, blogs, white papers, policy documents, theses, conference papers)",Iterative keyword search,data stewardship; governance; transparency,Not regionally specific,NGO/Non-profit,EU/UK,"Independent research institute based in London, UK",,"Advocates for a new approach to data governance called participatory data stewardship, emphasizing that beneficiaries, including data subjects and those indirectly impacted by data use, should be involved in the design, development, and deployment of data governance frameworks to ensure fairness, equity, and societal benefit.",
"Adelani et al., 2021","Adelani, D. I., Abbott, J., Neubig, G., D’souza, D., Kreutzer, J., Lignos, C., Palen-Michel, C., Buzaaba, H., Rijhwani, S., Ruder, S., Mayhew, S., Azime, I. A., Muhammad, S. H., Emezue, C. C., Nakatumba-Nabende, J., Ogayo, P., Anuoluwapo, A., Gitau, C., Mbaye, D., … Osei, S. (2021). MasakhaNER: Named Entity Recognition for African Languages. Transactions of the Association for Computational Linguistics, 9, 1116–1131. https://doi.org/10.1162/tacl_a_00416",MasakhaNER: Named Entity Recognition for African Languages,Practices less-extractive,Creating culturally inclusive datasets,"Data practices, Community impacts and relations",ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,ADC,A: addresses NER gaps in African languages; D: curates datasets and evaluates models; C: mobilizes local annotators and practitioners,"White (published journal papers, conference proceedings, books)","Existing networks, relevant organizations and conferences",Africa; NER; dataset; community annotator,Africa,Mixed,Africa,"Spoken Language Systems Group (LSV), Saarland University, Germany; Masakhane NLP","Retro Rabbit, South Africa; Language Technologies Institute, Carnegie Mellon University, United States; ProQuest, United States; Google Research, Canada; Brandeis University, United States; Graduate School of Systems and Information Engineering, University of Tsukuba, Japan; DeepMind, United Kingdom; Duolingo, United States; African Institute for Mathematical Sciences (AIMS-AMMI), Ethiopia; University of Porto, Nigeria; Bayero University, Kano, Nigeria; Technical University of Munich, Germany; Makerere University, Kampala, Uganda; African Leadership University, Rwanda; University of Lagos, Nigeria; Max Planck Institute for Informatics, Germany; LT Group, Universität Hamburg, Germany; University of Chinese Academy of Science, China; Lancaster University, United Kingdom; University of Electronic Science and Technology of China, China; United States International University - Africa (USIU-A), Kenya; Niger-Volta LTI; Luleo University of Technology, Sweden; African University of Science and Technology, Abuja, Nigeria; University of Ibadan, Nigeria; Namibia University of Science and Technology, Namibia; Instadeep, Nigeria; Jacobs University Bremen, Germany; University of Waterloo, Canada","Builds the first large, publicly available NER dataset for ten African languages. Mobilizes local corpora and annotators, and evaluates supervised and transfer learning models. Releases data, code, and models to catalyze research. Demonstrates community-driven dataset creation that addresses representation gaps while documenting persistent technical and resourcing challenges.",
"Adley et al., 2024","Adley, M., Alderson, H., Jackson, K., McGovern, W., Spencer, L., Addison, M., & O’Donnell, A. (2024). Ethical and practical considerations for including marginalised groups in quantitative survey research. International Journal of Social Research Methodology, 27(5), 559–574. https://doi.org/10.1080/13645579.2023.2228600  ",Ethical and practical considerations for including marginalised groups in quantitative survey research,Extractive,Ethics dumping in less-regulated contexts,"Data practices, Community impacts and relations",ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,DC,A: none; D: examines ethical data collection practices with vulnerable populations; C: addresses power dynamics and inclusion challenges for marginalized groups in research,"White (published journal papers, conference proceedings, books)",Citation/reference snowballing,"survey research, marginalized groups, data collection ethics",EU/UK,Academic,EU/UK,"Population Health Sciences Institute, Faculty of Medical Science Newcastle University, Newcastle Upon Tyne, UK",,"Analyzes ethical and practical challenges of data collection with marginalized populations through focus group with researchers conducting surveys with substance users. Identifies themes around researcher positionality, study design, and ethics in practice. Advocates for participatory research design methods, meaningful involvement of target populations in study design, and responsive approaches by funders and ethics boards to integrate marginalized groups.",
"Agnew et al., 2024","Agnew, W., Bergman, A. S., Chien, J., Díaz, M., El-Sayed, S., Pittman, J., Mohamed, S., & McKee, K. R. (2024). The Illusion of Artificial Inclusion. Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems, 1–12. https://doi.org/10.1145/3613904.3642703 
",The Illusion of Artificial Inclusion,Extractive,Reproducing biases through synthetic data generation,"Data practices, Community impacts and relations",ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,AC,"A: analyzes proposals to replace human participants with AI surrogates; D: none; C: examines impacts on representation, inclusion, and understanding in research contexts","White (published journal papers, conference proceedings, books)",Database search,"synthetic data, human participation, representation",Not regionally specific,Mixed,North America,"Human-Computer Interaction Institute, Carnegie Mellon University, USA","Google DeepMind, United Kingdom; University of California, San Diego, USA; Google Research, USA; Stanford University, USA","Human participants play a central role in the development of modern artificial intelligence (AI) technology, in psychological science, and in user research. Recent advances in generative AI have attracted growing interest to the possibility of replacing human participants in these domains with AI surrogates. We survey several such “substitution proposals” to better understand the arguments for and against substituting human participants with modern generative AI. Our scoping review indicates that the recent wave of these proposals is motivated by goals such as reducing the costs of research and development work and increasing the diversity of collected data. However, these proposals ignore and ultimately conflict with foundational values of work with human participants: representation, inclusion, and understanding. This paper critically examines the principles and goals underlying human participation to help chart out paths for future work that truly centers and empowers participants.",
"Ajmani et al., 2024","Ajmani, L., Stapleton, L., Houtti, M., & Chancellor, S. (2024). Data Agency Theory: A Precise Theory of Justice for AI Applications. The 2024 ACM Conference on Fairness, Accountability, and Transparency, 631–641. https://doi.org/10.1145/3630106.3658930",Data Agency Theory: A Precise Theory of Justice for AI Applications,Principles less-extractive,Participatory data ownership & governance,Ethics frameworks,Problem Understanding & Formulation,Product Conception & Design,Era 3,ADC,A: theorizes consent justice for AI applications; D: evaluates consent procedures and policy design; C: emphasizes group-level harms and data agency for affected communities,"White (published journal papers, conference proceedings, books)",Hand-searching key journals,"Data agency, AI justice, consent policies, data labor, societal groups",Not regionally specific,Academic,North America,"University of Minnesota, USA",,"Introduces Data Agency Theory (DAT) as a framework to assess the fairness of consent procedures in AI applications, arguing that data agency is crucial for justice in AI. The study applies DAT to real-world examples and suggests improvements for consent policies in AI development.",
"Akera et al., 2022","Akera, B., Mukiibi, J., Naggayi, L. S., Babirye, C., Owomugisha, I., Nsumba, S., Nakatumba-Nabende, J., Bainomugisha, E., Mwebaze, E., & Quinn, J. (2022). Machine Translation for African Languages: Community Creation of Datasets and Models in Uganda. AfricaNLP Workshop at ICLR2022. https://openreview.net/pdf?id=BK-z5qzEU-9 
",Machine Translation for African Languages: Community Creation of Datasets and Models in Uganda,Practices less-extractive,Community engaged data production,Community impacts and relations,ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,ADC,A: trains/evaluates MT models for 5 Ugandan langs; D: locally created parallel corpora & release; C: argues practical translation utility for local language communities,"Grey (Reports, blogs, white papers, policy documents, theses, conference papers)","Existing networks, relevant organizations and conferences","Africa, machine translation, model quality, low resource languages, text corpora",Africa,Mixed,Africa,"Sunbird AI; Makerere University AI Lab, Uganda",,"Details community-created parallel corpora and transformer models for five Ugandan languages. Describes corpus construction, training, and evaluation, with public releases to support broader use. Demonstrates feasibility of building practical MT resources outside high-resource settings and links local data governance to improved inclusion and access for Ugandan language communities.",
"Anuyah et al., 2024","Anuyah, O., Wan, R., Adejoro, C., Yeh, T., Metoyer, R., & Badillo-Urquiola, K. (2024). Cultural Considerations in AI Systems for the Global South: A Systematic Review. Proceedings of the 4th African Human Computer Interaction Conference, 125–134. https://doi.org/10.1145/3628096.3629046",Cultural Considerations in AI Systems for the Global South: A Systematic Review,Principles less-extractive,Creating culturally inclusive datasets,"Data practices, Community impacts and relations",ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,ADC,"A: addresses AI design for Global South systems; D: emphasizes integration of cultural values and culturally inclusive datasets; C: highlights visibility, representation, and usefulness of AI for African communities","White (published journal papers, conference proceedings, books)",Database search,"Africa, AI design, cultural values, healthcare, inclusion",Africa,Academic,North America,"University of Notre Dame, USA","University of Colorado, USA","Systematic review of twelve studies on AI for Global South contexts. Focuses on healthcare and assistants, highlighting challenges in usability, transparency, and data availability. Recommends integrating cultural values and locally relevant datasets to increase acceptance and utility. Links culturally inclusive data practices to improved representation and community trust for African users of AI systems.",
"Apple, 2021","Apple. (2021, April). A Day in the Life of Your Data. Retrieved August 14, 2024, from https://www.apple.com/au/privacy/docs/A_Day_in_the_Life_of_Your_Data.pdf",A Day in the Life of Your Data,Extractive,Keeping communities in the dark through opaque data practices,Data practices,Cross-pipeline,Cross-pipeline,Multi-era,DC,A: none; D: illustrates pervasive data tracking and monetization practices; C: affects individuals and families through privacy erosion,"Grey (Reports, blogs, white papers, policy documents, theses, conference papers)","Existing networks, relevant organizations and conferences","data tracking, privacy, monetization",Not regionally specific,Industry,North America,"Silicon Valley, USA",,"Discusses how technology companies collect and monetize personal data, illustrating this through a narrative of a father and daughter's day at the park. It highlights Apple's privacy initiatives like Intelligent Tracking Prevention and App Tracking Transparency as solutions to the pervasiveness of data tracking.",
"Arnstein, 1969","Arnstein, S. R. (1969). A Ladder Of Citizen Participation. Journal of the American Institute of Planners. https://doi.org/10.1080/01944366908977225",A Ladder Of Citizen Participation,Principles less-extractive,Early co-design and participatory initiatives,Critical theory/Historical background,Cross-pipeline,Cross-pipeline,Multi-era,C,A: none; D: none; C: centers redistribution of power to communities through typology of citizen participation.,"White (published journal papers, conference proceedings, books)","Existing networks, relevant organizations and conferences",participation; governance; citizen power,Not regionally specific,Mixed,North America,"US government / urban planning circles, USA",,"Argues that citizen participation requires a redistribution of power from traditional power holders to disenfranchised citizens, illustrating this through a typology of eight levels of participation. The ultimate goal is to empower citizens to advocate for their needs and hold institutions accountable.",
"Arora et al., 2023","Arora, A., Barrett, M., Lee, E., Oborn, E., & Prince, K. (2023). Risk and the future of AI: Algorithmic bias, data colonialism, and marginalization. Information and Organization, 33(3), 100478. https://doi.org/10.1016/j.infoandorg.2023.100478","Risk and the future of AI: Algorithmic bias, data colonialism, and marginalization",Extractive,Exploitative and invisible data labor,Critical theory/Historical background,Problem Understanding & Formulation,Institutional Prioritization & Funding,Era 3,ADC,A: discusses algorithmic bias & AI in orgs/health; D: Kenya labeling case foregrounds data labor; C: marginalization & social risk,"White (published journal papers, conference proceedings, books)",Database search,"Data colonialism, Kenya, data labeling, marginalized communities",Africa,Academic,EU/UK,"School of Clinical Medicine, Cambridge University, United Kingdom","Judge Business School, Cambridge University, United Kingdom; CDI, Cambridge University, United Kingdom; Warwick Business School, University of Warwick, United Kingdom","Examines how AI can exacerbate existing inequalities, particularly through algorithmic bias in healthcare, and explores the issue of data colonialism using the example of data labeling in Kenya. The authors propose a relational risk perspective to address both the harms and benefits of AI.",
"Asiedu et al., 2024","Asiedu, M., Dieng, A., Haykel, I., Rostamzadeh, N., Pfohl, S., Nagpal, C., Nagawa, M., Oppong, A., Koyejo, S., & Heller, K. (2024). The Case for Globalizing Fairness: A Mixed Methods Study on Colonialism, AI, and Health in Africa (No. arXiv:2403.03357). arXiv. https://doi.org/10.48550/arXiv.2403.03357","The Case for Globalizing Fairness: A Mixed Methods Study on Colonialism, AI, and Health in Africa",Practices less-extractive,Early co-design and participatory initiatives,Community impacts and relations,ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,ADC,A: fairness for AI in health settings; D: discusses data collection/annotation & contextualization; C: health equity for African populations,"Grey (Reports, blogs, white papers, policy documents, theses, conference papers)","Existing networks, relevant organizations and conferences",Africa; health AI; fairness framework; colonialism,Africa,Mixed,Multiple areas,"Google Research, USA",Google DeepMind; Duke University; Ghana NLP,"Mixed-methods study arguing fairness frameworks must be adapted to African health contexts shaped by colonial legacies. Identifies gaps in datasets, labeling, and deployment conditions. Recommends practices that center local institutions and communities in defining objectives, curating data, and assessing harms to advance equitable AI in public health across the continent.",
"Atari et al., 2023","Atari, M., Xue, M. J., Park, P. S., Blasi, D. E., & Henrich, J. (2023, September 22). Which Humans?. https://doi.org/10.31234/osf.io/5b26t",Which Humans?,Extractive,"""Deploying AI systems that lack local, contextual data""","Community impacts and relations, Data practices",ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,ADC,A: shows LLM “human-likeness” maps to WEIRD populations; D: traces WEIRD-skew to English/Internet-heavy training data and debiasing norms; C: flags global harms when deployed across diverse societies,"Grey (Reports, blogs, white papers, policy documents, theses, conference papers)",Database search,global; LLM; WEIRD bias; cultural psychology,Multiple areas,Academic,North America,"Department of Human Evolutionary Biology, Harvard University, USA",,"Analyzing LLM outputs against cross-cultural surveys and cognitive tasks, the paper shows models cluster with WEIRD populations and diverge as cultural distance from the U.S. increases (e.g., r = −0.70), indicating an outlier “WEIRD psychology.” It links this skew to English-dominant, Internet-scraped training data and WEIRD-centered safety norms, warning that global deployment risks misalignment with non-WEIRD cultures. The authors call for diversifying training data and feedback sources to mitigate “WEIRD in, WEIRD out.”",
"Ayana et al., 2024","Ayana, G., Dese, K., Daba Nemomssa, H., Habtamu, B., Mellado, B., Badu, K., Yamba, E., Faye, S. L., Ondua, M., Nsagha, D., Nkweteyim, D., & Kong, J. D. (2024). Decolonizing global AI governance: Assessment of the state of decolonized AI governance in Sub-Saharan Africa. Royal Society Open Science, 11(8), 231994. https://doi.org/10.1098/rsos.231994 
 ",Decolonizing global AI governance: assessment of the state of decolonized AI governance in Sub-Saharan Africa,Extractive,Excluding underrepresented groups from decision-making,"Community impacts and relations, Critical theory/Historical background",Problem Understanding & Formulation,Institutional Prioritization & Funding,Era 3,ADC,A: national AI governance & policy for AI systems; D: explicit indicators include data protection & local data use requirements; C: SSA equity/sovereignty & impacts of governance choices on populations,"White (published journal papers, conference proceedings, books)",Citation/reference snowballing,"AI governance, decolonization, Africa, bias in AI, data protection regulations",Africa,Academic,Africa,"Jimma University, Jimma, Ethiopia",,"Mixed-methods assessment of AI governance across SSA. Finds limited progress on decolonized governance: few countries have comprehensive AI policies, institutions to steward local data, or strategies to mitigate bias. Emphasizes data protection, local data use, and accountability as indicators. Argues that governance choices shape sovereignty and equity, steering data practices toward or away from extractive defaults.",
"Baack, 2024","Baack, S. (2024). A Critical Analysis of the Largest Source for Generative AI Training Data: Common Crawl. The 2024 ACM Conference on Fairness, Accountability, and Transparency, 2199–2208. https://doi.org/10.1145/3630106.3659033",A Critical Analysis of the Largest Source for Generative AI Training Data: Common Crawl,Extractive,Collecting vast amounts of data to train AI systems,Data practices,Deployment & Impact,Product Testing,Era 3,ADC,A: examines LLM training data source; D: analyzes Common Crawl curation/coverage/bias; C: discusses downstream harms and proposes governance,"White (published journal papers, conference proceedings, books)",Hand-searching key journals,"Common Crawl, web crawl, training data, generative AI",Not regionally specific,Industry,EU/UK,"Mozilla Foundation, Germany",,"Examines the impact of Common Crawl, a massive web data archive, on the development of large language models (LLMs) and highlights concerns about bias and harmful content in AI systems. The paper proposes recommendations to improve ethical and responsible AI development.",
"Baker and Karasti, 2018","Baker, K. S., & Karasti, H. (2018). Data care and its politics: Designing for local collective data management as a neglected thing. Proceedings of the 15th Participatory Design Conference: Full Papers - Volume 1, 1–12. https://doi.org/10.1145/3210586.3210587",Data care and its politics: Designing for local collective data management as a neglected thing.,Principles less-extractive,Participatory data ownership & governance,Data practices,Problem Understanding & Formulation,Institutional Prioritization & Funding,Era 2,ADC,A: connects data care to infrastructures leveraged by AI; D: foregrounds local collective management and partnering designers; C: supports community capacity and stewardship,"White (published journal papers, conference proceedings, books)",Database search,EU/UK; data care; local stewardship; ecological research,EU/UK,Academic,EU/UK,"University of Illinois at Urbana–Champaign, USA","University of Oulu, Finland","Explores the concept of “data care” in the context of local, collective data management, using case studies from ecological research communities. The authors argue that with the push for large-scale data sharing, the crucial aspects of data work at the local level are often overlooked. They emphasize the importance of understanding and supporting the practices and challenges faced by researchers in managing and sharing data within their communities. The source introduces the role of a “partnering designer” who collaborates with local data practitioners (“data allies”) to address these challenges. Through case studies, it illustrates how partnering designers can help communities develop data management plans, create data stewardship workshops, and document their practices for broader use and learning.
",
"Bali et al., 2019","Bali, K., Choudhury, M., Sitaram, S., & Seshadri, V. (2019, December 1). ELLORA: Enabling Low Resource Languages with Technology. UNESCO International Conference on Language Technologies for all (LT4All). https://www.microsoft.com/en-us/research/publication/ellora-enabling-low-resource-languages-with-technology/",ELLORA: Enabling Low Resource Languages with Technology,Practices less-extractive,Creating culturally inclusive datasets,"Community impacts and relations, Data practices",Problem Understanding & Formulation,Product Conception & Design,Era 3,ADC,A: identifies underserved languages globally; D: develops methods for constrained-resource contexts; C: aims to empower communities via technology access,"White (published journal papers, conference proceedings, books)","Existing networks, relevant organizations and conferences","global, low-resource languages, technology",Multiple areas,Industry,Multiple areas,"Microsoft Research Labs,
Bangalore, India",,"Presents MSR’s initiative to extend language tech to 5,000+ low-resource languages. Outlines methodological approaches under data constraints and positions language equity as infrastructural work. Frames early agenda-setting for empowering communities via access and tailored workflows.",
"Barocas & Nissenbaum, 2014","Barocas, S., & Nissenbaum, H. (2014). Big Data’s End Run around Anonymity and Consent. In J. Lane, B. Stodden S. ,. &. Nissenbaum, H. (2014). Big Data’s End Run around Anonymity and Consent. In J. Lane, V. Stodden, S. Bender, &. H. Nissenbaum (Eds.), Privacy, Big Data, and the Public Good (1st ed., pp. 44–75). Cambridge University Press. https://doi.org/10.1017/CBO9781107590205 ",Big data's end run around anonymity and consent,Extractive,"Collecting vast amounts of data to train AI systems, Soliciting data without reciprocal benefits",Critical theory/Historical background,ML System Design & Development,"Data Selection, Collection & Annotation",Era 2,DC,A: none; D: shows anonymity/consent fail under big-data inference and recombination; C: calls for substantive safeguards beyond procedural consent,"White (published journal papers, conference proceedings, books)",Citation/reference snowballing,global; big data; anonymity; consent; privacy,Not regionally specific,Academic,North America,"Princeton University, New York University, USA","Research support from Intel Science and Technology Center for Social Computing, DHHS Strategic Healthcare Information Technology Advanced Research Projects on Security (SHARPS), NSF Cyber-Trust Collaborative Research (CNS-0831124), and Lady Davis Trust, The Hebrew University of Jerusalem","Argues that the conventional tools used to address privacy concerns—namely, anonymity and informed consent—are inadequate in the face of big data. The authors contend that while achieving true anonymity is often impossible, even when achieved, it fails to address the core ethical dilemmas of big data because individuals become identifiable through comprehensive data profiles and inferences drawn from data mining. Similarly, they assert that informed consent, while theoretically sound, becomes meaningless in the context of big data due to the complexity and unpredictable nature of data flows, rendering genuine user understanding and control impossible. Barocas and Nissenbaum advocate for a shift in focus from procedural safeguards to substantive moral and political principles that address the ethical challenges of big data.",
"Battiste, 2005","Battiste, M. (2005). Indigenous Knowledge: Foundations for First Nations. WINHEC: International Journal of Indigenous Education Scholarship, 1, Article 1. https://journals.uvic.ca/index.php/winhec/article/view/19251",Indigenous Knowledge: Foundations for First Nations,Principles less-extractive,Decentering Western ontologies,"Community impacts and relations, Critical theory/Historical background",Cross-pipeline,Cross-pipeline,Multi-era,C,"A: none; D: none (indirect implications for data stewardship); C: centers Indigenous epistemologies, language, and self-determination","White (published journal papers, conference proceedings, books)",Citation/reference snowballing,North America; Indigenous knowledge; education; sovereignty,North America,Academic,North America,"University of Saskatchewan, Saskatoon, SK Canada",,"Articulates Indigenous knowledge as holistic, dynamic, and systematically marginalized by Eurocentric systems. Calls for curricular and institutional change recognizing language, culture, and sovereignty. Offers a foundation widely drawn upon to reframe technology and data practices toward relational accountability and community control, informing debates over AI data governance impacting First Nations.",
"Bender & Friedman, 2018","Bender, E. M., & Friedman, B. (2018). Data Statements for Natural Language Processing: Toward Mitigating System Bias and Enabling Better Science. Transactions of the Association for Computational Linguistics, 6, 587–604. https://doi.org/10.1162/tacl_a_00041 
",Data Statements for Natural Language Processing: Toward Mitigating System Bias and Enabling Better Science,Principles less-extractive,Building public visibility in dataset development,Data practices,ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,ADC,A: proposes NLP documentation practice; D: specifies structured “data statements” for dataset provenance and context; C: targets reduced exclusion and misrepresentation,"White (published journal papers, conference proceedings, books)",Database search,NLP; data statement; documentation; transparency,Not regionally specific,Academic,North America,"Department of Linguistics, University of Washington, Seattle, USA ","The Information School, University of Washington, USA","Introduces “data statements,” a structured documentation practice for NLP datasets detailing speaker populations, collection context, and processing. Argues this visibility improves scientific claims and mitigates bias when models trained on one group are applied to others. Provides a concrete schema and adoption guidance, linking better documentation to improved generalization and reduced harms in language technologies that affect diverse user communities.",
"Bender et al., 2021","Bender, E. M., Gebru, T., McMillan-Major, A., & Shmitchell, S. (2021). On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? 🦜. Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency, 610–623. https://doi.org/10.1145/3442188.3445922",On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? 🦜,Extractive,"Collecting vast amounts of data to train AI systems, ""Deploying AI systems that lack local, contextual data"", Excluding underrepresented groups from decision-making",Data practices,ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,ADC,"A: critiques LMs and scale; D: interrogates web-scale data, documentation, and evaluation practices; C: details representational harms and environmental costs","White (published journal papers, conference proceedings, books)","Existing networks, relevant organizations and conferences",LLM; training data; environmental cost; representational harm,Not regionally specific,Mixed,North America,"University of Washington, Seattle, WA, USA; Black in AI; independent","3 authors equal contributions; 4th author UW, USA","Bender, Gebru, McMillan-Major, and Shmitchell argue that the increasing size of language models (LMs) in NLP poses significant risks. The authors critique the trend of relying on ever-larger LMs as the primary driver of improved performance, claiming that this approach overlooks important ethical and societal implications. They examine into three main areas of concern: the environmental and financial costs of training large LMs, the inherent biases encoded in massive datasets derived from the internet, and the misconception of LMs as capable of genuine language understanding. The paper emphasizes the dangers of relying on LMs, which are essentially ""stochastic parrots"" that mimic language without true comprehension, and proposes alternative research directions that prioritize careful planning, ethical data curation, and a broader understanding of the limitations and potential harms associated with these models. ",
"Benyera, 2021","Benyera, E. (2021). The Fourth Industrial Revolution and the Recolonisation of Africa: The Coloniality of Data (1st ed.). Routledge. https://doi.org/10.4324/9781003157731 
",The Fourth Industrial Revolution and the Recolonisation of Africa: The Coloniality of Data,Extractive,Ethics dumping in less-regulated contexts,"Community impacts and relations, Critical theory/Historical background",Problem Understanding & Formulation,Institutional Prioritization & Funding,Multi-era,ADC,"A: situates AI within 4IR as a core technological driver of change; D: theorizes “data coloniality” and D4D infrastructures; C: articulates sovereignty, inequity, and social impacts in African contexts","White (published journal papers, conference proceedings, books)","Existing networks, relevant organizations and conferences","Africa, data coloniality, sovereignty, inequality",Africa,Academic,Africa,South Africa,,Argues data practices within 4IR perpetuate coloniality in Africa through extractive infrastructures and “Data for Development” initiatives that centralize control outside the continent. Articulates sovereignty-focused governance and locally grounded development pathways to counter inequities reproduced by global data economies and AI systems.,
"Berditchevskaia et al., 2022","Berditchevskaia, A., Peach, K., & Stewart, I. (2022). Localising AI for crisis response. https://www.nesta.org.uk/report/localising-ai/ ",Localising AI for crisis response,Practices less-extractive,Participatory data ownership & governance,"Data practices, Community impacts and relations",Problem Understanding & Formulation,Product Conception & Design,Multi-era,ADC,"A: discusses implications of AI and crisis-response systems; D: analyzes participatory data production in Nepal and Cameroon; C: centers community needs for privacy, misinformation response, and local governance","Grey (Reports, blogs, white papers, policy documents, theses, conference papers)",Database search,APAC/Africa (Nepal/Cameroon); crisis response; local AI; community codesign,APAC (Asia-Pacific Region),NGO/Non-profit,EU/UK,"Nesta foundation, UK",,"Proposes “collective crisis intelligence” that integrates local knowledge with AI. Two prototypes—NFRI-Predict (Nepal) and Report & Respond (Cameroon)—illustrate participatory design, data minimization, and privacy for sensitive contexts. Argues local development and governance are essential to avoid extractive humanitarian AI.",
"Bergman et al., 2022","Bergman, A. S., Abercrombie, G., Spruit, S., Hovy, D., Dinan, E., Boureau, Y.-L., & Rieser, V. (2022). Guiding the Release of Safer E2E Conversational AI through Value Sensitive Design. In O. Lemon, D. Hakkani-Tur, J. J. Li, A. Ashrafzadeh, D. H. Garcia, M. Alikhani, D. Vandyke, & O. Dušek (Eds.), Proceedings of the 23rd Annual Meeting of the Special Interest Group on Discourse and Dialogue (pp. 39–52). Association for Computational Linguistics. https://doi.org/10.18653/v1/2022.sigdial-1.4",Guiding the Release of Safer E2E Conversational AI through Value Sensitive Design,Principles less-extractive,Early co-design and participatory initiatives,Data practices,Deployment & Impact,Product Launch,Multi-era,ADC,A: frames safer release of conversational AI; D: ties training data and documentation to harm mitigation; C: embeds user reporting and feedback loops,"White (published journal papers, conference proceedings, books)",Database search,global; conversational AI; value sensitive design; model release; harm,Not regionally specific,Mixed,North America,"Meta (Responsible AI), USA","Heriot-Watt University; Independent Ethics Advisor
Populytics, Netherlands; Bocconi University; FAIR, Meta; FAIR, Meta; Heriot-Watt University, UAE
Alana AI","Uses Value Sensitive Design to weigh release timing, harms, and benefits for end-to-end conversational AI. Proposes documentation of known risks, visible user reporting channels, and mechanisms to incorporate feedback post-release. Links unsafe behaviors to large web-scraped training data and emphasizes governance at launch. Positions participatory oversight as part of safer deployment for communities interacting with chat systems.",
"Bhardwaj et al., 2024","Bhardwaj, E., Gujral, H., Wu, S., Zogheib, C., Maharaj, T., & Becker, C. (2024). Machine learning data practices through a data curation lens: An evaluation framework. The 2024 ACM Conference on Fairness, Accountability, and Transparency, 1055–1067. https://doi.org/10.1145/3630106.3658955 ",Machine learning data practices through a data curation lens: An evaluation framework,Practices less-extractive,Biased pre-processing and category erasure,Ethics frameworks,ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,AD,A: proposes evaluation of ML datasets; D: develops a rubric grounded in data curation and FAIR; C: none (indirect implications),"White (published journal papers, conference proceedings, books)",Database search,ML dataset; data curation; FAIR; rubric,Not regionally specific,Academic,North America,"University of Toronto, Canada",,"Argues that the field of machine learning can benefit from adopting practices of data curation to improve the fairness, accountability, and transparency of machine learning models. The authors highlight how data curation principles, which emphasize a holistic lifecycle approach to data management, can address issues such as bias and lack of transparency often associated with machine learning datasets. To bridge the gap between these two fields, the authors developed an evaluation framework in the form of a rubric. This rubric assesses machine learning datasets based on data curation concepts, including ethical considerations, documentation of data practices, and adherence to FAIR principles (findability, accessibility, interoperability, reusability). By applying this rubric to a sample of machine learning datasets, the authors identify common challenges in aligning machine learning data practices with data curation principles, such as discrepancies in the interpretation of shared terminology and difficulties in scoping the depth and breadth of documentation. The authors conclude by suggesting practical pathways to overcome these challenges, emphasizing the importance of continued dialogue and collaboration between the fields of data curation and machine learning.",
"Bhattacharjee, 2024","Bhattacharjee, R. (2024, June 18). Indigenous data stewardship stands against extractivist AI. Faculty of Arts, The University of British Columbia. https://www.arts.ubc.ca/news/indigenous-data-stewardship-stands-against-extractivist-ai/ 
",Indigenous data stewardship stands against extractivist AI,Extractive,Excluding underrepresented groups from decision-making,"Critical theory/Historical background, Community impacts and relations",Problem Understanding & Formulation,Institutional Prioritization & Funding,Era 3,ADC,"A: critiques extractivist AI and calls for stewardship; D: advocates institutional shifts toward Indigenous-led governance; C: details harms (misrepresentation, appropriation) and community protections.","Grey (Reports, blogs, white papers, policy documents, theses, conference papers)",Database search,Indigenous data stewardship; extractivism,Not regionally specific,Academic,North America,"UBC, Canada",,"Op-ed synthesizing Indigenous scholars’ calls to halt extractivist AI practices. Outlines risks—misrepresentation, appropriation, and amplified disparities—and frames stewardship as community-controlled governance of data use. Links institutional commitments and decision-making power to correcting asymmetries shaping AI data production and downstream impacts on Indigenous peoples",
"Bhutani et al., 2024","Bhutani, M., Robinson, K., Prabhakaran, V., Dave, S., & Dev, S. (2024, March 8). SeeGULL Multilingual: A Dataset of Geo-Culturally Situated Stereotypes. arXiv.Org. https://arxiv.org/abs/2403.05696v1",SeeGULL Multilingual: a Dataset of Geo-Culturally Situated Stereotypes,Practices less-extractive,Creating culturally inclusive datasets,"Data practices, Community impacts and relations",ML System Design & Development,Model Training & Evaluation,Era 3,ADC,"A: evaluates LLM stereotyping; D: builds multilingual, culturally situated stereotype dataset; C: targets harms in non-English communities","Grey (Reports, blogs, white papers, policy documents, theses, conference papers)",Database search,multiple areas; multilingual stereotype dataset; evaluation,Multiple areas,Industry,North America,"Google Research, USA",,"Introduces a 20-language, 23-region dataset of culturally situated stereotypes. Method: identity-term selection, LLM-generated candidates, culturally grounded human annotations. Demonstrates cross-model/language differences in stereotype endorsement, enabling more representative safety/fairness evaluation.",
"Bird & Yibarbuk, 2024","Bird, S., & Yibarbuk, D. (2024). Centering the Speech Community. In Y. Graham & M. Purver (Eds.) Proceedings of the 18th Conference of the European Chapter of the Association for Computational Linguistics (Volume 1: Long Papers) (pp. 826–839). Association for Computational Linguistics. https://aclanthology.org/2024.eacl-long.50 ",Centering the Speech Community,Practices less-extractive,"Community engaged data production, Creating culturally inclusive datasets","Community impacts and relations, Data practices",ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,ADC,A: reorients NLP design to speech-community needs; D: proposes machine-in-the-loop pattern prioritizing capacity over extraction; C: advances equitable partnerships with Indigenous communities,"White (published journal papers, conference proceedings, books)","Existing networks, relevant organizations and conferences",Australia; speech technology; community partnership; vernacular,Oceania,Mixed,Oceania,"Charles Darwin University, Australia; Warddeken Land Management, Australia","Steven: I am a settler Australian descended from English and German immigrants, with professional training in computer science and linguistics and experience of working with minoritised language groups in Africa, Amazonia, Melanesia, and Australia. I entered Arnhem Land in the remote north of Australia in 2016 with the aspiration of collecting a million word corpus of transcribed speech in Kunwinjku, and to bring this language up to speed
with all the usual language technologies.
Dean: I am a Gurrgoni man and traditional owner of the Djinkarr estate outside Maningrida. I speak 16 languages, including Kunwinjku, which is the language that Bangardi (Steven) is learning. I helped establish various ranger programs, and we use traditional knowledge in our seasonal burning and in caring for Country. I have worked with many researchers over the years.",Investigates how NLP and AI practitioners can ethically and effectively engage with oral language communities to develop culturally appropriate language technologies. Proposes a “machine-in-the-loop” design pattern that prioritizes human capacity building and knowledge transmission over data extraction.,
"Bird, 2020","Bird, S. (2020). Decolonising Speech and Language Technology. In D. Scott, N. Bel, & C. Zong (Eds.), Proceedings of the 28th International Conference on Computational Linguistics (pp. 3504–3519). International Committee on Computational Linguistics. https://doi.org/10.18653/v1/2020.coling-main.313 ",Decolonising Speech and Language Technology,Principles less-extractive,"Community engaged data production, Early co-design and participatory initiatives, Participatory data ownership & governance","Community impacts and relations, Data practices",Problem Understanding & Formulation,Product Conception & Design,Era 3,ADC,A: critiques SLT paradigms; D: prescribes co-design and community governance of language data; C: centers Indigenous goals for revitalization,"White (published journal papers, conference proceedings, books)",Database search,Oceania; Australia; Indigenous language technology; decolonizing practice,Not regionally specific,Academic,Oceania,"Northern Institute, Charles Darwin University, Australia",,"Argues SLT often reproduces colonial logics through “discovery/saving” narratives. Calls for community-led priorities, participation across all stages, and participatory ownership and governance of language data. Reframes success as empowering Indigenous communities to sustain languages on their own terms, rather than purely technical benchmarks.",
"Bird, 2024","Bird, S. (2024). Must NLP be Extractive?. In Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 14915–14929, Bangkok, Thailand. Association for Computational Linguistics. https://aclanthology.org/2024.acl-long.797/",Must NLP be Extractive?,Principles less-extractive,"Decentering Western ontologies, Early co-design and participatory initiatives","Community impacts and relations, Data practices",Problem Understanding & Formulation,Product Conception & Design,Multi-era,ADC,A: critiques assumptions in NLP system design; D: D: develops Relational NLP as alternative to extractive data production; C: emphasizes oral vernacular languages and community needs,"Grey (Reports, blogs, white papers, policy documents, theses, conference papers)","Existing networks, relevant organizations and conferences","Australia, NLP, oral languages, relational",Oceania,Academic,Oceania,"Northern Institute, Charles Darwin University, Australia",,"Challenges the prevailing notion in NLP that achieving “Language Technology for All” involves incorporating more languages into existing models. The author argues that this approach, while suitable for the world’s 500 institutional languages, fails to adequately address the needs of the remaining 6,500 oral vernacular languages. These languages, often embedded within specific geographical regions and cultural practices, necessitate a different approach that acknowledges their unique characteristics. Drawing on his experiences working with the Kunwinjku community in Arnhem Land, Australia, the author proposes a shift towards “Relational NLP.” This approach prioritizes understanding language as an embodied social practice deeply rooted in a community’s culture and environment. By focusing on augmentative solutions that empower local communities and respect their knowledge systems, Relational NLP offers a more inclusive and ethical path for developing language technology.",
"Birhane et al., 2021","Birhane, A., Prabhu, V. U., & Kahembwe, E. (2021). Multimodal datasets: Misogyny, pornography, and malignant stereotypes (No. arXiv:2110.01963). arXiv. https://doi.org/10.48550/arXiv.2110.01963 
","Multimodal datasets: Misogyny, pornography, and malignant stereotypes",Extractive,Collecting vast amounts of data to train AI systems,"Data practices, Community impacts and relations",ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,ADC,A: critiques web-scale multimodal training; D: analyzes LAION-400M/CC curation and toxic content; C: details downstream harms to targeted groups,"Grey (Reports, blogs, white papers, policy documents, theses, conference papers)","Existing networks, relevant organizations and conferences",LAION-400M; Common Crawl; stereotype; harm,EU/UK,Academic,EU/UK,"University College Dublin & Lero
Dublin, Ireland",,"Audits Common Crawl as a cornerstone of generative AI training data. Identifies coverage gaps, harmful content, and opaque curation that shape model behavior. Recommends improvements and governance levers to reduce downstream harms, linking web-scale collection to community impacts through model outputs.",
"Birhane et al., 2022a","Birhane, A., Ruane, E., Laurent, T. S., Brown, M., Flowers, J., Ventresque, A., & L. Dancy, C. (2022). The Forgotten Margins of AI Ethics. 2022 ACM Conference on Fairness Accountability and Transparency, 948–958. https://doi.org/10.1145/3531146.3533157 ",The Forgotten Margins of AI Ethics,Extractive,Excluding underrepresented groups from decision-making,"Community impacts and relations, Critical theory/Historical background, Ethics frameworks",Cross-pipeline,Cross-pipeline,Era 3,AC,A: critiques AI ethics agendas detached from lived harms; D: none (indirect; calls to re-center affected communities in data work); C: surfaces concrete harms and power asymmetries,"White (published journal papers, conference proceedings, books)",Database search,"AI ethics, marginalized groups, power asymmetries",Not regionally specific,Mixed,EU/UK,"Mozilla Foundation, USA and School of Computer Science, University College Dublin, Ireland","Mozilla Foundation, USA and School of Computer Science, University College Dublin, Ireland; School of Computer Science, University College Dublin, Ireland; School of Computer Science, Bucknell University, USA; Worcester State University, USA;nDept of Industrial and Manufacturing Engineering & Dept of Computer Science and Engineering, Pennsylvania State University, USA",Critiques gap between AI ethics discourse and real-world harms experienced by marginalized communities. Argues mainstream AI ethics fails to address concrete harms and power imbalances. Calls for ethics grounded in lived experiences of those most affected by AI systems rather than abstract principles developed by dominant groups.,
"Birhane et al., 2022b","Birhane, A., Isaac, W., Prabhakaran, V., Diaz, M., Elish, M. C., Gabriel, I., & Mohamed, S. (2022). Power to the People? Opportunities and Challenges for Participatory AI. Equity and Access in Algorithms Mechanisms and Optimization, 1–8. https://doi.org/10.1145/3551624.3555290 ",Power to the People? Opportunities and Challenges for Participatory AI,Principles less-extractive,Early co-design and participatory initiatives,"Community impacts and relations, Ethics frameworks",Problem Understanding & Formulation,Product Conception & Design,Era 3,AC,"A: assesses participatory AI opportunities/risks; D: none (indirect implications); C: warns against cooptation, calls for genuine empowerment","White (published journal papers, conference proceedings, books)",Database search,global; participatory AI; governance; marginalized community,Not regionally specific,Mixed,EU/UK,"Mozilla Foundation, USA; School of Computer Science, University College Dublin, Ireland","DeepMind, United Kingdom; Google, USA","Reviews participatory approaches to AI with attention to power, representation, and risk. Identifies opportunities for inclusion but highlights structural barriers and the danger of symbolic participation. Argues for clear roles, accountability, and community leadership. Connects participation quality to downstream effects on AI data and model choices that shape community impacts.",
"Birhane et al., 2024","Birhane, A., Dehdashtian, S., Prabhu, V., & Boddeti, V. (2024). The Dark Side of Dataset Scaling: Evaluating Racial Classification in Multimodal Models. The 2024 ACM Conference on Fairness Accountability and Transparency, 1229–1244. https://doi.org/10.1145/3630106.3658968 ",The Dark Side of Dataset Scaling: Evaluating Racial Classification in Multimodal Models,Extractive,Biased pre-processing and category erasure,"Data practices, Community impacts and relations",ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,ADC,A: evaluates multimodal models’ racial classification; D: interrogates dataset scaling and labeling; C: surfaces disparate harms to racialized groups,"White (published journal papers, conference proceedings, books)",Hand-searching key journals,"Dataset curation, data scaling, racial bias, multimodal AI models",Not regionally specific,Mixed,EU/UK,"Mozilla & Trinity College Dublin, Ireland","Michigan State University, USA; HAL51 Inc., San Francisco, CA, USA","Investigates how dataset scaling in AI models exacerbates racial biases, particularly the association of certain racial groups with harmful labels, emphasizing the need for transparency and responsible dataset curation.",
"Birhane, 2020","Birhane, A. (2020). Algorithmic Colonization of Africa. SCRIPTed, 17(2), 389–409. https://doi.org/10.2966/scrip.170220.389 ",Algorithmic Colonization of Africa,Extractive,"Prioritizing data wants over community needs, Soliciting data without reciprocal benefits","Community impacts and relations, Critical theory/Historical background",Problem Understanding & Formulation,Institutional Prioritization & Funding,Multi-era,ADC,A: centers “algorithmic” systems as sociotechnical actors shaping power; D: critiques data extraction/appropriation and infrastructural control; C: analyzes harms and structural effects on African communities,"White (published journal papers, conference proceedings, books)",Database search,"Algorithmic colonialism, AI, Africa",Africa,Academic,EU/UK,"School of Computer Science, University College Dublin, Ireland; Lero - The Irish Software Research",,"Discusses how the adoption of Western-developed AI technologies across Africa can be a new form of colonialism, emphasizing the need for AI solutions driven by local communities and ethical considerations.",
"Birhane, 2021","Birhane, A. (2021). Algorithmic injustice: A relational ethics approach. Patterns, 2(2), 100205. https://doi.org/10.1016/j.patter.2021.100205 ",Algorithmic injustice: A relational ethics approach,Principles less-extractive,Decentering Western ontologies,Ethics frameworks,Cross-pipeline,Cross-pipeline,Era 3,AC,A: critiques narrow technical fixes for bias in AI systems; D: none (indirect implications); C: foregrounds relational ethics rooted in lived experience and Afro-feminist perspectives,"White (published journal papers, conference proceedings, books)","Existing networks, relevant organizations and conferences",justice; data science; Afro-feminism; relational epistemology,Not regionally specific,Academic,EU/UK,"School of Computer Science, University College Dublin, Ireland",,"Argues that current solutions for algorithmic bias are often too narrow, focusing on technical fixes rather than examining the broader historical, social, and political contexts. By contrasting the prevailing ""rational"" worldview that prioritizes objective, abstract, and universal principles with a ""relational"" perspective rooted in interdependence, lived experience, and active engagement, the paper calls for a fundamental shift in how we understand and develop AI ethics. Birhane emphasizes prioritizing understanding over prediction, centering the disproportionately impacted, and viewing data science as a practice that actively shapes the social fabric, rather than merely offering neutral, technical solutions.",
"Blackmore et al., 2023","Blackmore, B., Thorp, M., Chen, A. T.-Y., Morreale, F., Burmester, B., Bahmanteymouri, E., & Bartlett, M. (2023). Hidden humans: Exploring perceptions of user-work and training artificial intelligence in Aotearoa New Zealand. Kōtuitui: New Zealand Journal of Social Sciences Online, 18(4), 443–456. https://doi.org/10.1080/1177083X.2023.2212736",Hidden humans: Exploring perceptions of user-work and training artificial intelligence in Aotearoa New Zealand,Extractive,Exploitative and invisible data labor,"Data labor, Community impacts and relations",ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,ADC,A: examines AI platforms’ reliance on user contributions; D: documents hidden labor dynamics in NZ; C: surfaces perceptions of unfairness and exploitation,"White (published journal papers, conference proceedings, books)",Database search,"Aotearoa New Zealand, data labor, user-work, fairness",Oceania,Academic,Oceania,"Department of Philosophy, University of Otago, Dunedin, New Zealand","Faculty of Arts, University of Auckland, Auckland, New Zealand; cKoi Tū: The Centre for Informed Futures, University of Auckland,Auckland, New Zealand; School of Music, University of Auckland, Auckland, New Zealand; Department ofManagement and International Business, University of Auckland, Auckland, New Zealand; School ofArchitecture and Planning, University of Auckland, Auckland, New Zealand; Faculty of Law, University ofAuckland, Auckland, New Zealand","Combines computational analysis with fieldwork, engaging rural women annotators to define bias in context. Finds English-centric methods miss Hindi-specific harms. Recommends inclusive workflows and participatory annotation to align NLP with local norms and needs.",
"Bogiatzis-Gibbons, 2024","Bogiatzis-Gibbons, D. J. (2024). Beyond Individual Accountability: (Re-)Asserting Democratic Control of AI. The 2024 ACM Conference on Fairness, Accountability, and Transparency, 74–84. https://doi.org/10.1145/3630106.3658541",Beyond Individual Accountability: (Re-)Asserting Democratic Control of AI,Principles less-extractive,Participatory data ownership & governance,Community impacts and relations,Deployment & Impact,Product Testing,Era 3,ADC,A: conceptualizes democratic control over AI beyond individual rights; D: reframes governance mechanisms and institutional designs; C: emphasizes collective participation and oversight,"Grey (Reports, blogs, white papers, policy documents, theses, conference papers)",Hand-searching key journals,democratic control; AI governance; social impact,Not regionally specific,Academic,EU/UK,"Birkbeck College, UK",,"Argues that existing AI control mechanisms are insufficient because they fail to address the inherently political nature of AI. The author contends that AI systems are both incidentally and inherently political, shaping and being shaped by social, economic, and political orders. Bogiatzis-Gibbons proposes two forms of democratic control: a weak form that focuses on regulating government use of AI through transparency, rule-bound frameworks, and independent oversight, and a strong form that advocates for democratic control over all facets of AI through participatory institutions like citizens' assemblies. The author concludes by urging data scientists to promote new social imaginaries of AI that emphasize the possibility and importance of democratic control.",
"Bommasani et al., 2023","Bommasani, R., Klyman, K., Longpre, S., Kapoor, S., Maslej, N., Xiong, B., Zhang, D., & Liang, P. (2023). The Foundation Model Transparency Index (No. arXiv:2310.12941). arXiv. https://doi.org/10.48550/arXiv.2310.12941",The Foundation Model Transparency Index,Extractive,Keeping communities in the dark through opaque data practices,Data practices,Problem Understanding & Formulation,Institutional Prioritization & Funding,Era 3,AD,A: evaluates transparency of major foundation model developers; D: assesses disclosure of data sources and labor practices; C: none (indirect implications),"Grey (Reports, blogs, white papers, policy documents, theses, conference papers)",Citation/reference snowballing,"transparency index, foundation models, data sources",Not regionally specific,Academic,North America,"Stanford University, USA","MIT, Princeton, USA","Reviews the transparency of major foundation model developers. The authors establish an index of 100 indicators across three domains -- upstream, model, and downstream -- to assess the transparency of ten major developers and their flagship models. The key finding is a concerning lack of transparency, particularly regarding the upstream resources used to build foundation models, such as data sources and labor practices. Open-source developers score significantly higher on transparency across all domains compared to their closed counterparts. The authors provide recommendations for developers, deployers, and policymakers, strongly urging increased transparency in future foundation model releases, particularly through robust documentation and third-party audits. This call for transparency is situated within a broader movement advocating for ethical and responsible AI development, emphasizing that transparency is crucial for accountability and effective regulation.",
"Bragg et al., 2021","Bragg, D., Caselli, N., Hochgesang, J. A., Huenerfauth, M., Katz-Hernandez, L., Koller, O., Kushalnagar, R., Vogler, C., & Ladner, R. E. (2021). The FATE Landscape of Sign Language AI Datasets: An Interdisciplinary Perspective. ACM Trans. Access. Comput., 14(2), 7:1-7:45. https://doi.org/10.1145/3436996",The FATE Landscape of Sign Language AI Datasets: An Interdisciplinary Perspective,Principles less-extractive,Establishing consent and contextually appropriate compensation,"Data practices, Ethics frameworks, Community impacts and relations",ML System Design & Development,"Data Selection, Collection & Annotation",Multi-era,ADC,"A: situates sign language AI datasets within FATE concerns; D: addresses rights, responsibilities, and dataset governance in data collection and storage; C: centers Deaf community identity, cultural sensitivities, and histories of oppression","White (published journal papers, conference proceedings, books)",Database search,"Global, sign language datasets, dataset governance, Deaf community",Not regionally specific,Mixed,Multiple areas,"Microsoft Research, USA","Boston University, USA; Gallaudet University, USA; Rochester Institute of Technology, USA; Microsoft, USA; Microsoft, Germany; University of Washington, USA","Reviews sign-language AI datasets at a pivotal deployment moment. Articulates obligations around consent, privacy, ownership, and access across contributors, data owners, and users. Emphasizes Deaf community centrality and cultural sensitivities, given the personal nature of signed recordings and histories of oppression. Recommends governance and documentation practices that respect identity and reduce harm, linking dataset decisions to accountable, equitable sign-language technologies.",
"Brewer et al., 2023","Brewer, R. N., Harrington, C., & Heldreth, C. (2023). Envisioning Equitable Speech Technologies for Black Older Adults. 2023 ACM Conference on Fairness, Accountability, and Transparency, 379--388. https://doi.org/10.1145/3593013.3594005",Envisioning Equitable Speech Technologies for Black Older Adults,Extractive,"""Deploying AI systems that lack local, contextual data""","Community impacts and relations, Data practices",Deployment & Impact,Product Testing,Era 3,ADC,A: studies speech AI use among Black older adults; D: interrogates data disclosure and representation design choices; C: centers lived experience and cultural specificity in evaluation,"White (published journal papers, conference proceedings, books)","Existing networks, relevant organizations and conferences",North America; speech technology; Black older adult; authenticity,North America,Academic,North America,"University of Michigan, USA","Carnegie Mellon, USA; Google, USA","Investigates the potential for bias and inequity in speech recognition technologies, particularly as they are used by Black older adults. The authors conducted workshops and interviews with 16 Black older adults to explore their experiences with voice assistants and understand their expectations for fairness, inclusivity, and representation in these technologies. The research reveals that participants were concerned that current voice technologies fail to understand cultural context and often misinterpret Black speech patterns. This, they argue, leads to feelings of exclusion and reinforces structural inequities. The authors propose the concept of ""authenticity"" as a critical component of fairness in AI, suggesting that systems should be designed to represent cultural nuances and diverse voices accurately, without relying on harmful stereotypes. Finally, the paper explores the complex issue of data disclosure and raises questions about whether and how to incorporate cultural and identity data into large language models without perpetuating existing biases.",
"Brown et al., 2024","Brown, P. T., Wilson, D., West, K., Escott, K.-R., Basabas, K., Ritchie, B., Lucas, D., Taia, I., Kusabs, N., & Keegan, T. T. (2024). Māori Algorithmic Sovereignty: Idea, Principles, and Use. Data Science Journal, 23(1). https://doi.org/10.5334/dsj-2024-015","Māori Algorithmic Sovereignty: Idea, Principles, and Use",Principles less-extractive,Participatory data ownership & governance,"Community impacts and relations, Ethics frameworks",Cross-pipeline,Cross-pipeline,Era 3,ADC,"A: discusses implications of algorithmic systems for Māori contexts; D: articulates sovereignty principles for algorithm design and governance; C: emphasizes Māori collective benefit, accountability, and control.","White (published journal papers, conference proceedings, books)",Database search,"Oceania, Māori language, Indigenous data sovereignty; algorithms; cultural preservation",Oceania,Academic,Oceania,"Te Whare Wānanga o Waikato | University of Waikato, Hamilton, NZ",,"Articulates MASov to govern data, models, and algorithm use affecting Māori. Offers value-linked principles and assessment strategies to identify bias and align systems with Māori tikanga. Recasts AI governance toward collective rights, transparency, and Indigenous control across the pipeline.",
"Buolamwini & Gebru, 2018","Buolamwini, J., & Gebru, T. (2018). Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification. Proceedings of the 1st Conference on Fairness, Accountability and Transparency, 77–91. https://proceedings.mlr.press/v81/buolamwini18a.html",Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification,Extractive,"""Deploying AI systems that lack local, contextual data""","Data practices, Community impacts and relations",ML System Design & Development,Model Training & Evaluation,Multi-era,ADC,A: audits commercial facial recognition systems; D: links bias to dataset imbalance; C: foregrounds harms for women of color,"White (published journal papers, conference proceedings, books)",Iterative keyword search,"facial analysis, gender classification, bias",Not regionally specific,Mixed,North America,MIT Media Lab; Microsoft Research,Microsoft Research,"Demonstrates that commercial gender classification systems show large accuracy disparities across race and gender, with darker-skinned women misclassified most. Attributes errors to biased training data. Advocates for inclusive benchmarks, transparency, and accountability in algorithmic reporting. Paper became a landmark in AI bias research.",
"Buolamwini, 2023","Buolamwini, J. (2023). Unmasking AI: My Mission to Protect What Is Human in a World of Machines. Random House Publishing Group.
",Unmasking AI: My Mission to Protect What Is Human in a World of Machines,Extractive,"Keeping communities in the dark through opaque data practices, ""Deploying AI systems that lack local, contextual data""","Data practices, Community impacts and relations",Deployment & Impact,Product Launch,Era 3,ADC,"A: documents facial recognition harms and biased model performance; D: critiques dataset and evaluation practices that encode bias; C: centers racialized and gendered impacts, advocating accountable oversight","White (published journal papers, conference proceedings, books)","Existing networks, relevant organizations and conferences",facial recognition; algorithmic bias; coded gaze,Not regionally specific,NGO/Non-profit,North America,"NPO Algorithmic Justice League, a digital advocacy non-profit organization based in Cambridge, MA, USA","part memoir, part thesis on AI harms resulting from biased AI designs and datasets","Examines bias in facial analysis systems through lived research practice. Details how dataset composition, benchmarking, and deployment choices yield disparate errors for dark-skinned women and other marginalized groups. Argues that technical fixes alone cannot address misuse and power asymmetries. Calls for inclusive development, transparency, and oversight to protect communities affected by surveillance and biometric applications.",
"Cameron et al., 1993","Cameron, D., Frazer, E., Harvey, P., Rampton, B., & Richardson, K. (1993). Ethics, advocacy, and empowerment: Issues of method in researching language. Language & Communication, 13(2), 81–94. https://doi.org/10.1016/0271-5309(93)90001-4","Ethics, advocacy, and empowerment: Issues of method in researching language",Extractive,Scraping or repurposing sensitive data,"Ethics frameworks, Critical theory/Historical background",Problem Understanding & Formulation,Institutional Prioritization & Funding,Multi-era,C,A: none; D: critiques research ethics frameworks in language studies; C: proposes empowerment model emphasizing collaborative knowledge production with communities,"White (published journal papers, conference proceedings, books)","Existing networks, relevant organizations and conferences","Latin America, decoloniality, datafication, social movement",Not regionally specific,Academic,EU/UK,"University of Strathclyde, Scotland, UK",,"Critiques traditional social science research for perpetuating an imbalance of power between the researcher and the researched. The authors argue that the standard ethical framework, focused on minimizing harm to research subjects, and the advocacy framework, where researchers use their expertise to support subjects' interests, are insufficient. They propose an empowerment framework that emphasizes researching with subjects, acknowledging their agendas, and sharing knowledge. This framework challenges the positivist view of research, suggesting that interactive methods and the recognition of multiple, shifting power dynamics lead to more insightful and collaborative research. The authors call for a shift from objectification to collaboration, where knowledge is produced and shared to benefit both researchers and the researched.",
"Carroll et al., 2019","Carroll, S. R., Rodriguez-Lonebear, D., & Martinez, A. (2019). Indigenous Data Governance: Strategies from USA Native Nations. Data Science Journal, 18, 31. https://doi.org/10.5334/dsj-2019-031 
",Indigenous Data Governance: Strategies from USA Native Nations,Principles less-extractive,Participatory data ownership & governance,"Community impacts and relations, Ethics frameworks",Cross-pipeline,Cross-pipeline,Multi-era,DC,"A: none (indirect implications); D: outlines IDS/IDG strategies, policy, and practice; C: centers Native nations’ sovereignty and community control","White (published journal papers, conference proceedings, books)",Database search,"North America, Indigenous data sovereignty, open data, governance",North America,Academic,North America,"Native Nations Institute at the Udall Center for Studies in Public Policy, University of Arizona, USA",,"Synthesizes Indigenous Data Sovereignty and Indigenous Data Governance strategies from U.S. Native nations. Maps legal and organizational mechanisms that position tribes to control data collection, ownership, and application. Provides actionable levers—policy, institutions, and partnerships—to reposition authority over Indigenous data to communities themselves. Offers governance scaffolding relevant across AI data lifecycles where Indigenous peoples are impacted.",
"Carroll et al., 2024","Carroll, S. R., Chung, P., Rowe, R. K., Siri, S., & Walter. (2024). Indigenous Data Sovereignty and the State of Open Data. Data for Development. Retrieved August 27, 2024, from https://www.d4d.net/news/indigenous-data-sovereignty-and-the-state-of-open-data",Indigenous Data Sovereignty and the State of Open Data,Principles less-extractive,Participatory data ownership & governance,"Community impacts and relations, Ethics frameworks",Cross-pipeline,Cross-pipeline,Multi-era,ADC,A: articulates governance principles applicable to AI data ecosystems; D: examines open data ecosystems and governance frameworks; C: advances Indigenous Peoples' rights and interests in data contexts,"Grey (Reports, blogs, white papers, policy documents, theses, conference papers)",Database search,"multiple regions; Indigenous data sovereignty, open data, governance",Multiple areas,Mixed,North America,"University of Arizonia, USA","Stephanie Russo Carroll is Dene/Ahtna, a citizen of the Native Village of Kluti-Kaah in Alaska and of Sicilian-descent, and lives in Chukson on O’odham and Yaqui lands. She is an associate professor at the University of Arizona. Stephanie directs the Collaboratory for Indigenous Data Governance. She is a co-founder of the US Indigenous Data Sovereignty Network and chairs the Global Indigenous Data Alliance.

Pyrou Chung directs the East-West Management Institute’s programs on natural resource, land, and data initiatives in Asia under the Open Development Initiative. Pyrou has extensive experience in the development sector, including in conservation and human rights. Her work with Indigenous Peoples in Asia has helped to articulate the Indigenous Knowledge and Data Sovereign framework that is adapted within an Asian context. This work intersects with the open data movement through the Open Development Mekong platform that focuses upon inclusion of women and Indigenous Peoples within environmental data justice programming. 

Tahu Kukutai belongs to the Māori tribes of Ngāti Tiipa, Ngāti Māhanga, Ngāti Kinohaku, and Te Aupōuri. She is professor of demography at the University of Waikato and a co-director of Ngā Pae o te Māramatanga, which is Aotearoa New Zealand’s only Indigenous Centre of Research Excellence. Tahu is a founding member of the Māori data sovereignty network Te Mana Raraunga and the Global Indigenous Data Alliance. She co-edited 'Indigenous data sovereignty: toward an agenda and Indigenous data sovereignty and policy', and was a co-author of the Māori Data Governance Model.

Robyn K. Rowe is an Anishinaabe-kwe (First Nations woman) of mixed settler ancestry, a member of Matachewan First Nation, and hereditary member of Teme-Augama Anishnabai in Northeastern, Ontario, Canada. She is a mother of four and holds a PhD in Rural and Northern Health. Her research focuses on the intersection of Indigeneity, equity, and justice, and the historical events that led to modern day forms of data extraction. Her work has expanded toward advancing discussions on the trajectory of data uses in the fields of AI and genomics. She is a Postdoctoral Fellow in Indigenous Digital Rights, Decolonization, and Data in AI at Queen’s University-Kingston.

Susanna Ragnhild Andersdatter Siri (Fimbenáillu-ántte ja Gárenniillas-Máhteristena Susánna) is from Guovdageaidnu and is a northern Sámi researcher who works at the Centre for Sámi Health Research at UiT The Arctic University in Norway. Her research has focused on risk factors and the incidence of cardiovascular diseases in Sámi and non-Sámi populations. She is engaged in the SAMINOR Study, a population-based study on health and living conditions in regions with Sámi and Norwegian populations. She also works to develop best practice in Sámi governance of research data.

Maggie Walter is a Palawa woman and a Distinguished Professor Emerita of Sociology at the University of Tasmania, Australia. Maggie is an executive member of the Maiam nayri Wingara Indigenous Data Sovereignty Collective in Australia and a member of the Global Indigenous Data Alliance.",Analyzes Indigenous Data Sovereignty movement's advancement of Indigenous rights within open data ecosystems. Documents varied global experiences during COVID-19 pandemic revealing tensions and issues. Presents CARE Principles for Indigenous Data Governance as guidance framework for engaging with Indigenous Peoples' data.,
"Césaire, 2000","Césaire, A. (2000). Discourse on Colonialism. Monthly Review Press.",Discourse on Colonialism,Principles less-extractive,Decentering Western ontologies,Critical theory/Historical background,Cross-pipeline,Cross-pipeline,Multi-era,C,A: none; D: none (indirect implications for extraction logics); C: theorizes colonial domination and its moral-structural harms,"White (published journal papers, conference proceedings, books)","Existing networks, relevant organizations and conferences",EU/UK; colonial critique; dehumanization,Multiple areas,Journalist/Other/Not Sure,EU/UK,Originally published mid-20th century by a Black Francophone poet-politician,,"Classic critique of colonialism’s violences and justificatory myths. Positions extraction and domination as “decivilizing” forces. Provides a conceptual lens frequently mobilized to interrogate modern knowledge infrastructures and extractive relations, offering language to analyze how large-scale data capture and classification can reproduce colonial hierarchies and harms.",Césaire et al. - 2000 - Discourse on colonialism.pdf
"Chandhiramowuli et al., 2024","Chandhiramowuli, S., Taylor, A. S., Heitlinger, S., & Wang, D. (2024). Making Data Work Count. Proc. ACM Hum.-Comput. Interact., 8(CSCW1), 90:1-90:26. https://doi.org/10.1145/3637367",Making Data Work Count,Extractive,Exploitative and invisible data labor,Data labor,ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,ADC,A: situates annotation within AI supply chains; D: documents counting logics structuring data work; C: shows worker valuation and justice impacts in outsourcing center,"White (published journal papers, conference proceedings, books)",Database search,"India, data annotation, counting regimes, labor valuation",Multiple areas,Mixed,EU/UK,"University of Edinburgh, Edinburgh, United Kingdom","University of Edinburgh, Edinburgh, United Kingdom; City, University of London, London, United Kingdom; Google Research, Atlanta, GA, USA","Ethnography of two Indian outsourcing centers shows how pervasive counting logics (tasks, time, quality) standardize annotation and assert requester authority. These “regimes of counting” devalue discretion, homogenize work, and shape justice outcomes. Authors propose seeing counting as partial and situated to redesign metrics and governance that recognize workers and enable more accountable AI supply chains.",
"Chen et al., 2024 ","
Chen, H., Raj, B., Xie, X., & Wang, J. (2024). On Catastrophic Inheritance of Large Foundation Models (No. arXiv:2402.01909). arXiv. https://doi.org/10.48550/arXiv.2402.01909",On Catastrophic Inheritance of Large Foundation Models,Principles less-extractive,Building public visibility in dataset development,Data practices,ML System Design & Development,Model Training & Evaluation,Era 3,AD,A: theorizes LFM risks; D: analyzes inherited biases from pretraining data and proposes UIM (Understand–Interpret–Mitigate); C: none (indirect implications),"Grey (Reports, blogs, white papers, policy documents, theses, conference papers)",Citation/reference snowballing,foundation model; catastrophic inheritance; pretraining data; UIM,Not regionally specific,Mixed,North America,"Carnegie Mellon University, USA",,"Defines “catastrophic inheritance,” where LFMs inherit dataset biases and pathologies that propagate to downstream tasks, causing fairness, security, and privacy risks. Proposes UIM—Understand, Interpret, Mitigate—to diagnose and address inherited defects through interdisciplinary analysis. Frames visibility into pretraining data characteristics as central to safer downstream deployment.",
"Chung, 2019","Chung, A. W. (2019, January 24). How Automated Tools Discriminate Against Black Language – MIT Center for Civic Media. https://civic.mit.edu/index.html%3Fp=2402.html",How Automated Tools Discriminate Against Black Language,Extractive,"""Deploying AI systems that lack local, contextual data""","Community impacts and relations, Data practices",ML System Design & Development,"Data Selection, Collection & Annotation",Multi-era,ADC,A: critiques automated moderation tools; D: shows biased training datasets (Wikipedia); C: foregrounds harms to AAVE speakers,"Grey (Reports, blogs, white papers, policy documents, theses, conference papers)",Database search,"AAVE, marginalized communities, language training data",North America,Government,North America,"Massachusettes Bay Transportation Authority, USA",,"Critiques bias in automated moderation tools like Perspective API, showing AAVE phrases are disproportionately misclassified as toxic. Traces the problem to Anglo-centric training data and exclusion of Black linguistic practices. Argues that such mislabeling reinforces systemic devaluation of AAVE and calls for more inclusive training corpora.",
"Coffey, 2021","Coffey, D. (2021, April 28). Māori are trying to save their language from Big Tech. Wired. Retrieved August 13, 2024, from https://www.wired.com/story/maori-language-tech/",Māori are trying to save their language from Big Tech,Extractive,Soliciting data without reciprocal benefits,"Community impacts and relations, Data practices",ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,ADC,A: discusses implications of corporate data use for AI language tools; D: documents Te Hiku’s practices of safeguarding and licensing data; C: emphasizes Māori self-determination and cultural preservation.,"Grey (Reports, blogs, white papers, policy documents, theses, conference papers)","Existing networks, relevant organizations and conferences",Oceania; Māori language technology; sovereignty; cultural preservation,Oceania,Journalist/Other/Not Sure,North America,"Narrative Storyteller, USA",,"Describes Te Hiku Media’s efforts to develop Māori language tech while resisting extractive deals. Highlights consent, licensing, and community control to keep benefits local. Links sovereignty-respecting data production to durable language revitalization and more appropriate AI tools",
"Coleman, 2019","Coleman, D. (2019). Digital Colonialism: The 21st Century Scramble for Africa through the Extraction and Control of User Data and the Limitations of Data Protection Laws. Michigan Journal of Race and Law, 24(2), 417–439. https://doi.org/10.36643/mjrl.24.2.digital",Digital Colonialism: The 21st Century Scramble for Africa through the Extraction and Control of User Data and the Limitations of Data Protection Laws,Extractive,Other/NA (conceptual framing),"Community impacts and relations, Critical theory/Historical background",Problem Understanding & Formulation,Institutional Prioritization & Funding,Era 3,DC,A: none; D: analyzes legal regimes and governance gaps that enable extractive user data practices in Africa; C: frames harms to African communities as digital colonialism continuing historical exploitation,"White (published journal papers, conference proceedings, books)",Database search,"Africa, digital colonialism, user data, legal framework",Africa,Academic,North America,"University of Michigan, USA",,"Argues that Western technology companies are enacting a new form of colonialism in Africa by extracting user data, comparing this to the historical exploitation during the Scramble for Africa.",
"Combahee River Collective, 1977",Combahee River Collective. (1977). The Combahee River Collective Statement. Retrieved from https://www.blackpast.org/african-american-history/combahee-river-collective-statement-1977/,The Combahee River Collective Statement,Principles less-extractive,Decentering Western ontologies,"Community impacts and relations, Critical theory/Historical background",Cross-pipeline,Cross-pipeline,Multi-era,C,A: none; D: none (indirect implications for extraction logics); C: theorizes colonial domination and its moral-structural harms,"Grey (Reports, blogs, white papers, policy documents, theses, conference papers)","Existing networks, relevant organizations and conferences",North America; Black feminism; intersectionality; collective action,Not regionally specific,Journalist/Other/Not Sure,North America,"Boston-based Black feminist collective, USA",,"Foundational Black feminist statement centering interlocking oppressions (race, gender, class, sexuality) and collective praxis. Informs contemporary approaches to community-centered technology and data practices by foregrounding intersectionality, accountability, and self-determination—principles now invoked in efforts to reimagine AI data work with and for marginalized communities.",
"Cooper & Zafiroglu, 2024","Cooper, N., & Zafiroglu, A. (2024). From Fitting Participation to Forging Relationships: The Art of Participatory ML. Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems, 1–9. https://doi.org/10.1145/3613904.3642775",From Fitting Participation to Forging Relationships: The Art of Participatory ML,Principles less-extractive,Early co-design and participatory initiatives,"Community impacts and relations, Data labor",Problem Understanding & Formulation,Product Conception & Design,Era 3,ADC,"A: examines participatory ML design processes; D: shows how brokers translate participant input into ML-compatible formats;
C: emphasizes power asymmetries, participant frustration, and value creation for communities","White (published journal papers, conference proceedings, books)",Database search,"participatory methods, machine learning, artifcial intelligence, design ",Multiple areas,Academic,Oceania,"School of Cybernetics, Australian National University, Australia",,"Interviews 18 “participation brokers.” Shows frictions turning rich, contextual input into ML-usable artifacts and uneven power/benefit flows. Recommends brokers act as educators/advocates, foregrounding participant value, dissent, and alternative futures rather than fitting participation to pre-set workflows.",
"Cooper et al., 2022","Cooper, N., Horne, T., Hayes, G., Heldreth, C., Lahav, M., Holbrook, J. S., & Wilcox, L. (2022). A Systematic Review and Thematic Analysis of Community-Collaborative Approaches to Computing Research. CHI Conference on Human Factors in Computing Systems, 1–18. https://doi.org/10.1145/3491102.3517716",A Systematic Review and Thematic Analysis of Community-Collaborative Approaches to Computing Research,Practices less-extractive,"Community engaged data production, Early co-design and participatory initiatives, Participatory data ownership & governance",Ethics frameworks,Problem Understanding & Formulation,Product Conception & Design,Multi-era,DC,"A: none; D: synthesizes CCA methods for computing research; C: emphasizes trust, shared control, and sustained benefits","White (published journal papers, conference proceedings, books)","Existing networks, relevant organizations and conferences",community collaboration; co-design; governance,Not regionally specific,Academic,Oceania,"Australian National University, Australia",,"Reviews 47 HCI/comp-research papers using community-collaborative approaches. Identifies themes for partnership building, participatory decision-making, and sustaining outcomes. Recommends structural supports to center communities, integrate local knowledge, share control, and ensure mutual benefit in collaborative technology work.",
"Cooper et al., 2024","Cooper, N., Heldreth, C., & Hutchinson, B. (2024). “It’s how you do things that matters”: Attending to Process to Better Serve Indigenous Communities with Language Technologies. In Y. Graham & M. Purver (Eds.), Proceedings of the 18th Conference of the European Chapter of the Association for Computational Linguistics (Volume 2: Short Papers) (pp. 204–211). Association for Computational Linguistics. https://aclanthology.org/2024.eacl-short.19",“It’s how you do things that matters”: Attending to Process to Better Serve Indigenous Communities with Language Technologies,Practices less-extractive,"Community engaged data production, Creating culturally inclusive datasets","Community impacts and relations, Data practices",Problem Understanding & Formulation,Institutional Prioritization & Funding,Era 3,ADC,"A: reframes goals around community needs in AI language tech; D: recommends long-term, equitable process design; C: centers Indigenous priorities and benefit sharing","White (published journal papers, conference proceedings, books)",Database search,Australia; Indigenous language; process; governance,Oceania,Academic,Oceania,"Australian National University, Australia","Google Research, USA, Australia","Advocates for a more ethical approach to developing language technology for Indigenous languages. The authors argue that such projects should prioritize the needs and values of Indigenous communities, focusing on the process of engagement rather than solely on technological outcomes. Based on interviews with researchers in Australia, the paper recommends that language technologists prioritize community needs, build long-term relationships, and ensure that data and technology benefits are shared equitably. Proposes a shift in focus from decontextualized benchmarks to a more community-centered approach that empowers Indigenous voices.",
"Cooper, 2004","Cooper, F. (2004). Development, Modernization, and the Social Sciences in the Era of Decolonization: The Examples of British and French Africa. Revue d’Histoire des Sciences Humaines, 10(1), 9–38. https://doi.org/10.3917/rhsh.010.0009","Development, Modernization, and the Social Sciences in the Era of Decolonization: The Examples of British and French Africa. ",Principles less-extractive,Early co-design and participatory initiatives,"Community impacts and relations, Critical theory/Historical background",Problem Understanding & Formulation,Institutional Prioritization & Funding,Multi-era,C,A: none; D: examines how modernization shaped research funding and agendas in Africa; C: highlights African contexts within broader decolonization analysis.,"White (published journal papers, conference proceedings, books)",Iterative keyword search,Africa; modernization; social science; decolonization,Africa,Academic,North America,"New York University, USA",,"Examines how decolonization shaped modernization theories in British and French Africa. Analyzes how social sciences structured agendas, policies, and funding during the transition from colonial to postcolonial governance. Shows how development logics embedded hierarchies that continue to influence global research and policy frameworks.",
"Corbett et al., 2023","Corbett, E., Denton, E., & Erete, S. (2023). Power and Public Participation in AI. Proceedings of the 3rd ACM Conference on Equity and Access in Algorithms, Mechanisms, and Optimization, 1–13. https://doi.org/10.1145/3617694.3623228",Power and Public Participation in AI,Principles less-extractive,Early co-design and participatory initiatives,Community impacts and relations,Cross-pipeline,Cross-pipeline,Era 3,AC,"A: evaluates public power in AI projects; D: none (indirect implications); C: maps engagement levels via Arnstein’s ladder, urging meaningful roles","White (published journal papers, conference proceedings, books)",Database search,global; participatory AI; public participation; power,Not regionally specific,Industry,North America,"Google, USA","Google Research; University of Maryland, USA","Analyzes 21 AI-related projects using Arnstein’s ladder to assess the degree of public power. Finds most efforts sit at inform/consult rather than share power. Recommends clearer accountability and resourcing for community-led roles. Implicates data-related decisions across the pipeline, shaping whose needs and harms are reflected in AI systems.",
"Costanza-Chock, 2020","Costanza-Chock, S. (2020). Design Justice: Community-Led Practices to Build the Worlds We Need. The MIT Press. https://doi.org/10.7551/mitpress/12255.001.0001",Design Justice: Community-Led Practices to Build the Worlds We Need,Principles less-extractive,Participatory data ownership & governance,"Ethics frameworks, Community impacts and relations",Problem Understanding & Formulation,Product Conception & Design,Multi-era,ADC,A: examines how technology design perpetuates inequalities; D: none; C: advocates framework centering marginalized communities,"White (published journal papers, conference proceedings, books)",Database search,"design justice, intersectionality, community-led design",Not regionally specific,Academic,North America,"Harvard University, USA",,Explores how technology design perpetuates societal inequalities and potential for dismantling them. Advocates for design justice framework that centers marginalized communities in design processes. Addresses AI bias and intersectional approaches to technology development that challenge rather than reproduce existing power structures.,
"Crawford & Paglan, 2021","Crawford, K., & Paglen, T. (2021). Excavating AI: The politics of images in machine learning training sets. AI & Society, 36(4), 1105–1116. https://doi.org/10.1007/s00146-021-01162-8",Excavating AI: The politics of images in machine learning training sets,Extractive,"Collecting vast amounts of data to train AI systems, Biased pre-processing and category erasure",Data practices,ML System Design & Development,"Data Selection, Collection & Annotation",Multi-era,ADC,"A: examines CV training sets; D: analyzes taxonomies, classes, and labeled images as political artifacts; C: surfaces harms from racialized/gendered labeling","White (published journal papers, conference proceedings, books)",Iterative keyword search,ImageNet; UTKFace; taxonomy; labeling politics,Not regionally specific,Mixed,North America,"University of Southern California, Annenberg School, Microsoft Research New York, New York, USA",,"Dissects image training sets as socio-political constructions. Unpacks how taxonomies and class labels encode assumptions about race, gender, emotion, and morality, shaping model perception. Uses case analyses (e.g., ImageNet, UTKFace) to show how dataset structures propagate stereotyping and exclusion, calling for accountable curation and label governance.",
"Crawford, 2021","Crawford, K. (2021). Atlas of AI. Yale University Press. ",Atlas of AI,Extractive,Collecting vast amounts of data to train AI systems,"Data practices, Data labor",Cross-pipeline,Cross-pipeline,Era 3,ADC,A: maps AI’s material/organizational infrastructures; D: documents extractive data and labor practices; C: centers environmental and social harms,"White (published journal papers, conference proceedings, books)",Citation/reference snowballing,"AI development, Unethical AI, data labor",North America,Mixed,North America,"Microsoft, NYU, USA",,"Examines LAION-400M (CLIP-filtered Common Crawl) and documents misogyny, pornography, slurs, and malignant stereotypes in image–alt-text pairs. Argues that web-scale scraping without robust curation encodes toxicity and reproduces harms in downstream multimodal systems, raising questions for researchers, regulators, and data subjects.",
"D’Ignazio & Klein, 2020","D’Ignazio, C., & Klein, L. F. (2020). Data Feminism. The MIT Press. https://doi.org/10.7551/mitpress/11805.001.0001",Data Feminism,Principles less-extractive,"Early co-design and participatory initiatives, Community engaged data production, Participatory data ownership & governance",Data practices,Cross-pipeline,Cross-pipeline,Multi-era,ADC,"A: offers intersectional framework for data work; D: advances participatory, power-aware methods; C: centers marginalized voices and accountability","White (published journal papers, conference proceedings, books)",Iterative keyword search,Feminism; intersectionality; data ethics; participation; accountability,Not regionally specific,Academic,North America,"Massachusettes Institute of Technology, USA","Emory University, USA",Examines how data practices can perpetuate gender inequalities and advocates for a data feminism framework that centers marginalized voices and intersectional analysis.,
"Daliparthi et al., 2023a","Daliparthi, V. S. S. A., Momen, N., Tutschku, K., & De Prado, M. (2023a). ViSDM 1.0: Vision Sovereignty Data Marketplace a Decentralized Platform for Crowdsourcing Data Collection and Trading. Proceedings of the 2023 ACM Conference on Information Technology for Social Good, 374–383. https://doi.org/10.1145/3582515.3609556",ViSDM 1.0: Vision Sovereignty Data Marketplace a Decentralized Platform for Crowdsourcing Data Collection and Trading,Practices less-extractive,Crowdsourcing data collection,Data labor,ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,AD,"A: marketplace supports AI data pipelines conceptually; D: decentralized crowdsourcing, pricing, ownership; C: none","White (published journal papers, conference proceedings, books)",Database search,decentralized marketplace; crowdsourcing; blockchain; data ownership,Not regionally specific,Academic,EU/UK,"Blekinge Institute of Technology, Sweden",,"Proposes a blockchain-based data marketplace where contributors retain ownership and set prices for computer-vision data. Describes mechanisms for task posting, pricing, verification, and reward distribution. Positions decentralized governance as a way to compensate contributors and surface provenance for downstream model use. While not community-focused, it links compensation and ownership to less-extractive data acquisition pathways in AI development.",
"Daliparthi et al., 2023b","Daliparthi, V. S. S. A., Momen, N., Tutschku, K., & De Prado, M. (2023b). ViSDM: A Liquid Democracy based Visual Data Marketplace for Sovereign Crowdsourcing Data Collection. European Interdisciplinary Cybersecurity Conference, 108–115. https://doi.org/10.1145/3590777.3590794",ViSDM: A Liquid Democracy based Visual Data Marketplace for Sovereign Crowdsourcing Data Collection,Practices less-extractive,Crowdsourcing data collection,Data labor,ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,AD,"A: target users are AI data buyers; D: sovereign crowdsourcing, value/pricing, profit-sharing; C: none","White (published journal papers, conference proceedings, books)",Database search,"crowdsource data collection, decentralized, blockchain, NOT ABOUT MARGINALIZED COMMUNITIES",Not regionally specific,Academic,EU/UK,"Blekinge Institute of Technology, Sweden",,"Describes a visual-data marketplace where contributors retain ownership, pricing reflects negotiated or model-based value, and profits are shared under liquid-democracy mechanisms. Focuses on incentive design, provenance, and payout logic for AI buyers. Positions decentralized compensation as an alternative to opaque sourcing, without centering community justice or marginalized groups.",
"Davies et al., 2019","Davies, T., Walker, S. B., Rubinstein, M., & Perini, F. (Eds.). (2019). The State of Open Data: Histories and Horizons. African Minds. https://doi.org/10.5281/zenodo.2668475",The State of Open Data: Histories and Horizons,Principles less-extractive,Participatory data ownership & governance,Data practices,Problem Understanding & Formulation,Institutional Prioritization & Funding,Multi-era,DC,A: none; D: analyzes open data movement progress and infrastructure; C: highlights need for inclusivity and data literacy across global contexts,"White (published journal papers, conference proceedings, books)",Database search,"open data, data literacy, infrastructure",Multiple areas,Government,North America,"International Development of Research Centre (IDRC), Ottawa, Canada ",,"Comprehensive assessment of open data movement's first decade with over 60 global authors. Examines sectors from agriculture to urban development, addresses issues including AI, Indigenous data sovereignty, and privacy. Features dedicated chapter on Indigenous data sovereignty and global regional analyses. Evaluates real-world progress and challenges shaping open data's future evolution.",
"Delgado et al., 2023","Delgado, F., Yang, S., Madaio, M., & Yang, Q. (2023). The Participatory Turn in AI Design: Theoretical Foundations and the Current State of Practice. Proceedings of the 3rd ACM Conference on Equity and Access in Algorithms Mechanisms and Optimization, 1–23. https://doi.org/10.1145/3617694.3623261",The Participatory Turn in AI Design: Theoretical Foundations and the Current State of Practice,Principles less-extractive,Early co-design and participatory initiatives,"Critical theory/Historical background, Community impacts and relations",Problem Understanding & Formulation,Product Conception & Design,Era 3,AC,A: synthesizes participatory AI theory and practice; D: none (indirect implications); C: defines axes to strengthen stakeholder roles and accountability,"White (published journal papers, conference proceedings, books)",Database search,global; participatory AI; framework; stakeholder engagement,Not regionally specific,Academic,North America,"Cornell University, New York, USA","Google Research, New York; University of Southern California, CA, USA","Synthesizes participatory design work in AI and proposes “Parameters of Participation” to evaluate representation, timing, power, and feedback. Highlights gaps between rhetoric and practice. Links framework choices to how data is defined, gathered, and governed, affecting communities shaped by AI outputs.",
"Deloria & Lytle, 1998","Deloria, V., & Lytle, C. M. (1998). The Nations Within: The Past and Future of American Indian Sovereignty. University of Texas Press.
",The Nations Within: The Past and Future of American Indian Sovereignty,Principles less-extractive,Other/NA (conceptual framing),"Ethics frameworks, Community impacts and relations, Critical theory/Historical background",Cross-pipeline,Cross-pipeline,Multi-era,C,A: none; D: none; C: centers Native nations’ authority and community self-determination.,"White (published journal papers, conference proceedings, books)","Existing networks, relevant organizations and conferences",North America; sovereignty; Indigenous governance,North America,Mixed,North America,"University of Arizona, USA",,"Seminal work tracing legal and political foundations of American Indian sovereignty and federal relations, arguing for Native nations’ authority over governance decisions. Provides historical grounding for contemporary sovereignty claims that inform Indigenous data governance debates. Frames community-controlled decision-making and consent as central to managing information practices that affect Indigenous communities.",
"Denton et al., 2020","Denton, R., Hanna, A., Amironesei, R., Smart, A., Nicole, H., & Scheuerman, M. K. (2020). Bringing the People Back In: Contesting Benchmark Machine Learning Datasets (No. arXiv:2007.07399). arXiv. https://doi.org/10.48550/arXiv.2007.07399",Bringing the People Back In: Contesting Benchmark Machine Learning Datasets,Extractive,"Excluding underrepresented groups from decision-making, Keeping communities in the dark through opaque data practices","Community impacts and relations, Data practices",ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,ADC,"A: critiques benchmark-driven modeling; D: calls for accountable, participatory dataset curation; C: centers affected people","White (published journal papers, conference proceedings, books)","Existing networks, relevant organizations and conferences","Benchmark datasets, machine learning, data ethics, social context",Not regionally specific,Industry,North America,"Google Research, USA","Denton and Hanna equal contribution. One author affiliated with University of San Francisco, USA","Outlines a genealogy approach to examine benchmark datasets as social infrastructure. Proposes reflexive practices before collection, including explicit objectives and methods for curation and classification. Moves inquiry from data subjects to dataset creators and their labor, highlighting “predatory inclusion” and visibility traps. Links dataset design to downstream harms and argues for participatory, accountable data documentation that shifts power toward affected communities.",
"Denton et al., 2021","Denton, E., Hanna, A., Amironesei, R., Smart, A., & Nicole, H. (2021). On the genealogy of machine learning datasets: A critical history of ImageNet. Big Data & Society, 8(2), 205395172110359. https://doi.org/10.1177/20539517211035955",On the genealogy of machine learning datasets: A critical history of ImageNet,Extractive,Collecting vast amounts of data to train AI systems,Data practices,ML System Design & Development,"Data Selection, Collection & Annotation",Multi-era,ADC,"A: interrogates dataset norms shaping CV; D: traces accumulation, construction of meaning, and invisibilized labor; C: surfaces downstream harms from ImageNet lineage","White (published journal papers, conference proceedings, books)",Database search,ImageNet; dataset genealogy; computer vision,Not regionally specific,Industry,North America,"Google Research, NY, USA","Center for Applied Data Ethics, University of San Francisco, CA, USA","Traces AI’s political economy across minerals, labor, data centers, and datasets, arguing that invisible extraction underpins AI progress. Uses visual/empirical mapping to connect data practices and labor to environmental and social harms, foregrounding communities affected along the pipeline.",
"Dev et al., 2023","Dev, S., Goyal, J., Tewari, D., Dave, S., & Prabhakaran, V. (2023). Building Socio-culturally Inclusive Stereotype Resources with Community Engagement (No. arXiv:2307.10514). arXiv. https://doi.org/10.48550/arXiv.2307.10514",Building Socio-culturally Inclusive Stereotype Resources with Community Engagement,Practices less-extractive,Community engaged data production,"Community impacts and relations, Data practices",ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,ADC,A: positions stereotype resources for AI fairness evaluation; D: builds SPICE via community engagement; C: centers culturally grounded perspectives from India,"Grey (Reports, blogs, white papers, policy documents, theses, conference papers)",Database search,India; stereotype resource; community engagement; fairness,APAC (Asia-Pacific Region),Industry,North America,Google Research India,"Circadian Connect, India","Introduces SPICE, a stereotype resource designed to improve culturally inclusive AI fairness evaluations. The team engaged Indian communities to co-design categories, collect examples, and validate annotations. Findings show that stereotypes embedded in Western datasets often misrepresent local contexts, while SPICE captures regionally specific patterns that models fail to address. By foregrounding participatory processes, the work demonstrates how community-led resource creation produces more accurate diagnostic tools. It links dataset development directly to the fairness of AI data production, showing that culturally grounded evaluation resources are essential to reducing bias and supporting impacted groups.",
"DeWitt Prat et al., 2024","DeWitt Prat, L., Lucas, O., Golias, C., Lewis, M. (2024). Decolonizing LLMs: An Ethnographic Framework for AI in African Contexts. Ethnographic Praxis in Industry Conference Proceedings 2024, 46–85. https://doi.org/10.1111/epic.12196",Decolonizing LLMs: An Ethnographic Framework for AI in African Contexts,Principles less-extractive,Early co-design and participatory initiatives,"Ethics frameworks, Community impacts and relations",Problem Understanding & Formulation,Product Conception & Design,Era 3,ADC,"A: interrogates LLM behavior in African settings; D: proposes fieldwork-informed data practices/provenance; C: centers agency, vernaculars, and local impact","White (published journal papers, conference proceedings, books)","Existing networks, relevant organizations and conferences","Africa, large language models, generative AI, multilingualism, decolonization, cultural translation",Africa,Mixed,EU/UK,"Bold Insight, Paris, France
","Mantaray, South Africa;
Google, USA;
Independent scholar, USA","Highlights the potential pitfalls of deploying LLMs in African contexts due to their predominantly Western origins and training data. The authors, a group of researchers with diverse backgrounds, argue that LLMs, despite their impressive capabilities, can unintentionally perpetuate digital colonialism and exacerbate existing sociopolitical tensions if not carefully adapted to the unique linguistic and cultural landscapes of Africa. The paper explores the complexities of language use and decolonization in Africa, highlighting the need for a more culturally informed and ethical approach to LLM research and deployment. It presents a two-phased ethnographic framework designed to guide researchers in conducting culturally sensitive studies that center African agency and vernaculars.",
"Díaz et al., 2022","Díaz, M., Kivlichan, I., Rosen, R., Baker, D., Amironesei, R., Prabhakaran, V., & Denton, R. (2022). CrowdWorkSheets: Accounting for Individual and Collective Identities Underlying Crowdsourced Dataset Annotation. Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency, 2342–2351. https://doi.org/10.1145/3531146.3534647",CrowdWorkSheets: Accounting for Individual and Collective Identities Underlying Crowdsourced Dataset Annotation,Principles less-extractive,"Building public visibility in dataset development, Establishing consent and contextually appropriate compensation","Data practices, Data labor",ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,ADC,A: connects dataset annotation to ML development; D: proposes CrowdWorkSheets to document annotator identity and task design; C: highlights annotator–platform power asymmetries and fairness concerns,"White (published journal papers, conference proceedings, books)",Database search,"dataset annotation, documentation, annotator identity, crowdsourcing",Not regionally specific,Industry,North America,"Google, USA","Jigsaw, USA","Human annotated data plays a crucial role in machine learning (ML) research and development. However, the ethical considerations around the processes and decisions that go into dataset annotation have not received nearly enough attention. In this paper, we survey an array of literature that provides insights into ethical considerations around crowdsourced dataset annotation. We synthesize these insights, and lay out the challenges in this space along two layers: (1) who the annotator is, and how the annotators’ lived experiences can impact their annotations, and (2) the relationship between the annotators and the crowdsourcing platforms, and what that relationship affords them. Finally, we introduce a novel framework, CrowdWorkSheets, for dataset developers to facilitate transparent documentation of key decisions points at various stages of the data annotation pipeline: task formulation, selection of annotators, platform and infrastructure choices, dataset analysis and evaluation, and dataset release and maintenance.",
"Domingos et al., 2019","Domingos, N., Jerónimo, M. B., & Roque, R. (Eds.). (2019). Resistance and Colonialism: Insurgent Peoples in World History. Springer International Publishing. https://doi.org/10.1007/978-3-030-19167-2",Resistance and Colonialism: Insurgent Peoples in World History,Principles less-extractive,Other/NA (conceptual framing),Critical theory/Historical background,Problem Understanding & Formulation,Institutional Prioritization & Funding,Multi-era,C,A: none; D: none; C: situates colonialism and resistance as central to knowledge of extraction,"White (published journal papers, conference proceedings, books)",Iterative keyword search,"Colonialism, resistance, insurgency",Multiple areas,Academic,EU/UK,"University of Lisbon, Lisbon, Portugal",Edited academic collection from University of Lisbon scholars,"Edited collection arguing resistance must be understood as diverse and context-specific, not singular. Brings global case studies showing how colonial extraction provoked multiple insurgent responses. Provides conceptual grounding for analyzing extractive dynamics and their contestation.",
"Dourish et al., 2020","Dourish, P., Lawrence, C., Leong, T. W., & Wadley, G. (2020). On Being Iterated: The Affective Demands of Design Participation. Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems, 1–11. https://doi.org/10.1145/3313831.3376545",On Being Iterated: The Affective Demands of Design Participation,Extractive,"Prioritizing data wants over community needs, Soliciting data without reciprocal benefits",Community impacts and relations,Problem Understanding & Formulation,Product Conception & Design,Era 3,DC,A: none; D: critiques iterative HCI practices as burdensome; C: highlights affective costs for marginalized communities in participatory design,"White (published journal papers, conference proceedings, books)",Database search,"Oceania, Aboriginal Australian communities, HCI, iteration, participation",Oceania,Academic,EU/UK,"Maastricht Univeristy, Netherlands",,"Critically examines the concept of iteration in human-computer interaction (HCI) design. While iteration is considered a fundamental practice in HCI, the authors question its affective demands on user communities, particularly those historically marginalized, such as Aboriginal Australians. Drawing on feminist and decolonial theory, the paper argues that iteration often masks a history of broken promises and postponed solutions. The authors suggest that HCI’s emphasis on participation can further burden marginalized communities by delegating responsibility and emotional labor. Instead, the authors call for HCI researchers to acknowledge the historical and political contexts of their work and to re-evaluate the power dynamics inherent in design processes. By shifting the focus from design artifacts to design relations, HCI can better serve the needs of diverse communities.",
"Duffourc et al., 2024","Duffourc, M., Gerke, S., & Kollnig, K. (2024). Privacy of Personal Data in the Generative AI Data Lifecycle (SSRN Scholarly Paper No. 4899219). https://doi.org/10.2139/ssrn.4899219",Privacy of Personal Data in the Generative AI Data Lifecycle,Extractive,Collecting vast amounts of data to train AI systems,Data practices,ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,ADC,"A: surveys GenAI data lifecycle and legal bases; D: analyzes scraping, consent, retention, and risk; C: details individual harms and GDPR/US law gaps","Grey (Reports, blogs, white papers, policy documents, theses, conference papers)",Citation/reference snowballing,GenAI; privacy; scraping; consent; GDPR,Multiple areas,Academic,EU/UK,"Maastricht University, NL","University of Illinois College of Law, USA","Provides a critical genealogy of ImageNet, identifying norms of accumulation, computationally constructed meaning, and obscured data labor. Shows how these norms traveled into contemporary CV practice and influenced downstream uses and harms, motivating re-examination of dataset making.",
"Duncan et al., 2024","Duncan, S., Leoni, G., Steven, L., Mahelona, K., & Jones, P.-L. (2024, November 13). Fit for our purpose, not yours: Benchmark for a low-resource, Indigenous language. The Thirty-eight Conference on Neural Information Processing Systems Datasets and Benchmarks Track. https://openreview.net/forum?id=w5jfyvsRq3#discussion ","Fit for our purpose, not yours: Benchmark for a low-resource, Indigenous language",Practices less-extractive,"Community engaged data production, Decentering Western ontologies, Creating culturally inclusive datasets","Community impacts and relations, Data practices",ML System Design & Development,Model Training & Evaluation,Era 3,ADC,A: benchmarks model performance in Māori; D: develops culturally appropriate evaluation; C: supports revitalization goals,"White (published journal papers, conference proceedings, books)","Existing networks, relevant organizations and conferences","Oceania, Maori, benchmark, inclusivity",Oceania,NGO/Non-profit,Oceania,"Te Reo Irirangi o Te Hiku o Te Ika (Te Hiku Media), Aotearoa New Zealand",,"Te Hiku Media develops “Te Taumata,” a Māori benchmark tailored to local linguistic norms and revitalization aims. Paper shows mainstream benchmarks misrepresent low-resource Indigenous languages and can mislead system development. Custom evaluation better captures pronunciation, grammar, and usage variation relevant to community needs. Work advances a pathway for culturally grounded benchmarking tied to sovereignty and practical outcomes.",
"Durante et al., 2021","Durante, F., Kröger, M., & LaFleur, W. (2021). Extraction and Extractivisms. In J. Shapiro & J.-A. McNeish (Eds.), Our Extractive Age (pp. 17–30). Routledge. https://doi.org/10.4324/9781003127611-3
",Extraction and Extractivisms,Extractive,Other/NA (conceptual framing),Critical theory/Historical background,Problem Understanding & Formulation,Institutional Prioritization & Funding,Multi-era,C,A: none; D: none; C: defines extraction as ontology and traces its history; introduces extrActivism,"White (published journal papers, conference proceedings, books)",Database search,"extractivism, colonialism, capitalism",Not regionally specific,Academic,EU/UK,"University of Helsinki, Finland",,"Defines extractivism as a mindset and set of practices oriented toward maximizing benefit through removal, tied to violence and dispossession. Traces etymology and historical continuities from ancient empires to modern capitalism and data economies. Introduces “extrActivism” as resistance. Foundational conceptual framing for understanding extraction across domains.","Gives an inclusive definition of extractivism as “a particular way of thinking and the properties and practices organized towards the goal of maximizing benefit through extraction, which brings in its wake violence and destruction.” They outline how extraction and extractivism have been used as concepts and how they can be used in reference to violence with an etymological analysis of the Latin roots of the key concepts and distinguished different historical epochs, timelines, and roots of global extractivisms as an ontological feature of the modern world-ecology, as nested in a longer succession of world systems. Although these dynamics began to gain traction about 500 years ago, ontologically extractivist mindsets and practices already existed—depleting, destroying, and deforesting lived environments for thousands of years before the modern world-system—as is visible in the building of empires and ancient civilizations. Based on that historical panorama, they discuss how “the extractivist thrust has become ever more widespread, violent, and global in scale and pace. The line between tangible and intangible realms of extraction has become blurred as financial speculation and markets that are digitized and run by algorithms have spread.”"
"Eglash et al., 2024","Eglash, R., Robinson, K. P., Bennett, A., Robert, L., & Garvin, M. (2024). Computational reparations as generative justice: Decolonial transitions to unalienated circular value flow. Big Data & Society, 11(1), 20539517231221732. https://doi.org/10.1177/20539517231221732",Computational reparations as generative justice: Decolonial transitions to unalienated circular value flow,Principles less-extractive,Participatory data ownership & governance,Critical theory/Historical background,Deployment & Impact,Product Launch,Era 3,DC,A: none; D: proposes computational models for equitable value circulation; C: emphasizes community reparations and local ownership of labor and data value,"White (published journal papers, conference proceedings, books)",Database search,"North America, computational tools, reparations, generative justice",North America,Academic,North America,"University of Michigan, USA",,"Argues that reparations require restructuring technology systems toward generative justice rather than extraction. Proposes a framework where communities retain control of production and value circulation. Case work in Detroit Black-owned businesses integrates computational tools with artisanal labor to build circular economies. Demonstrates how micro-level adaptations, institutional collaborations, and platform development can create more equitable data and labor infrastructures. Positions computational design as a site for decolonial transition and community empowerment",
"Ekbia & Nardi, 2017","Ekbia, H. R., & Nardi, B. A. (2017). Heteromation, and Other Stories of Computing and Capitalism. MIT Press.","Heteromation, and Other Stories of Computing and Capitalism",Extractive,Exploitative and invisible data labor,"Data labor, Critical theory/Historical background",Cross-pipeline,Cross-pipeline,Era 2,DC,A: non-AI automation context; D: exposes hidden data work underpinning systems; C: worker exploitation dynamics,"White (published journal papers, conference proceedings, books)",Database search,"heteromation, computing, capitalism",Not regionally specific,Academic,North America,"Syracuse University, USA",,"Develops “heteromation” to describe extraction of value from low- or unpaid digital labor across platforms. Synthesizes communicative, cognitive, creative, emotional, and organizing labor forms to show how computation reconfigures work. Highlights how users’ everyday interactions produce value without commensurate returns. Provides a conceptual frame to read data production practices underlying AI pipelines as part of broader capitalist accumulation, illuminating risks of invisibilized labor for affected communities.",
"Ekdale & Tully, 2019","Ekdale, B., & Tully, M. (2019). African elections as a testing ground: Comparing coverage of Cambridge Analytica in Nigerian and Kenyan newspapers. African Journalism Studies, 40(4), 27-43. https://doi.org/10.1080/23743670.2019.1679208 ","African Elections as a Testing Ground: Comparing Coverage of Cambridge Analytica in Nigerian and Kenyan Newspapers
",Extractive,Ethics dumping in less-regulated contexts,"Data practices, Community impacts and relations",Problem Understanding & Formulation,Institutional Prioritization & Funding,Era 2,ADC,"A: examines the deployment context of psychometric profiling/micro-targeting (algorithmic campaigning) as a news object; D: data harvesting appears as background, not analyzed methodologically; C: implications for elections, press, and democratic institutions in NG/KE","White (published journal papers, conference proceedings, books)",Citation/reference snowballing,"Africa, Cambridge analytica, data privacy, data protection, democracy, politics",Africa,Academic,North America,"University of Iowa, USA",,"Compares Nigerian and Kenyan newspaper coverage of Cambridge Analytica. Finds reliance on international reporting and differences in emphasis: Nigerian papers address scandal and political effects; Kenyan papers stress implications for democratic institutions. Shows how Global South elections are framed as sites for external data-driven experimentation, with local scrutiny and accountability lagging behind transnational actors.",
"Elish & Boyd, 2018","Elish, M. C., & Boyd, D. (2018). Situating methods in the magic of Big Data and AI. Communication Monographs, 85(1), 57–80. https://doi.org/10.1080/03637751.2017.1375130",Situating methods in the magic of Big Data and AI,Principles less-extractive,Early co-design and participatory initiatives,"Critical theory/Historical background, Data practices",Problem Understanding & Formulation,Product Conception & Design,Era 2,ADC,"A: interrogates AI/Big Data “magic”; D: critiques data collection/interpretation myths; C: urges contextual, reflexive practice to limit harm","White (published journal papers, conference proceedings, books)",Citation/reference snowballing,global; big data; methodological reflexivity; social context,Not regionally specific,Mixed,North America,"Data & Society Research Institute, NY USA","Microsoft Research, USA","Critiques the cultural “magic” of Big Data/AI and calls for methodological reflexivity. Shows how unexamined assumptions distort problem framing, data collection, and interpretation. Argues for situated methods attentive to context and limits. Connects reflexive practice to more careful AI data decisions with downstream consequences for affected communities.",
"Fanon, 1961","Fanon, F. (1961). The Wretched of the Earth (C. Farrington, Trans.). Grove Press.",The Wretched of the Earth ,Principles less-extractive,Decentering Western ontologies,Critical theory/Historical background,Cross-pipeline,Cross-pipeline,Multi-era,C,A: none; D: none (indirect implications for data extraction critique); C: analyzes colonial domination and necessitates structural transformation,"White (published journal papers, conference proceedings, books)","Existing networks, relevant organizations and conferences",Decolonization; power,Multiple areas,Journalist/Other/Not Sure,EU/UK,"Independent, originally from Martinique/Algeria",,"Examines colonial violence and the persistence of hierarchical control after formal decolonization. Argues for dismantling exploitative structures and centering the agency of the oppressed. Provides a theoretical anchor for critiques of extractive infrastructures—frequently referenced when assessing how data capture, categorization, and deployment can reinforce racialized and geopolitical asymmetries.",
"Farnadi et al., 2024","Farnadi, G., Havaei, M., & Rostamzadeh, N. (2024). Position: Cracking the Code of Cascading Disparity Towards Marginalized Communities (No. arXiv:2406.01757). arXiv. https://doi.org/10.48550/arXiv.2406.01757",Position: Cracking the Code of Cascading Disparity Towards Marginalized Communities,Extractive,"Collecting vast amounts of data to train AI systems, Biased pre-processing and category erasure","Data practices, Community impacts and relations",ML System Design & Development,Model Training & Evaluation,Era 3,ADC,"A: theorizes disparities in foundation models; D: links data, training, and deployment to cascading disparity; C: centers impacts on marginalized communities","Grey (Reports, blogs, white papers, policy documents, theses, conference papers)",Citation/reference snowballing,foundation model; cascading disparity; representation metric,Not regionally specific,Mixed,North America,"Google Research, Canada",,"Defines “cascading disparity” across the foundation-model lifecycle—data composition, training, and deployment—showing how interconnected gaps amplify harms for marginalized groups. Proposes metrics for representation quality, capacity-guided modeling, and model-guided data collection to address disparities at the source. Emphasizes measurable interventions that foreground impacted communities.",
"Feffer et al., 2023","Feffer, M., Skirpan, M., Lipton, Z., & Heidari, H. (2023). From Preference Elicitation to Participatory ML: A Critical Survey & Guidelines for Future Research. Proceedings of the 2023 AAAI/ACM Conference on AI, Ethics, and Society, 38–48. https://doi.org/10.1145/3600211.3604661 ",From Preference Elicitation to Participatory ML: A Critical Survey & Guidelines for Future Research,Principles less-extractive,Early co-design and participatory initiatives,"Community impacts and relations, Data practices",ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,ADC,A: surveys participatory ML methods; D: critiques preference-elicitation pipelines shaping data; C: centers meaningful stakeholder engagemen,"White (published journal papers, conference proceedings, books)",Database search,global; participatory ML; stakeholder participation; AI ethics,Not regionally specific,Academic,North America,"Carnegie Mellon University, USA",,"Surveys participatory ML, arguing common preference-elicitation methods flatten complex values and under-engage stakeholders. Proposes ten axes for evaluating participation across the ML lifecycle. Ties participation quality to how training data is defined, collected, and labeled, with direct implications for community representation in AI systems",
"Felkner et al., 2023","Felkner, V. K., Chang, H.-C. H., Jang, E., & May, J. (2023). WinoQueer: A Community-in-the-Loop Benchmark for Anti-LGBTQ+ Bias in Large Language Models (No. arXiv:2306.15087). arXiv. https://doi.org/10.48550/arXiv.2306.15087 ",WinoQueer: A Community-in-the-Loop Benchmark for Anti-LGBTQ+ Bias in Large Language Models,Practices less-extractive,Creating culturally inclusive datasets,"Data practices, Community impacts and relations",ML System Design & Development,Model Training & Evaluation,Era 3,ADC,A: measures LLM bias; D: co-creates benchmark with LGBTQ+ community; C: targets community-relevant harms and mitigation,"Grey (Reports, blogs, white papers, policy documents, theses, conference papers)",Database search,North America; LGBTQ+ benchmark; bias; mitigation,North America,Academic,North America,"Information Sciences Institute, University of Southern California, USA","Dartmouth College; Annenberg School
for Communication and Journalism
University of Southern California, USA","Builds WinoQueer from LGBTQ+ community reports of harm to capture bias phenomena that generic benchmarks miss. Evaluates several LLMs, showing significant anti-LGBTQ+ bias; shows that fine-tuning on relevant community text reduces bias. Provides a template for participatory benchmarks.",
"Fricker, 2007","Fricker, M. (2007). Epistemic injustice: Power and the ethics of knowing. Oxford university press.",Epistemic injustice: Power and the ethics of knowing,Extractive,Excluding underrepresented groups from decision-making,Critical theory/Historical background,Cross-pipeline,Cross-pipeline,Multi-era,C,A: none; D: none (indirect implications); C: defines testimonial and hermeneutical injustice marginalizing communities in knowledge systems,"White (published journal papers, conference proceedings, books)",Iterative keyword search,"epistemic injustice, credibility, exclusion",Not regionally specific,Academic,EU/UK,"Birkbeck College, University of London",,"DIscusses concept of epistemic injustice and the exclusion of marginalized groups from full participation in knowledge sharing and social understanding. It includes testimonial injustice, where identity prejudice undermines the credibility of speakers, and hermeneutical injustice, where marginalized groups are excluded from shaping broader social meanings due to systemic barriers.",
"Gadiraju et al., 2023","Gadiraju, V., Kane, S., Dev, S., Taylor, A., Wang, D., Denton, E., & Brewer, R. (2023). “I wouldn’t say offensive but...”: Disability-Centered Perspectives on Large Language Models. 2023 ACM Conference on Fairness, Accountability, and Transparency, 205–216. https://doi.org/10.1145/3593013.3593989 ",“I wouldn’t say offensive but...”: Disability-Centered Perspectives on Large Language Models,Extractive,"""Deploying AI systems that lack local, contextual data""","Community impacts and relations, Data practices",ML System Design & Development,Model Training & Evaluation,Era 3,ADC,A: probes LLM outputs; D: connects failures to biased data/training; C: centers lived experiences of disabled participants,"White (published journal papers, conference proceedings, books)",Database search,"Global, large language models, disability, stereotypes",Not regionally specific,Mixed,North America,"University of Colorado Boulder, USA","Google Research; City University of London, UK; University of Michigan, USA","Focus groups with 56 people with disabilities revealed that LLMs perpetuate subtle harms—e.g., inspiration porn and able-bodied savior tropes—rather than overt offensiveness. Findings highlight systemic bias in training data. Authors recommend co-design with disability communities, diverse annotation, and collaborative model development.",
"Gago & Mezzadra, 2017","Gago, V., & Mezzadra, S. (2017). A Critique of the Extractive Operations of Capital: Toward an Expanded Concept of Extractivism. Rethinking Marxism, 29(4), 574–591. https://doi.org/10.1080/08935696.2017.1417087
",A Critique of the Extractive Operations of Capital: Toward an Expanded Concept of Extractivism,Extractive,Soliciting data without reciprocal benefits,Critical theory/Historical background,Problem Understanding & Formulation,Institutional Prioritization & Funding,Multi-era,DC,A: none; D: expands extractivism concept beyond natural resources to include data and social cooperation; C: analyzes impacts on labor and social spaces in Latin American contexts,"White (published journal papers, conference proceedings, books)",Database search,"extractivism, capitalism, financialization","LatAm (includes Central America, South America & Carribbean)",Academic,"LatAm (includes Central America, South America & Carribbean)","University of Buenos Aires, National University of San Martín, National Scientific and Technical Research Council (CONICET, Argentina",,"Critiques the dominant understanding of extractivism in Latin America by broadening its scope to encompass contemporary capitalist processes. The authors argue that extractivism is not limited to the extraction of natural resources like minerals and agricultural products, but also includes the extraction of value from human labor and life through financialization, digitalization, and even the exploitation of social and political spaces. They contend that financial capital, through processes of financialization, functions as an extractive apparatus that generates wealth by drawing upon ""future production,"" and that this ""extractive"" function is a defining feature of contemporary capitalism. By exploring the interconnections between extractivism, financialization, and the production of social cooperation, the authors highlight how these interconnected operations contribute to a pattern of valorization that differs from that of industrial capitalism.",
"Garcia et al., 2022","Garcia, P., Sutherland, T., Salehi, N., Cifor, M., & Singh, A. (2022). No! Re-imagining Data Practices Through the Lens of Critical Refusal. Proc. ACM Hum.-Comput. Interact., 6(CSCW2), 315:1-315:20. https://doi.org/10.1145/3557997",No! Re-imagining Data Practices Through the Lens of Critical Refusal,Principles less-extractive,Other/NA (conceptual framing),"Data practices, Critical theory/Historical background",Problem Understanding & Formulation,Product Conception & Design,Multi-era,ADC,"A: links refusal to alternatives in AI data practices; D: examines how refusal disrupts extractive data logics; C: foregrounds power, inequities, and interlocking struggles","White (published journal papers, conference proceedings, books)",Database search,North America; critical refusal; feminist data practice; inequity,North America,Academic,North America,"University of Michigan, Ann Arbor, MI, USA","University of Hawai'i at Manoa, Honolulu, HI, USA; University of California, Berkeley, Berkeley, CA, USA; University of Washington, Seattle, WA, USA","Theorizes “critical refusal” as a practice for confronting unequal power in data work. Using the Feminist Data Manifest-No and cases, authors show how saying “no” can open space for community-protective alternatives, reorienting goals, methods, and governance away from extraction and toward justice across intertwined struggles.",
"García et al., 2024","García, A., Rogotis, S., Farrell, E., Hajikhani, A., Kinnula, A., Komssi, M., & Tuikka, T. (Eds.). (2024). Generative AI and Data Spaces: White Paper. Data Spaces Support Centre.",Generative AI and Data Spaces: White Paper,Practices less-extractive,Developing federated data spaces,Data practices,ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,AD,"A: links GenAI adoption to governed data infrastructure; D: proposes secure, interoperable data spaces; C: none","Grey (Reports, blogs, white papers, policy documents, theses, conference papers)",Iterative keyword search,Europe; data space; governance; interoperability,EU/UK,Mixed,EU/UK,"Data Spaces Support Centre (DSSC), EU; Big Data Value Association (BDVA), BE; Joint Research Centre (JRC), Italy; Fraunhofer Group for Microelectronics, Germany",,"Examines how European data spaces can support GenAI via governed, interoperable access to domain data. Identifies barriers (quality, legal constraints, skills, sustainability) and offers sectoral cases and recommendations. Frames data-space design as an actionable route to higher-quality training inputs and compliance, affecting how data is produced, shared, and reused for AI.",
"Gebru et al., 2021","Gebru, T., Morgenstern, J., Vecchione, B., Vaughan, J. W., Wallach, H., III, H. D., & Crawford, K. (2021). Datasheets for datasets. Commun. ACM, 64(12), 86–92. https://doi.org/10.1145/3458723",Datasheets for datasets,Practices less-extractive,Building public visibility in dataset development,Data practices,ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,ADC,"A: formalizes dataset documentation artifact; D: presents question template covering creation, composition, use, and maintenance; C: aims to mitigate harmful outcomes for affected groups","White (published journal papers, conference proceedings, books)",Database search,"data documentation, dataset creators, dataset consumers, transparency & accountability",Not regionally specific,Mixed,North America,"DAIR Institute, Palo Alto, CA, USA",,"Proposes “datasheets” as standardized documentation for datasets, detailing motivation, composition, collection, processing, intended uses, distribution, and maintenance. Positions documentation as technical infrastructure that supports transparency, accountability, and better communication between dataset creators and consumers, reducing downstream harms and enabling more ethical ML practice.",
"Ghana NLP, n.d.","Ghana NLP. (n.d.). Ghana Natural Language Processing (NLP)— Ghana NLP. Retrieved September 7, 2025, from https://ghananlp.org/",Ghana Natural Language Processing (NLP),Practices less-extractive,"Creating culturally inclusive datasets, Community engaged data production",Community impacts and relations,ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,ADC,"A: motivates gaps in language tech for Ghana; D: develops datasets, tools, and systems for local use; C: builds regional capacity and access","Grey (Reports, blogs, white papers, policy documents, theses, conference papers)","Existing networks, relevant organizations and conferences",Africa; Ghanaian language; dataset; local application,Africa,NGO/Non-profit,Africa,"Ghana NLP, Ghana",,"Describes an open-source initiative dedicated to developing resources and applications for Ghanaian languages. The group focuses on building corpora, adapting state-of-the-art NLP methods to low-resource contexts, and creating systems such as translation tools for Twi, Ewe, and Frafra. Their work demonstrates how locally driven projects overcome data scarcity while aligning technology development with community needs. The initiative positions open datasets and applications as community assets rather than proprietary products. This approach links AI data production to regional inclusion, strengthening access to language technologies across West Africa and reducing dependency on external platforms.",
"Gilman, 2022","Gilman, M. E. (2022). Beyond window dressing: public participation for marginalized communities in the datafied society. Fordham L. Rev., 91, 503.",Beyond Window Dressing: Public Participation for Marginalized Communities in the Datafied Society,Principles less-extractive,Early co-design and participatory initiatives,"Data practices, Community impacts and relations",Problem Understanding & Formulation,Institutional Prioritization & Funding,Era 3,DC,A: none (indirect implications); D: analyzes participation mechanisms in data governance; C: focuses on marginalized communities’ capacity to influence outcomes,"White (published journal papers, conference proceedings, books)",Iterative keyword search,North America; public participation; data governance; marginalized community,North America,Academic,North America,"University of Baltimore, USA",,"Evaluates participation in datafied governance with attention to legal design. Argues that transparency, enforceable duties, and resources are prerequisites for meaningful input by marginalized communities. Connects procedural design to upstream agenda setting and downstream data decisions that shape AI-mediated services.",
"Goetze, 2024","Goetze, T. S. (2024). AI Art is Theft: Labour, Extraction, and Exploitation: Or, On the Dangers of Stochastic Pollocks. The 2024 ACM Conference on Fairness, Accountability, and Transparency, 186–196. https://doi.org/10.1145/3630106.3658898","AI Art is Theft: Labour, Extraction, and Exploitation: Or, On the Dangers of Stochastic Pollocks",Extractive,Collecting vast amounts of data to train AI systems,Data practices,ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,ADC,A: critiques generative-image model training; D: argues web-scraped datasets appropriate artistic labor; C: articulates harms to creative workers and futures,"White (published journal papers, conference proceedings, books)",Database search,generative AI; art; extraction; labor,Not regionally specific,Academic,North America,"Cornell University, USA",,"Critically examines AI image generation’s reliance on mass-scraped art corpora, arguing this appropriates labor and devalues future creative work. Frames training-data practices as extractive and calls for remedies that recognize artists’ rights and sustain creative ecosystems.",
"Gray & Suri, 2019","Gray, M. L., & Suri, S. (2019). Ghost Work: How to Stop Silicon Valley from Building a New Global Underclass. Houghton Mifflin Harcourt.",Ghost Work: How to Stop Silicon Valley from Building a New Global Underclass,Extractive,Exploitative and invisible data labor,Data labor,ML System Design & Development,"Data Selection, Collection & Annotation",Multi-era,ADC,A: platform/policy remedies for AI supply chain; D: details annotation workflows & precarity; C: worker-centered reforms,"White (published journal papers, conference proceedings, books)","Existing networks, relevant organizations and conferences","ghost work, on-demand platforms, global labor economy",Multiple areas,Mixed,North America,"Harvard, MA, USA; Microsoft Research and Indiana University, IN, USA",,"Book arguing that the rapid rise of “ghost work,” meaning tasks performed online by invisible workers for companies like Amazon, Google, and Microsoft, is creating a new global underclass. The authors use anecdotes, data, and historical analysis to illustrate how the increasing reliance on on-demand platforms is eroding traditional employment structures and leaving workers vulnerable and exploited. They argue that this “algorithmic cruelty” is not just a technological issue but a social and economic one, demanding a reevaluation of how we think about work, labor rights, and the social contract between employers and employees. The authors advocate for a more worker-centered approach to platform design, including the creation of professional guilds to promote collaboration and advocacy. They also urge for policy changes that recognize the value of ghost work and provide workers with greater security and benefits, arguing that the future of work depends on a sustainable and ethical on-demand labor economy.",
"Grosfoguel, 2019","Grosfoguel, R. (2019). Epistemic Extractivism: A Dialogue with Alberto Acosta, Leanne Betasamosake Simpson, and Silvia Rivera Cusicanqui. In B. de S. Santos & M. Meneses (Eds.), Knowledges Born in the Struggle: Constructing the Epistemologies of the Global South (pp. 203–218). Routledge.","Epistemic Extractivism: A Dialogue with Alberto Acosta, Leanne Betasamosake Simpson, and Silvia Rivera Cusicanqui",Extractive,Other/NA (conceptual framing),Critical theory/Historical background,Problem Understanding & Formulation,Institutional Prioritization & Funding,Multi-era,C,A: none; D: critiques epistemic extraction as appropriation of Indigenous knowledge into Western frameworks; C: surfaces Indigenous and Global South perspectives on knowledge production.,"White (published journal papers, conference proceedings, books)",Database search,epistemic extractivism; indigenous knowledge; coloniality,Multiple areas,Academic,North America,"University of California, Berkeley, USA",,"Defines epistemic extractivism as appropriation of ideas without horizontal dialogue, subsuming Indigenous knowledge into Western frameworks. Through dialogue with Acosta, Simpson, and Rivera Cusicanqui, critiques historical and ongoing practices of intellectual colonization that limit knowledge diversity and sovereignty.",
"Groves et al., 2023","Groves, L., Peppin, A., Strait, A., & Brennan, J. (2023). Going public: The role of public participation approaches in commercial AI labs (No. arXiv:2306.09871). arXiv. https://doi.org/10.48550/arXiv.2306.09871",Going public: The role of public participation approaches in commercial AI labs,Practices less-extractive,Early co-design and participatory initiatives,"Data practices, Community impacts and relations",Cross-pipeline,Cross-pipeline,Era 3,ADC,A: examines participation in AI labs; D: surfaces organizational/process barriers to integrating input; C: assesses risks of tokenism and exploitation,"Grey (Reports, blogs, white papers, policy documents, theses, conference papers)",Database search,Multiple areas; public participation; commercial AI lab; barrier,Multiple areas,Mixed,EU/UK,"Ada Lovelace Institute, London, UK",,"Interviews industry practitioners on public participation in commercial AI labs. Finds interest but limited capability, incentives, and evidence, especially for general-purpose AI. Identifies cost, expertise, and pace as barriers. Shows how weak participation affects data and model decisions, limiting benefits for affected publics.",
"Guerrero Millan et al., 2024","Guerrero Millan, C., Nissen, B., & Pschetz, L. (2024). Cosmovision Of Data: An Indigenous Approach to Technologies for Self-Determination. Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems, 1–13. https://doi.org/10.1145/3613904.3642598",Cosmovision Of Data: An Indigenous Approach to Technologies for Self-Determination,Principles less-extractive,Decentering Western ontologies,"Community impacts and relations, Data practices",Problem Understanding & Formulation,Product Conception & Design,Multi-era,ADC,A: challenges standard AI framings by embedding Indigenous cosmovision; D: redefines data perception and use; C: advances community autonomy and self-determination,"White (published journal papers, conference proceedings, books)",Database search,"Mexico, indigenous data, cosmovision, sovereignty, community technology","LatAm (includes Central America, South America & Carribbean)",Academic,EU/UK,"Design Informatics, University of Edinburgh, UK",,"Fieldwork with Masewal collaborators examines existing and envisioned community technologies through “cosmovisión” lenses. Paper articulates micro/meso/macro frames linking individual practices, communal action, and world-making. Findings show communities appropriate technologies for autonomy and environmental relations. The authors offer design considerations that embed Indigenous epistemologies, repositioning data as relational and context-rich rather than abstract resource.",
"Hada et al., 2024","Hada, R., Husain, S., Gumma, V., Diddee, H., Yadavalli, A., Seth, A., Kulkarni, N., Gadiraju, U., Vashistha, A., Seshadri, V., & Bali, K. (2024). Akal Badi ya Bias: An Exploratory Study of Gender Bias in Hindi Language Technology. The 2024 ACM Conference on Fairness, Accountability, and Transparency, 1926–1939. https://doi.org/10.1145/3630106.3659017 ",Akal Badi ya Bias: An Exploratory Study of Gender Bias in Hindi Language Technology,Extractive,"""Deploying AI systems that lack local, contextual data""","Data practices, Community impacts and relations",ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,ADC,A: examines bias in NLP systems; D: evaluates annotation and data mining processes; C: involves rural women in identifying harms and needs,"White (published journal papers, conference proceedings, books)",Hand-searching key journals,"India, gender bias, crowdsourcing, annotation, Hindi",APAC (Asia-Pacific Region),Mixed,APAC (Asia-Pacific Region),"Microsoft Research, India","Karya; Carnegie Mellon University; University of Michigan; Delft University of Technology; Cornell University. Primary author in India; multi-institutional team including academia, labs, and industry","Study probes gender bias in Hindi NLP, showing limits of English-centric bias detection methods. Combining computational analysis with fieldwork, it engaged rural women annotators to surface culturally specific views of bias. Findings highlight context-dependent definitions of harm, need for inclusive workflows, and value of participatory approaches in multilingual AI.",
"Hadfield et al., 2023","Hadfield, G., Cuéllar, M.-F. (Tino), & O’Reilly, T. (2023). It’s Time to Create a National Registry for Large AI Models. Carnegie Endowment for International Peace. https://carnegieendowment.org/posts/2023/07/its-time-to-create-a-national-registry-for-large-ai-models 
",It’s Time to Create a National Registry for Large AI Models,Principles less-extractive,Building public visibility in dataset development,Ethics frameworks,Cross-pipeline,Cross-pipeline,Era 3,AD,A: argues for registries to govern large AI models; D: operationalizes transparency/publicness as part of model/data production; C: none (indirect implications),"Grey (Reports, blogs, white papers, policy documents, theses, conference papers)",Iterative keyword search,USA; AI registry; governance; transparency,North America,Mixed,North America,"University of Toronto and Vector Institute for Artificial Intelligence, Canada","Carnegie Endowment for International Peace, USA; O’Reilly Media and University College London's Institute for Innovation and Public Purpose, UK","Argues for a national registry of large AI models to provide basic transparency about who is training what, for whom, and with what risks. Frames registration as a minimal governance tool analogous to other regulated domains, enabling oversight without exposing IP. Emphasizes public visibility as the first step toward accountable AI ecosystems.",
"Hall et al., 2024","Hall, M., Bell, S. J., Ross, C., Williams, A., Drozdzal, M., & Soriano, A. R. (2024). Towards Geographic Inclusion in the Evaluation of Text-to-Image Models. Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency, 585–601. https://doi.org/10.1145/3630106.3658927",Towards Geographic Inclusion in the Evaluation of Text-to-Image Models,Practices less-extractive,"Creating culturally inclusive datasets, Community engaged data production","Data practices, Community impacts and relations",ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,ADC,A: evaluates T2I with cross-regional annotators; D: analyzes stereotype/appeal/helpfulness differences; C: calls for global annotation and coverage,"White (published journal papers, conference proceedings, books)",Database search,multiple regions; text-to-image; geographic inclusion; annotation,Multiple areas,Industry,North America,"Meta (FAIR), USA","Meta (FAIR), France and Canada; Mila, Canada and McGill University, Canada","Cross-cultural annotation in Africa, Europe, SE Asia (65k+ images; surveys) shows region-dependent judgments of stereotypes and usefulness. Argues evaluation must reflect diverse perspectives to avoid Global-North centric bias and to guide dataset/model adjustments.",
"Hall et al., 2025","Hall, S. M., Dalal, S., Sefala, R., Yuehgoh, F., Alaagib, A., Hamzaoui, I., Ishida, S., Magomere, J., Crais, L., Salama, A., & Afonja, T. (2025). The Human Labour of Data Work: Capturing Cultural Diversity through World Wide Dishes (No. arXiv:2502.05961). arXiv. https://arxiv.org/abs/2502.05961v1",The Human Labour of Data Work: Capturing Cultural Diversity through World Wide Dishes,Practices less-extractive,"Creating culturally inclusive datasets, Crowdsourcing data collection","Data practices, Community impacts and relations, Data labor",ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,ADC,"A: situates dataset for ML uses and evaluation; D: details participatory, crowdsourced collection and curation; C: foregrounds community contribution, cultural nuance, and data labour","White (published journal papers, conference proceedings, books)","Existing networks, relevant organizations and conferences",global; dataset; crowdsourcing; cultural representation; community engagement,Multiple areas,Academic,EU/UK,"University of Oxford, United Kingdom","University of Oxford, United Kingdom; University of Colorado Boulder, USA; DAIR Institute, Mila, McGill University, South Africa; Conservatoire National des Arts et Métiers (CNAM), France
AISHA ALAAGIB, Independent researcher, Sudan
IMANE HAMZAOUI, École nationale Supérieure d’Informatique Algiers, New York University Abu Dhabi, Algeria
SHU ISHIDA, University of Oxford, United Kingdom
JABEZ MAGOMERE, University of Oxford, United Kingdom
LAUREN CRAIS, University of Oxford, United Kingdom
AYA SALAMA, Microsoft Egypt, Egypt
TEJUMADE AFONJA, CISPA Helmholtz Center for Information Security & AI Saturdays Lagos, Germany & Nigeria","Looks at creation of a dataset for ML with a focus on cultural representation. The authors discuss their experience building the World Wide Dishes (WWD) dataset, which uses a participatory approach involving community members in designing the research and crowdsourcing data about culinary dishes. A core argument is that building diverse datasets requires significant, often invisible, human labor related to community engagement, accessibility, data production, and understanding cultural nuances. By analyzing their experiences, the authors aim to contribute to the computer-supported cooperative work (CSCW) literature and guide future participatory dataset construction efforts. They highlight that infrastructure and attention to the human processes behind data collection are crucial to representing cultural diversity in ML datasets and models.",
"Hancock et al., 2024","Hancock, J., Mahesh, S., Cobbe, J., Singh, J., & Mazumder, A. (2024). The tensions of data sharing for human rights: A modern slavery case study. The 2024 ACM Conference on Fairness, Accountability, and Transparency, 974–987. https://doi.org/10.1145/3630106.3658949",The tensions of data sharing for human rights: A modern slavery case study,Principles less-extractive,Participatory data ownership & governance,"Data practices, Community impacts and relations",ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,DC,A: none; D: examines data sharing practices in modern slavery context; C: analyzes impacts on vulnerable communities and marginalized groups,"Grey (Reports, blogs, white papers, policy documents, theses, conference papers)",Hand-searching key journals,"modern slavery, data sharing, human rights",EU/UK,NGO/Non-profit,EU/UK,"Alan Turing Institute, UK","University of Cambridge, UK","Investigates the unintended consequences of data sharing within the context of human rights, specifically focusing on efforts to combat modern slavery in the UK. While data sharing is often touted as a way to increase transparency and improve responses to human rights abuses, the authors argue that it can also lead to further harms. Through interviews, workshops, and analysis of the UK’s modern slavery data ecosystem, they uncover several concerns: legal uncertainties, a lack of transparency and accountability in data handling, and the potential for data misuse. The authors conclude by suggesting that these issues may be present in other human rights contexts where data sharing is utilized. They advocate for increased scrutiny of fairness, accountability, and transparency within these data ecosystems to ensure that vulnerable communities are not further marginalized.",
"Hanschke et al., 2024","Hanschke, V. A., Rees, D., Alanyali, M., Hopkinson, D., & Marshall, P. (2024). Data Ethics Emergency Drill: A Toolbox for Discussing Responsible AI for Industry Teams. Proceedings of the CHI Conference on Human Factors in Computing Systems, 1–17. https://doi.org/10.1145/3613904.3642402",Data Ethics Emergency Drill: A Toolbox for Discussing Responsible AI for Industry Teams,Principles less-extractive,Building public visibility in dataset development,Ethics frameworks,Problem Understanding & Formulation,Product Conception & Design,Era 3,AD,A: introduces a role-play toolbox (DEED) for AI teams; D: operationalizes ethics discussion in workflow; C: none (indirect implications),"White (published journal papers, conference proceedings, books)",Database search,ethics toolbox; industry team; role-play; reflection,Not regionally specific,Mixed,EU/UK,"University of Bristol, UK",,"Presents DEED, a role-play “ethical emergency” exercise tailored to teams’ contexts. Through studies with two industry data-science teams, shows how structured role-play surfaces risks, values, and trade-offs early in conception and design. Provides actionable materials that embed ethical reflection into everyday AI practice, improving visibility into potential data and model harms.",
"Hao & Hernandez, 2022","Hao, K., & Hernández, A. P. (2022, April 20). How the AI industry profits from catastrophe. MIT Technology Review. https://www.technologyreview.com/2022/04/20/1050392/ai-industry-appen-scale-data-labels/",How the AI industry profits from catastrophe,Extractive,Exploitative and invisible data labor,Data labor,ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,ADC,"A: limited; D: exposes crisis-driven, low-wage labeling supply chains; C: evidences harms to Venezuelan workers","Grey (Reports, blogs, white papers, policy documents, theses, conference papers)",Database search,"data labeling, Venezuela, context-case, data labor","LatAm (includes Central America, South America & Carribbean)",Journalist/Other/Not Sure,North America,"Journalist (publication in MIT technology review), USA",2nd author freelance journalist from Venezuela,"Investigates the exploitative labor practices within the AI industry, specifically data labeling. The authors focus on Venezuela, where economic collapse coincided with a surge in demand for low-cost data annotation, making the country a prime source of labor for companies like Scale AI and Appen. Through the story of Oskarina Fuentes Anaya, a Venezuelan data labeler, the article exposes the difficult working conditions, low pay, and lack of worker protections prevalent in the industry. Furthermore, it raises concerns about the industry's potential to repeat these exploitative patterns in other vulnerable countries seeking economic opportunity. ",
"Hao, 2022","Hao, K. (2022, April 22). A new vision of artificial intelligence for the people. MIT Technology Review. https://www.technologyreview.com/2022/04/22/1050394/artificial-intelligence-for-the-people/",A new vision of artificial intelligence for the people,Extractive,Prioritizing data wants over community needs,"Data practices, Community impacts and relations",ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,ADC,A: critiques scale-first AI incentives; D: profiles Te Hiku’s community-created language data; C: foregrounds Māori data sovereignty and benefit alignment,"Grey (Reports, blogs, white papers, policy documents, theses, conference papers)",Database search,Oceania; Māori language data; sovereignty; minority language benefit,Oceania,Journalist/Other/Not Sure,North America,"Journalist (publication in MIT technology review), USA",,"Reports how Te Hiku Media builds Māori language datasets through community recording and governance, rejecting “more data at any cost.” Shows how sovereignty contracts and local control counter extractive corporate offers, linking data production choices to culturally aligned AI tools and benefits for te reo Māori speakers.",
"Haraway, 1988","Haraway, D. (1988). Situated Knowledges: The Science Question in Feminism and the Privilege of Partial Perspective. Feminist Studies, 14(3), 575–599. https://doi.org/10.2307/3178066",Situated Knowledges: The Science Question in Feminism and the Privilege of Partial Perspective,Extractive,Other/NA (conceptual framing),"Community impacts and relations, Critical theory/Historical background",Cross-pipeline,Cross-pipeline,Multi-era,C,A: none; D: none (indirect implications); C: theorizes accountability and partial perspective shaping knowledge practices and authority.,"White (published journal papers, conference proceedings, books)","Existing networks, relevant organizations and conferences","North America, knowledge production, objectivity, accountability",North America,Academic,North America,"University of California, Santa Cruz, USA",,"Seminal critique of traditional notions of objectivity in science that argues against the idea of a detached, all-seeing perspective termed the ""god trick."" She contends that all knowledge is situated and embodied, meaning it arises from a particular viewpoint and experience, challenging the perceived neutrality of scientific inquiry. Advocates for a feminist objectivity that embraces partial perspectives and acknowledges the active agency of the world, rather than seeing it as a passive object for human manipulation. The approach encourages accountability in knowledge production and fosters a ""successor science"" built on connections, contestation, and the transformative potential of understanding the world from diverse, often subjugated, viewpoints.",
"Heeks & Shekhar, 2019","Heeks, R., & Shekhar, S. (2019). Datafication, development and marginalised urban communities: An applied data justice framework. Information, Communication & Society, 22(7), 992–1011. https://doi.org/10.1080/1369118X.2019.1599039 ","Datafication, development and marginalised urban communities: An applied data justice framework",Principles less-extractive,"Early co-design and participatory initiatives, Participatory data ownership & governance","Community impacts and relations, Data practices",ML System Design & Development,"Data Selection, Collection & Annotation",Multi-era,ADC,A: proposes applied data justice for development; D: analyzes community mapping projects and governance choices; C: centers marginalized urban communities’ visibility and risks,"White (published journal papers, conference proceedings, books)",Database search,India/Africa; community mapping; data justice; urban development,APAC (Asia-Pacific Region),Mixed,EU/UK,"University of Manchester, UK","Citizen Consumer and Civic Action Group, India","Examines the impact of datafication on urban development in the global South, specifically its effects on marginalized communities. The authors argue that while datafication initiatives offer potential benefits, they often exacerbate existing inequalities. They introduce a data justice framework to analyze four community mapping projects in Chennai, Nairobi, Pune, and Solo. These projects, aimed at making marginalized communities more visible in urban data, demonstrate both the potential and the limitations of data-driven initiatives. While some progress is observed in terms of resource allocation and policy changes, the authors caution that datafication can entrench existing power structures and further marginalize vulnerable communities unless carefully designed and implemented.",
"Held, 2019","Held, M. B. E. (2019). Decolonizing Research Paradigms in the Context of Settler Colonialism: An Unsettling, Mutual, and Collaborative Effort. International Journal of Qualitative Methods, 18, 1609406918821574. https://doi.org/10.1177/1609406918821574","Decolonizing Research Paradigms in the Context of Settler Colonialism: An Unsettling, Mutual, and Collaborative Effort.",Principles less-extractive,"Community engaged data production, Decentering Western ontologies",Critical theory/Historical background,Problem Understanding & Formulation,Institutional Prioritization & Funding,Multi-era,DC,A: none; D: articulates Indigenous paradigms and relational methodologies; C: urges collaborative multiparadigmatic frameworks,"White (published journal papers, conference proceedings, books)",Database search,North America; decolonizing methodologies; indigenous paradigms; relationality,North America,Academic,North America,"Dalhousie University, Canada",,"Argues that Indigenous research paradigms, methodologies, and worldviews deserve equal weight and consideration to their Western counterparts in academic research. The author begins by introducing the concept of a research paradigm, highlighting its impact on research methods and the need for inclusivity beyond Western frameworks. She then provides an overview of both Western and Indigenous research paradigms, emphasizing the importance of relationality in Indigenous approaches. The article argues that true decolonization of research necessitates a radical shift in the academic landscape, requiring a collaborative creation of new multiparadigmatic research frameworks developed in partnership between Western and Indigenous researchers.",
"Helm et al., 2024","Helm, P., Lipp, B., & Pujadas, R. (2024). Generating reality and silencing debate: Synthetic data as discursive device. Big Data & Society, 11(2), 20539517241249447. https://doi.org/10.1177/20539517241249447 
",Generating reality and silencing debate: Synthetic data as discursive device,Extractive,Reproducing biases through synthetic data generation,"Data practices, Community impacts and relations, Critical theory/Historical background",ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,ADC,A: discusses implications of synthetic data for AI systems; D: analyzes practices of generating and deploying synthetic datasets; C: highlights risks for communities when debate and accountability are foreclosed,"White (published journal papers, conference proceedings, books)",Database search,synthetic data; bias/privacy; platform economy,Not regionally specific,Academic,EU/UK,"Media Studies Department/Data Science Center, Critical Data & AI Studies Group, University of Amsterdam, Amsterdam, The Netherlands","Department of Technology, Management and Economics, Section of Human-Centered Innovation, Technical University of Denmark, Copenhagen, Denmark; Department of Science, Technology, Engineering, and Public Policy, University College London, London, UK
","In addition to tapping data from users’ behavioral surplus, by drawing on generative adversarial networks, data for artificial intelligence is now increasingly being generated through artificial intelligence. With this new method of producing data synthetically, the data economy is not only shifting from “data collection” to “data generation.” Synthetic data is also being employed to address some of the most pressing ethical concerns around artificial intelligence. It thereby comes with the sociotechnical imaginary that social problems can be cut out of artificial intelligence, separating training data from real persons. In response to this technical solutionism, this commentary aims to initiate a critical debate about synthetic data that goes beyond misuse scenarios such as the use of generative adversarial networks to create deep fakes or dark patterns. Instead, on a more general level, we seek to complicate the idea of “solving,” i.e., “closing” and thus “silencing” the ethico-political debates for which synthetic data is supposed to be a solution by showing how synthetic data itself is political. Drawing on the complex connections between recent uses of synthetic data and public debates about artificial intelligence, we therefore propose to consider and analyze synthetic data not only as a technical device but as a discursive one as well. To this end, we shed light on their relationship to three pillars that we see associated with them (a) algorithmic bias, (b) privacy, (c) platform economy.",
"Henry, 2025","Henry, J. (2025). Jazmiahenry/aave_corpora [Jupyter Notebook]. https://github.com/jazmiahenry/aave_corpora (Original work published 2021)",Jazmiahenry/aave_corpora,Practices less-extractive,Creating culturally inclusive datasets,Community impacts and relations,ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,ADC,"A: frames downstream NLP bias against AAVE; D: compiles AAVE corpus from lyrics, speeches, books, social media; C: aims to improve fairness for Black speaker","Grey (Reports, blogs, white papers, policy documents, theses, conference papers)",Iterative keyword search,North America; AAVE corpus; sentiment bias; Black community,North America,Academic,North America,"Stanford University, CA, USA",,"develops a corpus of African American Vernacular English (AAVE) to address its under-representation in NLP. The dataset draws on song lyrics, speeches, books, and social media, with spoken material transcribed into text. Findings highlight how current NLP systems misclassify or stigmatize AAVE, reproducing societal bias. By compiling authentic language use from Black speakers, the project provides a resource to improve fairness in downstream tasks like sentiment analysis and language modeling. This initiative links corpus construction to equity in AI data production, showing how culturally representative datasets can shift system behavior and reduce harms to marginalized communities.",
"Ho et al., 2022","Ho, M.-T., Mantello, P., Ghotbi, N., Nguyen, M.-H., Nguyen, H.-K. T., & Vuong, Q.-H. (2022). Rethinking technological acceptance in the age of emotional AI: Surveying Gen Z (Zoomer) attitudes toward non-conscious data collection. Technology in Society, 70, 102011. https://doi.org/10.1016/j.techsoc.2022.102011",Rethinking technological acceptance in the age of emotional AI: Surveying Gen Z (Zoomer) attitudes toward non-conscious data collection,Extractive,Collecting vast amounts of data to train AI systems,"Data practices, Community impacts and relations",Deployment & Impact,Product Testing,Era 3,ADC,A: studies emotional AI acceptance; D: analyzes non-conscious data collection practices; C: maps Gen Z attitudes and governance preferences,"White (published journal papers, conference proceedings, books)",Database search,emotional AI; non-conscious data collection; data governance; survey,Multiple areas,Academic,APAC (Asia-Pacific Region),"Ritsumeikan Asia Pacific University, Beppu, Oita, Japan","Ritsumeikan Asia Pacific University, Beppu, Oita, Japan; Centre for Interdisciplinary Social Research, Phenikaa University, Yen Nghia Ward,  Ha Dong District, Hanoi; Institute of Philosophy, Vietnam Academy of Social Sciences, Lang Ha, Ba Dinh, Hanoi, Vietnam","Surveys 1,015 Gen Z students from 48 countries on acceptance of non-conscious data collection in emotional AI. Uses demographic and cultural predictors to model attitudes toward private versus governmental use. Finds heterogeneous acceptance and highlights gender, income, religion, and region effects. Argues existing acceptance models overlook sociocultural context. Links emotional-sensing data practices to governance needs that safeguard autonomy and reduce misuse affecting young users.",
"Hofmann et al., 2024","Hofmann, V., Kalluri, P. R., Jurafsky, D., & King, S. (2024). AI generates covertly racist decisions about people based on their dialect. Nature, 633(8028), 147–154. https://doi.org/10.1038/s41586-024-07856-5",AI generates covertly racist decisions about people based on their dialect,Extractive,"""Deploying AI systems that lack local, contextual data""","Data practices, Community impacts and relations",ML System Design & Development,Model Training & Evaluation,Era 3,AD,A: tests model inferences and decisions; D: none (indirect implications) regarding training workflows; C: shows harms to African American English speakers,"White (published journal papers, conference proceedings, books)",Database search,"North America, dialect bias, African American English, covert racism",North America,Mixed,North America,"Allen Institute for AI, Seattle, WA, USA
University of Oxford, Oxford, UK
LMU Munich, Munich, Germany",,"Shows LLMs encode covert racism in dialect judgments, especially toward African American English (AAE). Finds models predict more negative outcomes for AAE speakers than any human stereotype recorded, e.g., associating them with crime or lower-status jobs. Reveals alignment practices obscure bias rather than mitigate it, exacerbating systemic harms.",
"Holland et al., 2018","Holland, S., Hosny, A., Newman, S., Joseph, J., & Chmielinski, K. (2018). The Dataset Nutrition Label: A Framework To Drive Higher Data Quality Standards (No. arXiv:1805.03677). arXiv. https://doi.org/10.48550/arXiv.1805.03677 
",The Dataset Nutrition Label: A Framework To Drive Higher Data Quality Standards,Practices less-extractive,Building public visibility in dataset development,Data practices,ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,AD,A: proposes pre-model dataset “label” artifact; D: specifies modular analyses to standardize dataset review; C: none (indirect implications),"Grey (Reports, blogs, white papers, policy documents, theses, conference papers)",Database search,dataset nutrition label; diagnostic module; provenance,Not regionally specific,Mixed,North America,"Assembly, MIT Media Lab and Berkman Klein Center at Harvard University; Dana-Farber Cancer Institute, Harvard Medical School, USA","metaLAB (at) Harvard, Berkman Klein Center for Internet & Society, Harvard University, USA. First 2 authors contributed equally","Introduces a standardized, modular “nutrition label” to summarize dataset characteristics before modeling. Demonstrates an open-source prototype on ProPublica’s Dollars for Docs, arguing that consistent, visible pre-model checks raise data quality, help select appropriate datasets, and create expectations for documentation among data publishers.",
"Hong, 2023","Hong, S. (2023). Prediction as extraction of discretion. Big Data & Society, 10(1), 20539517231171053. https://doi.org/10.1177/20539517231171053",Prediction as extraction of discretion,Extractive,"Exploitative and invisible data labor, Biased pre-processing and category erasure",Critical theory/Historical background,Problem Understanding & Formulation,Product Conception & Design,Era 3,AC,A: analyzes predictive systems as power extraction mechanisms; D: none; C: examines impacts on employees and urban citizens through discretion redistribution,"White (published journal papers, conference proceedings, books)",Database search,"predictive systems, discretion extraction, power dynamics",Not regionally specific,Academic,North America,"Simon Fraser University, Canada",,"Argues that prediction is not primarily a technological means for knowing future outcomes, but a social model for extracting and concentrating discretionary power. Prediction is a ‘relational grammar’ that governs this allocation of discretion: the everyday ability to define one's situation. This extractive dynamic extends a long historical pattern, in which new methods for producing knowledge entail a redistribution of decision-making power. I focus on two contemporary domains: (1) crime and policing are emblematic of how predictive systems are extractive by design, with pre-existing interests governing what is measured and what persistently goes unmeasured. (2) The prediction of productivity demonstrates the long tradition of extracting discretion as a means to extract labour power. Time after time, making human behaviour more predictable for the client of prediction (the manager, the police officer) often means making life and work more unpredictable for the target of prediction (the employee, the urban citizen).",
"Hovy & Spruit, 2016","Hovy, D., & Spruit, S. L. (2016). The Social Impact of Natural Language Processing. In K. Erk & N. A. Smith (Eds.), Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers) (pp. 591–598). Association for Computational Linguistics. https://doi.org/10.18653/v1/P16-2096",The Social Impact of Natural Language Processing,Extractive,Collecting vast amounts of data to train AI systems,"Data practices, Community impacts and relations",ML System Design & Development,"Data Selection, Collection & Annotation",Era 2,ADC,A: positions NLP applications as socially consequential; D: discusses shifts to social-media data and related risks; C: outlines harms and mitigation avenues,"White (published journal papers, conference proceedings, books)",Database search,NLP; social impact; ethics; social media data,Not regionally specific,Academic,EU/UK,"University of Copenhagen,
Copenhagen, Denmark",,"Position paper identifying social implications as NLP moves from anonymous corpora to user-generated data. Catalogs risks such as privacy loss, discrimination, and feedback loops, and sketches responses through better data selection, consent, and evaluation. Connects corpus decisions to lived consequences for users whose language becomes training material, urging field-level discourse and practice change.",
"Huang & Siddarth, 2023 ","Huang, S., & Siddarth, D. (2023). Generative AI and the Digital Commons (No. arXiv:2303.11074). arXiv. https://doi.org/10.48550/arXiv.2303.11074",Generative AI and the Digital Commons,Extractive,Collecting vast amounts of data to train AI systems,Data practices,Problem Understanding & Formulation,Institutional Prioritization & Funding,Era 3,ADC,A: frames governance of foundation models; D: treats data as a central lever for stewarding the digital commons; C: none (indirect implications),"Grey (Reports, blogs, white papers, policy documents, theses, conference papers)",Citation/reference snowballing,GenAI; digital commons; data governance; training data,Not regionally specific,Industry,North America,"Collective Intelligence Project, USA",,Conceptual paper arguing data is a high-leverage governance point for foundation models trained on publicly available content. Warns that model training can degrade the digital commons while failing to return value to data producers. Outlines information needs and governance directions that prioritize broad benefit over unilateral extraction.,
"Huerta et al., 2023","Huerta, E. A., Blaiszik, B., Brinson, L. C., Bouchard, K. E., Diaz, D., Doglioni, C., Duarte, J. M., Emani, M., Foster, I., Fox, G., Harris, P., Heinrich, L., Jha, S., Katz, D. S., Kindratenko, V., Kirkpatrick, C. R., Lassila-Perini, K., Madduri, R. K., Neubauer, M. S., … Zhu, R. (2023). FAIR for AI: An interdisciplinary and international community building perspective. Scientific Data, 10(1), 487. https://doi.org/10.1038/s41597-023-02298-6 
",FAIR for AI: An interdisciplinary and international community building perspective,Principles less-extractive,Building public visibility in dataset development,"Data practices, Ethics frameworks",ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,AD,A: extends FAIR to AI contexts; D: shares community practices and incentives for FAIR uptake; C: none (indirect implications),"White (published journal papers, conference proceedings, books)",Database search,FAIR; stewardship; reuse; community building,Multiple areas,Mixed,North America,"Data Science and Learning Division, Argonne National Laboratory, USA","Department of Computer Science, University of Chicago, Chicago, Illinois; Globus, University of Chicago, Chicago, Illinois; Department of Mechanical Engineering and Materials Science, Duke University, Durham, North Carolina, USA; Scientific Data Division, Lawrence Berkeley National Laboratory, Berkeley, CA, USA; Biological Systems & Engineering, Lawrence Berkeley National Laboratory, Berkeley, California, USA; Helen Wills Neuroscience Institute, University of California Berkeley, Berkeley, California, USA; Department of Physics, University of California San Diego, La Jolla, California, 92093, USA; Lund University, Department of Physics, Box 118, 221 00, Lund, Sweden; School of Physics & Astronomy, The University of Manchester, Manchester, M13 9PL, UK; Leadership Computing Facility, Argonne National Laboratory, Lemont, Illinois, 60439, USA; Biocomplexity Institute and Department of Computer Science, University of Virginia, Charlottesville, Virginia, 22904, USA; Department of Physics, Massachusetts Institute of Technology, Cambridge, Massachusetts, 02139, USA; Technical University Munich, Arcisstraβe 21, 80333, München, Germany; Computational Science Initiative Brookhaven National Laboratory Upton, New York, 11973, USA; Electrical and Computer Engineering, Rutgers, The State University of New Jersey, Piscataway, New Jersey, 08854, USA; National Center for Supercomputing Applications, University of Illinois, Urbana-Champaign, Urbana, Illinois, 61801, USA; Department of Computer Science, University of Illinois at Urbana-Champaign, Urbana, Illinois, 61801, USA; Department of Electrical & Computer Engineering, University of Illinois at Urbana-Champaign, Urbana, Illinois, 61801, USA; School of Information Sciences, University of Illinois at Urbana-Champaign, Urbana, Illinois, 61801, USA; San Diego Supercomputer Center, University of California San Diego, La Jolla, California, 92093, USA; Helsinki Institute of Physics, University of Helsinki, P.O. Box 64, Helsinki, 00014, Finland; Department of Physics, University of Illinois at Urbana-Champaign, Urbana, Illinois, 61801, USA; Institute of Applied Biosciences, Centre for Research and Technology Hellas, Thessaloniki, 57001, Greece","Synthesizes international perspectives on adapting FAIR (Findable, Accessible, Interoperable, Reusable) to AI datasets and models. Draws on a 2022 FAIR for AI workshop and community efforts, outlining practices, tooling, and incentives to improve discoverability, stewardship, and reuse. Frames FAIR as socio-technical infrastructure supporting transparency across AI data lifecycles.",
"Hutchinson & Mitchell, 2019","Hutchinson, B., & Mitchell, M. (2019). 50 Years of Test (Un)fairness: Lessons for Machine Learning. Proceedings of the Conference on Fairness, Accountability, and Transparency, 49–58. https://doi.org/10.1145/3287560.3287600",50 Years of Test (Un)fairness: Lessons for Machine Learning,Extractive,Keeping communities in the dark through opaque data practices,Data practices,ML System Design & Development,Model Training & Evaluation,Multi-era,AD,A: traces fairness definitions in machine learning research; D: examines measurement methods and criteria across testing communities; C: none (indirect implications),"White (published journal papers, conference proceedings, books)",Database search,"algorithmic fairness, testing communities, measurement",Not regionally specific,Industry,North America,"Google, USA",,"Traces fairness definitions across education, hiring, and machine learning over 50 years. Compares historical and current fairness notions along criteria, focus, relationship to groups, and mathematical methods. Identifies overlooked insights from past fairness research that could inform current machine learning approaches to measuring and addressing unfairness.",
"Hutchinson et al., 2021","Hutchinson, B., Smart, A., Hanna, A., Denton, E., Greer, C., Kjartansson, O., Barnes, P., & Mitchell, M. (2021). Towards Accountability for Machine Learning Datasets: Practices from Software Engineering and Infrastructure. Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency, 560–575. https://doi.org/10.1145/3442188.3445918 ",Towards Accountability for Machine Learning Datasets: Practices from Software Engineering and Infrastructure,Principles less-extractive,Building public visibility in dataset development,Data practices,ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,AD,"A: reframes datasets as infrastructure; D: adapts software lifecycle practices (requirements, testing, maintenance) to datasets; C: none (indirect implications)","White (published journal papers, conference proceedings, books)",Database search,dataset accountability; lifecycle; engineering practice,Not regionally specific,Industry,North America,"Google, USA",,"Treats datasets as engineered infrastructure and maps accountability practices from software engineering—requirements capture, design decisions, testing, and maintenance—to dataset development. Aims to make data work legible, auditable, and durable, thereby reducing downstream harms from opaque or neglected dataset processes.",
"Hutchinson, 2025","Hutchinson, B. (2025). Modeling the Sacred: Considerations when Using Religious Texts in Natural Language Processing (No. arXiv:2404.14740). arXiv. https://doi.org/10.48550/arXiv.2404.14740",Modeling the Sacred: Considerations when Using Religious Texts in Natural Language Processing,Extractive,Scraping or repurposing sensitive data,"Data practices, Community impacts and relations",ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,ADC,"A: analyzes NLP applications using religious texts; D: examines data provenance and cultural context considerations; C: addresses potential harm to religious communities, particularly marginalized ones","Grey (Reports, blogs, white papers, policy documents, theses, conference papers)","Existing networks, relevant organizations and conferences","religious texts, NLP, cultural sensitivity",Multiple areas,Industry,Oceania,"Google Research, Australia",,"Addresses ethical considerations when using sacred texts in NLP research. Argues researchers often overlook religious dimensions and cultural contexts despite widespread use of texts like Bible and Quran. Identifies concerns including data provenance, cultural contexts, and potential for harmful applications in proselytism affecting marginalized religious communities.",
"Hutterer and Krumay, 2024","Hutterer, A., & Krumay, B. (2024). The adoption of data spaces: Drivers toward federated data sharing. Hawaii International Conference on System Sciences. https://doi.org/10.24251/HICSS.2024.542 
",The adoption of data spaces: Drivers toward federated data sharing,Practices less-extractive,Developing federated data spaces,Data practices,ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,DC,"A: none (general data-sharing); D: identifies 12 drivers for federated, interoperable data spaces; C: notes ecosystem benefits but not community-specific","White (published journal papers, conference proceedings, books)",Database search,EU; federated data spaces; interoperability; adoption drivers,Not regionally specific,Academic,EU/UK,"Johannes Kepler University Linz, Austria",,"Reports expert-elicited drivers (technical, organizational, legal, economic) shaping adoption of interoperable data spaces. Argues that holistic incentives, trust mechanisms, and governance are as crucial as technology. Offers actionable considerations for building federated sharing that could underpin less-extractive AI data pipelines without centralizing control.",
"Igwe et al., 2022","Igwe, P. A., Madichie, N. O., & Rugara, D. G. (2022). Decolonising research approaches towards non-extractive research. Qualitative Market Research: An International Journal, 25(4), 453–468. https://doi.org/10.1108/QMR-11-2021-0135",Decolonising research approaches towards non-extractive research,Principles less-extractive,Decentering Western ontologies,Critical theory/Historical background,Problem Understanding & Formulation,Product Conception & Design,Multi-era,C,A: none; D: critiques dominance of Western frameworks in research design; C: centers community-based participatory and decolonial ethics as non-extractive practice.,"White (published journal papers, conference proceedings, books)",Database search,research ethics; participatory research; decolonial practice,Not regionally specific,Academic,EU/UK,"University of Lincoln, UK","University of Kigali, Rwanda","Critiques Western-dominant research ethics that marginalize Indigenous knowledge. Integrates CBPR with six principles—respect, relevance, reciprocity, responsibility, relationships, relationality—to guide non-extractive practice. Offers a pragmatic model for reorienting research design toward community authority and ongoing accountability",
"Inel et al., 2023","Inel, O., Draws, T., & Aroyo, L. (2023). Collect, Measure, Repeat: Reliability Factors for Responsible AI Data Collection. Proceedings of the AAAI Conference on Human Computation and Crowdsourcing, 11(1), Article 1. https://doi.org/10.1609/hcomp.v11i1.27547","Collect, Measure, Repeat: Reliability Factors for Responsible AI Data Collection",Practices less-extractive,Building public visibility in dataset development,"Data practices, Ethics frameworks",ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,AD,A: recommends repeated collection with reliability metrics; D: operationalizes agreement/variability/stability over time; C: none (indirect implications),"White (published journal papers, conference proceedings, books)",Database search,reliability; repeated collection; rater agreement; dataset stability,Not regionally specific,Mixed,EU/UK,"University of Zurich, Switzerland","Delft University Netherlands; Google, USA","Critiques one-off data collection and proposes repeating collection with metrics for rater agreement, variability, and temporal stability. Validates the approach across nine datasets, showing how visibility into reliability factors supports more robust, fairer data for critical AI applications.",
"Inie et al., 2023","Inie, N., Falk, J., & Tanimoto, S. (2023). Designing Participatory AI: Creative Professionals’ Worries and Expectations about Generative AI (No. arXiv:2303.08931). arXiv. https://doi.org/10.48550/arXiv.2303.08931",Designing Participatory AI: Creative Professionals’ Worries and Expectations about Generative AI ,Principles less-extractive,Early co-design and participatory initiatives,Community impacts and relations,Problem Understanding & Formulation,Product Conception & Design,Era 3,AC,"A: probes generative AI expectations/risks; D: none (indirect implications); C: centers creatives’ concerns, roles, and needed safeguards","Grey (Reports, blogs, white papers, policy documents, theses, conference papers)",Database search,multiple areas; participatory AI; generative AI; creative work,Multiple areas,Academic,EU/UK,"IT University of Copenhagen, Denmark","University of Salzburg, Austria; University of Washington, USA","Surveys creative professionals about generative AI. Documents excitement and worry: productivity and inspiration vs. job loss, copyright, and dilution of craft. Advocates participatory design so creatives shape tool goals and guardrails. Links participation to upstream data and model choices impacting creative livelihoods.",
"Iqbal et al., 2023","Iqbal, U., Bahrami, P. N., Trimananda, R., Cui, H., Gamero-Garrido, A., Dubois, D., Choffnes, D., Markopoulou, A., Roesner, F., & Shafiq, Z. (2023). Tracking, Profiling, and Ad Targeting in the Alexa Echo Smart Speaker Ecosystem. Proceedings of the 2023 ACM on Internet Measurement Conference, 569–583. https://doi.org/10.1145/3618257.3624803","Tracking, Profiling, and Ad Targeting in the Alexa Echo Smart Speaker Ecosystem",Extractive,Collecting vast amounts of data to train AI systems,Data practices,Deployment & Impact,Product Testing,Era 3,AD,A: audits AI-enabled voice ecosystem; D: reveals first-party and third-party data flows and ad targeting; C: none (indirect implications),"White (published journal papers, conference proceedings, books)",Iterative keyword search,"smart speaker ecosystem, data collection, ads",Not regionally specific,Academic,North America,"Washington University in St. Louis, USA","University of California, Davis; University of California, Irvine; Northeastern University; University of Washington, USA","Builds an active-measurement audit of Alexa’s ecosystem using simulated profiles, traffic capture, and ad analysis. Finds Amazon and skills collect voice and interaction data to infer interests and target ads. Notes disclosures lag practice and third-party policies are opaque. Recommends stronger transparency, policy compliance, and user control given the sensitivity of voice data in domestic settings.",
"Iyer et al., 2021","Iyer, N., Chair, C., & Garnett, A. (2021). Afrofeminist Data Futures. Pollicy. https://archive.pollicy.org/feministdata/ 
",Afrofeminist Data Futures,Principles less-extractive,Building public visibility in dataset development,"Ethics frameworks, Critical theory/Historical background",Problem Understanding & Formulation,Product Conception & Design,Era 3,ADC,A: considers digital data’s implications for AI and justice; D: identifies gaps in data literacy and governance; C: centers African feminist movements for equitable data,"White (published journal papers, conference proceedings, books)",Database search,"feminism, feminist AI",Africa,NGO/Non-profit,Africa,"Pollicy, Uganda",supported and commissioned by Facebook,"Outlines how African feminist movements mobilize digital data for social justice while facing deficits in literacy, infrastructure, and gender-disaggregated data. Calls for ethical, transparent practices aligned with feminist principles, linking governance and capacity to inclusive AI data production that serves marginalized groups.",
"Iyer et al., 2021","Iyer, N., Achieng, G., Borokini, F., Ludger, U., Iyer, N., Syabani, Y., & Syabani, Y. (2021). Automated Imperialism, Expansionist Dreams: Exploring Digital Extractivism in Africa. https://archive.pollicy.org/digitalextractivism/","Automated Imperialism, Expansionist Dreams: Exploring Digital Extractivism in Africa",Extractive,Soliciting data without reciprocal benefits,"Data practices, Community impacts and relations",Problem Understanding & Formulation,Institutional Prioritization & Funding,Era 3,AC,A: none; D: critiques dominance of Western frameworks in research design; C: centers decolonial ethics and community-based participatory approaches.,"Grey (Reports, blogs, white papers, policy documents, theses, conference papers)",Database search,Africa; digital extractivism; labor; funding; governance,Africa,NGO/Non-profit,Africa,"Pollicy, Uganda","Work also funded by On, Omidyar Network, and Stanford PACS center on philanthropy and civil society","Explores how platform firms and partners extract African data and labor under weak regulation and inequitable funding. Through cases (e.g., Free Basics, moderation), details consent gaps, precarious work, and externalized harms. Positions governance and capacity as prerequisites to counter extractive AI data production",
"Iyer, 2022","Iyer, N. (2022, August 15). Digital Extractivism in Africa Mirrors Colonial Practices. https://hai.stanford.edu/news/neema-iyer-digital-extractivism-africa-mirrors-colonial-practices",Digital Extractivism in Africa Mirrors Colonial Practices,Extractive,Excluding underrepresented groups from decision-making,"Data practices, Community impacts and relations",Problem Understanding & Formulation,Institutional Prioritization & Funding,Era 3,ADC,"A: critiques AI/data industry models shaping platforms and policy; D: describes extraction of labor and data; C: centers African sovereignty, rights, and benefit-sharing","Grey (Reports, blogs, white papers, policy documents, theses, conference papers)",Database search,"Africa, digital extractivism, governance, sovereignty",Africa,Academic,Africa,"Pollicy; Stanford Pacs, USA",,"Focuses on the concept of digital extractivism, which she argues mirrors colonial-era exploitation by prioritizing wealth accumulation over ethical considerations. This modern form of extraction, facilitated by technology and borderless capitalism, manifests in various ways, including exploitative labor practices, data harvesting without consent, and the dominance of foreign tech companies in Africa. Iyer draws parallels between digital extractivism and historical extraction of resources like diamonds and agricultural products, both of which have resulted in lasting economic disparities. She advocates for policy solutions like strengthening consumer rights and establishing digital sovereignty through frameworks like the African Continental Free Trade Area and the Malabo Convention. Iyer calls for developers to prioritize ethical AI design and equitable technological advancement to disrupt the cycle of exploitation and foster a future where technology benefits all.",
"James, 1989","James, C. L. R. (1989). The black Jacobins: Toussaint l’Ouverture and the San Domingo revolution (2. ed., rev). Vintage Books, a Division of Random House, Inc.",The black Jacobins: Toussaint l’Ouverture and the San Domingo revolution,Principles less-extractive,Other/NA (conceptual framing),Critical theory/Historical background,Cross-pipeline,Cross-pipeline,Multi-era,C,A: none; D: none; C: Haitian revolution as collective resistance to extractive systems,"White (published journal papers, conference proceedings, books)","Existing networks, relevant organizations and conferences","San Domingo/Haiti, slavery, colonialism","LatAm (includes Central America, South America & Carribbean)",Journalist/Other/Not Sure,"LatAm (includes Central America, South America & Carribbean)","Independent, Trinidadian-British",,"Historical account of the Haitian Revolution, the first successful slave uprising, which overthrew French colonial rule. James situates the rebellion as a foundational act of resistance against systems of extraction, slavery, and empire. Provides critical historical grounding for later analyses of colonial economies and their legacies in knowledge and resource production.",
"Jha et al., 2023","Jha, A., Prabhakaran, V., Denton, R., Laszlo, S., Dave, S., Qadri, R., Reddy, C., & Dev, S. (2024). ViSAGe: A Global-Scale Analysis of Visual Stereotypes in Text-to-Image Generation. In L.-W. Ku, A. Martins, & V. Srikumar (Eds.), Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) (pp. 12333–12347). Association for Computational Linguistics. https://aclanthology.org/2024.acl-long.667",ViSAGe: A Global-Scale Analysis of Visual Stereotypes in Text-to-Image Generation,Practices less-extractive,Creating culturally inclusive datasets,"Community impacts and relations, Data practices",ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,ADC,A: evaluates T2I stereotyping globally; D: introduces ViSAGe with 135 nationalities; C: reveals disproportionate harms for Global South groups,"White (published journal papers, conference proceedings, books)",Hand-searching key journals,multiple areas; T2I; visual stereotype dataset; global coverage,Multiple areas,Mixed,North America,"Virginia Tech, USA",,"Shows T2I systems overproduce stereotypical attributes, especially for Africa, South America, Southeast Asia. Quantifies “stereotypical pull” even under neutral prompts. Provides ViSAGe to benchmark and study visual stereotypes with global coverage.",
"Jimerson et al., 2023","Jimerson, R., Liu, Z., & Prud’hommeaux, E. (2023). An (unhelpful) guide to selecting the best ASR architecture for your under-resourced language. In A. Rogers, J. Boyd-Graber, & N. Okazaki (Eds.), Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers) (pp. 1008–1016). Association for Computational Linguistics. https://doi.org/10.18653/v1/2023.acl-short.87 
",An (unhelpful) guide to selecting the best ASR architecture for your under-resourced language,Practices less-extractive,"Community engaged data production, Creating culturally inclusive datasets","Community impacts and relations, Data practices",ML System Design & Development,Model Architecture Selection & Design,Era 3,ADC,A: evaluates ASR architectures across under-resourced languages; D: none (architecture selection focus); C: informs communities facing data scarcity to make pragmatic trade-offs,"White (published journal papers, conference proceedings, books)",Database search,North America; ASR architecture; low-resource language; endangerment,North America,Academic,North America,"Rochester Institute of Technology, USA","University of Florida, Boston College, USA","Evaluates four leading ASR toolkits across 11 under-resourced and endangered languages. The authors systematically train and compare models, finding no single architecture consistently outperforms others. Results suggest that data quantity and quality, rather than model choice, drive performance differences. The study concludes that communities with greater media resources should prioritize data collection, while endangered language communities should experiment with multiple architectures to maximize limited data. These findings link model design to the realities of low-resource contexts, illustrating how careful technical decision-making can support more inclusive AI data production and language preservation.",
"Jing et al., 2023","Jing, F. S., Berger, S. E., & Becerra Sandoval, J. C. (2023). Towards Labor Transparency in Situated Computational Systems Impact Research. Proceedings of the 2023 ACM Conference on Fairness, Accountability, and Transparency, 1026–1037. https://doi.org/10.1145/3593013.3594060",Towards Labor Transparency in Situated Computational Systems Impact Research,Extractive,Exploitative and invisible data labor,"Data labor, Community impacts and relations",Deployment & Impact,Product Testing,Era 3,ADC,A: reframes impact studies’ processes; D: proposes labor documentation schema affecting data collection; C: treats participants as workers,"White (published journal papers, conference proceedings, books)",Iterative keyword search,"participatory research critique, framework, participants as workers, research practices, transparent documentation",Not regionally specific,Industry,North America,"Responsible & Inclusive Technologies, IBM Research, USA and Department of Political Science, Johns Hopkins University, USA",,"Critiques the rising trend of incorporating participatory research in the tech industry, particularly concerning its potential for exploiting communities. The authors argue that the emphasis on “diversity and inclusion” often masks exploitative labor relationships between researchers and participants. Using their experience developing the Responsible and Inclusive Technology Participatory Initiative (RITPI), they expose how corporate settings can prioritize profit and reputation over equitable collaboration. The authors urge researchers to recognize participants as laboring subjects and advocate for transparent documentation of labor divisions in research projects. They propose practical strategies, like a labor documentation schema and provocations for labor-sensitive collaborations, to foster more equitable research practices that recognize and value the contributions of participants.",
"Jing et al., 2024","Jing, F. S., Berger, S. E., Becerra Sandoval, J. C., Pepper, K., Wheeler, A. M., Mayoral, P. R., Lokesh, D., Feng, A., Mijalkovic, M., Bao, C., Dholakia, S., & Goyal, M. (2024). Designing for Agonism: 12 Workers’ Perspectives on Contesting Technology Futures. Proc. ACM Hum.-Comput. Interact., 8(CSCW1), 162:1-162:25. https://doi.org/10.1145/3641001",Designing for Agonism: 12 Workers’ Perspectives on Contesting Technology Futures,Principles less-extractive,Early co-design and participatory initiatives,"Ethics frameworks, Community impacts and relations",Problem Understanding & Formulation,Product Conception & Design,Era 3,AC,A: surfaces worker perspectives on AI/tech futures; D: none; C: community/worker concerns about surveillance & harm,"White (published journal papers, conference proceedings, books)",Hand-searching key journals,"North America, worker voices, agonism, participatory design",Not regionally specific,Industry,North America,"IBM, USA","IBM Research, USA; IBM India, Canada, NL","Proposes “designing for agonism,” a worker-authored approach that treats disagreement and friction as productive in early-stage design. Through speculative and deconstructive probes, participants interrogate AI, voice analysis, and neurotech, raising concrete worries about surveillance and inequality. Provides tactics to embed contestation and plural perspectives into participatory processes, linking internal deliberation to more accountable, community-aware technology development.",
"Jo & Gebru, 2020","Jo, E. S., & Gebru, T. (2020). Lessons from archives: Strategies for collecting sociocultural data in machine learning. Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency, 306–316. https://doi.org/10.1145/3351095.3372829",Lessons from archives: Strategies for collecting sociocultural data in machine learning,Principles less-extractive,Building public visibility in dataset development,Data practices,ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,ADC,"A: draws guidelines for sociocultural ML data; D: adapts archival practices (consent, power, inclusivity, transparency, privacy); C: centers communities whose data are collected","White (published journal papers, conference proceedings, books)",Database search,sociocultural dataset; archival method; consent; power,Not regionally specific,Mixed,North America,"Stanford University, USA","Google, USA","Argues ML needs a specialization for sociocultural data collection grounded in archival science. Transfers five archival approaches—consent, power, inclusivity, transparency, privacy—into practical guidance for dataset creation and annotation. Positions communities as stakeholders, improving documentation and ethics while making collection decisions legible and accountable.",
"Junker, 2024","Junker, M.-O. (2024). Data-mining and Extraction: The gold rush of AI on Indigenous Languages. In S. Moeller, G. Agyapong, A. Arppe, A. Chaudhary, S. Rijhwani, C. Cox, R. Henke, A. Palmer, D. Rosenblum, & L. Schwartz (Eds.), Proceedings of the Seventh Workshop on the Use of Computational Methods in the Study of Endangered Languages (pp. 52–57). Association for Computational Linguistics. https://aclanthology.org/2024.computel-1.8",The gold rush of AI on Indigenous Languages,Extractive,"Scraping or repurposing sensitive data, Prioritizing data wants over community needs","Data practices, Community impacts and relations",ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,ADC,A: analyzes AI applications to Indigenous language preservation; D: examines data mining and extraction practices; C: identifies impacts on Indigenous communities through digital colonialism,"White (published journal papers, conference proceedings, books)","Existing networks, relevant organizations and conferences","Indigenous languages, data mining, digital colonialism",North America,Academic,North America,"Carleton University, Canada",,"Raises ethical concerns about the use of AI in the preservation of Indigenous languages, particularly within the context of the Algonquian Dictionaries and Language Resources project. Junker highlights the growing trend of data mining and extraction of Indigenous language data without proper consent or acknowledgment. Presents 3 case studies, ranging from a well-intentioned but ultimately denied data request to an instance of data extraction without permission and a commercial entity profiting from the repackaging of Indigenous language data. Junker argues that such practices can perpetuate a form of “digital colonialism,” exploiting Indigenous language resources for commercial gain or academic advancement without considering the potential harms.",
"Kabra et al., 2023","Kabra, A., Liu, E., Khanuja, S., Aji, A. F., Winata, G., Cahyawijaya, S., Aremu, A., Ogayo, P., & Neubig, G. (2023). Multi-lingual and Multi-cultural Figurative Language Understanding. In A. Rogers, J. Boyd-Graber, & N. Okazaki (Eds.), Findings of the Association for Computational Linguistics: ACL 2023 (pp. 8269–8284). Association for Computational Linguistics. https://doi.org/10.18653/v1/2023.findings-acl.525 
",Multi-lingual and Multi-cultural Figurative Language Understanding,Practices less-extractive,Creating culturally inclusive datasets,"Data practices, Community impacts and relations",ML System Design & Development,Model Training & Evaluation,Era 3,ADC,A: benchmarks figurative language across 7 languages; D: builds culturally grounded inference dataset; C: exposes inequities relative to English,"White (published journal papers, conference proceedings, books)",Database search,multiple areas; figurative language; multilingual dataset; cultural context,Multiple areas,Mixed,North America,"Carnegie Mellon University, USA","Carnegie Mellon University; MBZUAI, UAE; Bloomberg; HKUST; Masakhane, Africa","Creates a figurative-language inference dataset for Hindi, Indonesian, Javanese, Kannada, Sundanese, Swahili, Yoruba. Finds multilingual LMs underperform vs. English, with gaps tied to pretraining/fine-tuning data. Argues exposure to broader linguistic–cultural variation is required for equitable performance.",
"Kalema, 2023","Kalema, N. (2023). Deconstructing the Global Coded Gaze on Digital Transformation. Anti-Racism Policy (2) pp. 67–74. https://discovery.ucl.ac.uk/id/eprint/10180589/ ",Deconstructing the Global Coded Gaze on Digital Transformation,Extractive,Excluding underrepresented groups from decision-making,"Critical theory/Historical background, Community impacts and relations",Problem Understanding & Formulation,Institutional Prioritization & Funding,Era 3,C,"A: none; D: none (indirect critiques of data infrastructures); C: analyzes power, techno-solutionism, and data necropolitics shaping harms","White (published journal papers, conference proceedings, books)",Citation/reference snowballing,digital transformation; data justice; power,Not regionally specific,Academic,EU/UK,"UCL Institute for Innovation, UK",,"Introduces the “global coded gaze” to explain how digital transformation policies reproduce racialized and geopolitical inequalities. Advocates data-justice approaches that center rights and equitable outcomes—useful for reframing AI program funding, targets, and metrics beyond narrow efficiency logics.",
"Kamikubo et al., 2022","Kamikubo, R., Wang, L., Marte, C., Mahmood, A., & Kacorri, H. (2022). Data Representativeness in Accessibility Datasets: A Meta-Analysis. Proceedings of the 24th International ACM SIGACCESS Conference on Computers and Accessibility, 1–15. https://doi.org/10.1145/3517428.3544826",Data Representativeness in Accessibility Datasets: A Meta-Analysis,Practices less-extractive,Creating culturally inclusive datasets,"Data practices, Community impacts and relations",ML System Design & Development,"Data Selection, Collection & Annotation",Multi-era,ADC,A: situates accessibility datasets within inclusive AI development; D: analyzes demographic representation in 190 datasets; C: identifies gaps that marginalize disabled communities,"White (published journal papers, conference proceedings, books)",Database search,"USA, accessibility datasets, demographic gaps, disability inclusion",Multiple areas,Academic,North America,"College of Information Studies, University of Maryland, USA","Department of Computer Science, University of Maryland, College Park, USA; College of Information Studies, University of Maryland, College Park, USA; Department of Mathematics, University of Maryland, College Park, USA","Reviews 190 accessibility datasets sourced from disabled and older adults. Finds better age coverage but significant gender and race/ethnicity gaps, plus inconsistent, opaque labeling. Argues demographic complexity and sensitivity demand clearer practices. Provides evidence and guidance to make accessibility datasets more representative and to reduce inequities in downstream AI systems.",
"Kapania et al., 2023","Kapania, S., Taylor, A. S., & Wang, D. (2023). A hunt for the Snark: Annotator Diversity in Data Practices. Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems, 1–15. https://doi.org/10.1145/3544548.3580645 
",A hunt for the Snark: Annotator Diversity in Data Practices,Extractive,Biased pre-processing and category erasure,Data practices,ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,AD,A: evaluates dataset work in AI/ML; D: documents operational barriers to annotator diversity; C: none (indirect implications),"White (published journal papers, conference proceedings, books)",Database search,annotator diversity; dataset production; annotation; representationalist logic,Multiple areas,Mixed,APAC (Asia-Pacific Region),"Google Research, India, USA; City, University of London, UK",,"Investigates how AI/ML practitioners conceptualize and operationalize annotator diversity in dataset production. Using 44 surveys and 16 semi-structured interviews across the US, UK, India, and France, it finds that while practitioners recognize annotator subjectivity, diversity is rarely incorporated due to operational, legal, and cost barriers. Diversity is often framed as bias to be mitigated, reinforcing representationalist logics that seek neutral ground truth. The study highlights how current practices suppress subjective perspectives and limit fairness, proposing shifts in how ground truth, bias, and diversity are understood to center annotator subjectivities in data work",
"Kapania et al., 2025","Kapania, S., Ballard, S., Kessler, A., & Vaughan, J. W. (2025). Examining the Expanding Role of Synthetic Data Throughout the AI Development Pipeline (No. arXiv:2501.18493). arXiv. https://arxiv.org/abs/2501.18493v1",Examining the Expanding Role of Synthetic Data Throughout the AI Development Pipeline ,Extractive,Reproducing biases through synthetic data generation,"Data practices, Community impacts and relations",ML System Design & Development,Model Training & Evaluation,Era 3,ADC,A: investigates synthetic data use across AI development pipeline; D: examines practitioner motivations and data validation challenges; C: identifies limitations in depicting underrepresented groups and ethical concerns,"White (published journal papers, conference proceedings, books)","Existing networks, relevant organizations and conferences","synthetic data, AI pipeline, validation",Not regionally specific,Mixed,North America,"Carnegie Mellon University, USA","Microsoft, Redmond, WA, USA;  Microsoft
New York, NY, USA
","Investigates the increasing use of synthetic data in AI development. It highlights that generative AI has enabled the widespread creation of artificial data, which is now used to train and evaluate AI models. Through interviews with AI practitioners and experts, the research explores motivations, practices, and challenges associated with synthetic data. While synthetic data offers solutions for data scarcity and resource constraints, the authors reveal limitations in controlling outputs, accurately depicting underrepresented groups, and validating data quality, while underlining various ethical concerns tied to its use. ",
"Karya, n.d.","Karya. (n.d.). Karya | We solve data needs. Retrieved September 7, 2025, from https://www.karya.in/ ",Karya,Practices less-extractive,Creating culturally inclusive datasets,"Data practices, Community impacts and relations, Data labor",ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,ADC,A: creates inclusive AI datasets; D: delivers ethical pay and community-oriented infrastructure; C: empowers underserved workers via participatory data labor,"Grey (Reports, blogs, white papers, policy documents, theses, conference papers)","Existing networks, relevant organizations and conferences",India; data service; fair wage; participatory labor,APAC (Asia-Pacific Region),Industry,APAC (Asia-Pacific Region),"Karya (Bengaluru-based social enterprise), India",Founded by Manu Chopra & Vivek Seshadri (Michael M. backing via Microsoft Research). Multi-stakeholder model; social-enterprise architecture ensuring worker ownership and recurring royalties; participatory infrastructure for ethically sourced AI data and gig labor fairness,"Describes a social enterprise for AI data work in rural India. Provides annotated datasets (text, speech, image) with fair wages, royalties, and open tools. Positions workers as partners, not invisible labor. Links: community-oriented data labor and governance to higher-quality datasets and more equitable benefits from AI development.",
"Kawakami & Venkatagiri, 2024","Kawakami, R., & Venkatagiri, S. (2024). The Impact of Generative AI on Artists. Proceedings of the 16th Conference on Creativity & Cognition, 79–82. https://doi.org/10.1145/3635636.3664263",The Impact of Generative AI on Artists,Extractive,"Collecting vast amounts of data to train AI systems, Prioritizing data wants over community needs",Data practices,ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,ADC,A: investigates generative-AI impacts; D: discusses dataset sourcing and opt-in/out controls; C: details labor precarity and distrust affecting artists,"White (published journal papers, conference proceedings, books)",Database search,genAI; artist labor; data consent,Not regionally specific,Academic,North America,"Swarthmore College, USA",,"Uses thematic analysis of social-media posts to examine how generative AI both augments and threatens artistic practice. Documents stress, job insecurity, and public distrust tied to accusations of AI use. Recommends protections—regulation and opt-in/out data collection—and tracks contested norms around scraping art for training.",
"Kawakami et al., 2024","Kawakami, A., Coston, A., Zhu, H., Heidari, H., & Holstein, K. (2024). The Situate AI Guidebook: Co-Designing a Toolkit to Support Multi-Stakeholder, Early-stage Deliberations Around Public Sector AI Proposals. Proceedings of the CHI Conference on Human Factors in Computing Systems, 1–22. https://doi.org/10.1145/3613904.3642849","The Situate AI Guidebook: Co-Designing a Toolkit to Support Multi-Stakeholder, Early-stage Deliberations Around Public Sector AI Proposals",Practices less-extractive,Early co-design and participatory initiatives,"Data practices, Ethics frameworks",Problem Understanding & Formulation,Product Conception & Design,Era 3,ADC,A: scaffolds early AI deliberations; D: provides data/model constraints modules; C: centers multi-stakeholder impacts in public sector contexts,"White (published journal papers, conference proceedings, books)",Database search,USA; public sector AI; co-design; toolkit,North America,Mixed,North America,"Carnegie Mellon University, USA",,"Co-designed a guidebook with agency staff, developers, advocates, and community groups to structure early AI decision-making. Toolkit includes deliberation modules on goals, legality, data limits, and governance. Demonstrates how participatory design supports responsible public-sector AI, reducing harm by addressing context-specific needs before development.",
"Kay et al., 2024","Kay, J., Kasirzadeh, A., & Mohamed, S. (2024). Epistemic Injustice in Generative AI. Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society, 7, 684–697. https://doi.org/10.1609/aies.v7i1.31671 
",Epistemic Injustice in Generative AI,Extractive,"Keeping communities in the dark through opaque data practices, Biased pre-processing and category erasure","Data practices, Community impacts and relations",ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,ADC,"A: analyzes generative model behaviors & effects; D: critiques data practices (categorization, preprocessing, multilingual coverage); C: maps harms to public knowledge, multilingual communities, democracy","White (published journal papers, conference proceedings, books)",Database search,Generative model; categorization; multilingual coverage; epistemic injustice,Not regionally specific,Mixed,EU/UK,"Google DeepMind; University College London, UK","Google Research; University of Edinburgh, UK","Develops the concept of generative algorithmic epistemic injustice. Identifies testimonial manipulation, hermeneutical ignorance, and access inequity as mechanisms through which models distort knowledge. Uses real-world examples to show representational harm, misinformation, and multilingual inequities. Recommends design principles and strategies to foster epistemically just systems and protect democratic knowledge ecosystems.",
"Kelley et al., 2023","Kelley, P. G., Cornejo, C., Hayes, L., Jin, E. S., Sedley, A., Thomas, K., Yang, Y., & Woodruff, A. (2023). “There will be less privacy, of course”: How and why people in 10 countries expect AI will affect privacy in the future. https://www.usenix.org/conference/soups2023/presentation/kelley","“There will be less privacy, of course”: How and why people in 10 countries expect AI will affect privacy in the future",Extractive,Keeping communities in the dark through opaque data practices,"Data practices, Community impacts and relations",Deployment & Impact,Product Testing,Era 3,AC,"A: surveys public expectations about AI's privacy impacts; D: none; C: captures concerns across vulnerability, inference, consent, and surveillance affecting global populations","White (published journal papers, conference proceedings, books)",Database search,"AI privacy, global survey, public opinion",Multiple areas,Mixed,North America,"Google, USA","IPSOS, USA","Surveys 10,011 respondents across ten countries on AI's expected privacy effects. Identifies four themes: data vulnerability, highly personal data and inference, lack of consent, and surveillance/government use. Finds privacy concerns well-reasoned and aligned with expert narratives, unlike other AI literacy areas marked by misconceptions.",
"Kelly et al., 2023","Kelly, S., Kaye, S.-A., White, K. M., & Oviedo-Trespalacios, O. (2023). Clearing the way for participatory data stewardship in artificial intelligence development: A mixed methods approach. Ergonomics, 66(11), 1782–1799. https://doi.org/10.1080/00140139.2023.2289864",Clearing the way for participatory data stewardship in artificial intelligence development: A mixed methods approach,Principles less-extractive,Participatory data ownership & governance,Community impacts and relations,Cross-pipeline,Cross-pipeline,Era 3,ADC,"A: discusses implications of participatory data stewardship for AI development; D: identifies predictors shaping willingness to share data; C: highlights trust, clarity, and social good as community concerns.","White (published journal papers, conference proceedings, books)",Database search,Oceania; PDS; willingness to share; transparency; social good,Oceania,Academic,Oceania,"Queensland University of Technology, Australia",,"Mixed-methods study (n=322, Australia) modeling willingness to contribute data through PDS. Trust in AI, clear use explanations, and perceived social good predict participation. Recommends transparent communication and benefit framing to support community-aligned data production for AI.",
"Khan & Hanna, 2022","Khan, M., & Hanna, A. (2022). The Subjects and Stages of AI Dataset Development: A Framework for Dataset Accountability. Forthcoming 19 Ohio St. Tech. L.J. (2023). https://doi.org/10.2139/ssrn.4217148",The Subjects and Stages of AI Dataset Development: A Framework for Dataset Accountability,Principles less-extractive,Building public visibility in dataset development,Data practices,Cross-pipeline,Cross-pipeline,Era 3,ADC,A: legal-technical framing of AI datasets; D: maps stages and stakeholders for accountability; C: analyzes informational harms across actors,"Grey (Reports, blogs, white papers, policy documents, theses, conference papers)",Database search,dataset development; accountability framework; data subject; privacy law,Not regionally specific,Academic,North America,"Yale University, USA",often cited as OSTLJ 19 (2023); no public journal page found,"Proposes a stage-by-stage framework for AI dataset accountability spanning formulation, collection, cleaning, annotation, training, deployment, and distribution. Identifies stakeholders such as data subjects, annotators, curators, and copyright holders and catalogs their potential harms. Provides a legal lens to align practices with safeguards, centering rights and responsibilities across the dataset lifecycle. ",
"Kirk et al., 2024","Kirk, H. R., Whitefield, A., Röttger, P., Bean, A., Margatina, K., Ciro, J., Mosquera, R., Bartolo, M., Williams, A., He, H., Vidgen, B., & Hale, S. A. (2024). The PRISM Alignment Dataset: What Participatory, Representative and Individualised Human Feedback Reveals About the Subjective and Multicultural Alignment of Large Language Models (No. arXiv:2404.16019). arXiv. https://doi.org/10.48550/arXiv.2404.16019","The PRISM Alignment Dataset: What Participatory, Representative and Individualised Human Feedback Reveals About the Subjective and Multicultural Alignment of Large Language Models",Practices less-extractive,"Community engaged data production, Creating culturally inclusive datasets","Data practices, Community impacts and relations",ML System Design & Development,Model Training & Evaluation,Era 3,ADC,"A: evaluates LLM behavior with personalized preference data; D: collects participatory, demographic-rich alignment data; C: analyzes multicultural impacts and representation","White (published journal papers, conference proceedings, books)","Existing networks, relevant organizations and conferences","LLM alignment, contextual preferences, data collection methods ",Multiple areas,Mixed,EU/UK,"University of Oxford, UK",,"Presents a novel resource for studying human preferences in language models. The dataset consists of conversations between humans and a diverse set of language models, covering a range of topics and conversation styles (unguided, values-guided, and controversy-guided). The dataset further captures detailed demographic information about the participants and model performance ratings, providing a rich foundation for exploring how individual differences impact AI alignment. Key considerations addressed in the source include ethical limitations, diversity of participants, and methodologies for analyzing subjective human feedback, with the goal of providing a benchmark for researchers to better align AI with diverse human values and preferences.",
"Kızrak, 2024","Kızrak, A. (2024, August 26). What is the Data Space? Medium. https://ayyucekizrak.medium.com/what-is-the-data-space-36037d0aab2d
",What is the Data Space? ,Practices less-extractive,Developing federated data spaces,Data practices,ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,DC,A: none; D: explains open/closed/federated data-space models with sovereignty and interoperability; C: frames trust and compliance benefits,"Grey (Reports, blogs, white papers, policy documents, theses, conference papers)",Iterative keyword search,EU; data spaces; sovereignty; interoperability,Multiple areas,Academic,EU/UK,"HUX AI, UK",,"Concept explainer outlining aims and variants of data spaces, emphasizing data owner control, interoperability, and secure cross-border exchange. Links to European initiatives (e.g., Green Deal) and proposes data spaces as foundational infra for analytics and AI. Useful orientation to governance choices shaping less-extractive data sharing.",
"Klein & D’Ignazio, 2024","Klein, L., & D’Ignazio, C. (2024). Data Feminism for AI. The 2024 ACM Conference on Fairness, Accountability, and Transparency, 100–112. https://doi.org/10.1145/3630106.3658543",Data Feminism for AI,Principles less-extractive,"Early co-design and participatory initiatives, Community engaged data production, Participatory data ownership & governance","Data practices, Ethics frameworks",ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,ADC,A: critiques AI fairness paradigms; D: none (indirect implications); C: advocates participatory feminist frameworks for inclusivity,"White (published journal papers, conference proceedings, books)",Hand-searching key journals,"global, feminism, participatory design, inclusivity",Not regionally specific,Academic,North America,"Emory University, USA
MIT (Civic Data Design Lab), USA",,"Advocates for applying intersectional feminist principles to AI research to combat bias and promote social justice. Builds on and rearticulates framework from 2020 book Data Feminism, Argues that current AI research often neglects the unequal power dynamics inherent in data collection and algorithmic design, leading to systems that perpetuate existing social inequalities. They propose several feminist principles for AI research, including examining power structures that shape AI development, challenging those power structures through community engagement and data literacy, and embracing a plurality of perspectives in research design. They also highlight the importance of considering the historical and social context of data, making labor practices visible, and addressing the environmental impacts of AI. 

“intersectional feminist theories of power…bridge personal experience and structural frameworks, and because they are explicit about their goal: understanding present imbalances of power in the world so that they can be challenged, rebalanced, and changed”

“[M]ore data collection is not always the ‘solution’ to problems of inequality. In many cases, additional data collection can lead to demonstrable harm. This is the ‘paradox of exposure’ that we name in Data Feminism, ""the double bind that places those who stand to significantly gain from being counted in the most danger from that same counting (or classifying) act’ (p 105). So as we celebrate these specific examples, we must also remind ourselves to ask before beginning any new project whether a technical intervention is even appropriate, as well as whether we along with the frontline communities we serve have together considered the range of possible harms.”",
"Klein, 2013","Klein, N. (2013). Dancing the world into being: A conversation with Idle No More’s Leanne Simpson. Yes! Magazine, 5. https://www.yesmagazine.org/social-justice/2013/03/06/dancing-the-world-into-being-a-conversation-with-idle-no-more-leanne-simpson","Dancing the World into Being: A Conversation with Idle No More’s Leanne Simpson
",Extractive,"Prioritizing data wants over community needs, Soliciting data without reciprocal benefits","Critical theory/Historical background, Community impacts and relations",Cross-pipeline,Cross-pipeline,Multi-era,DC,"A: none; D: examines extractive practices across knowledge systems; C: centers Indigenous perspectives on land, memory, and reciprocity through Idle No More movement","Grey (Reports, blogs, white papers, policy documents, theses, conference papers)",Citation/reference snowballing,"extractivism, Indigenous knowledge, reciprocity",North America,Academic,North America,"Rutgers University, USA",,"Naomi Klein speaks with writer, spoken-word artist, and indigenous academic Leanne Betasamosake Simpson about “extractivism,” why it’s important to talk about memories of the land, and what’s next for Idle No More.",
"Klein, 2022","Klein, L. (2022). Are Large Language Models Our Limit Case?. Startwords, 3. https://doi.org/10.5281/zenodo.6567985",Are Large Language Models Our Limit Case?,Extractive,"Collecting vast amounts of data to train AI systems, Prioritizing data wants over community needs",Data practices,Problem Understanding & Formulation,Institutional Prioritization & Funding,Era 3,ADC,A: interrogates LLMs in humanities; D: critiques data and funding logics that privilege scale; C: advances “refusal” to protect communities and scholarship,"White (published journal papers, conference proceedings, books)",Citation/reference snowballing,LLM; power asymmetry; refusal; humanities,Not regionally specific,Academic,North America,"Emory University, USA",,"Argues unequal power and corporate funding priorities shape LLMs and their training data, challenging compatibility with humanistic values. Develops “refusal” as a generative strategy—pausing or rejecting harmful systems—to open space for ethical alternatives. Calls humanities scholars to articulate limits and steer research toward community-attentive futures.",
"Kliemann, 2020","Kliemann, C. (2020, September 22). Towards a Non-Extractive and Care-Driven Academia. Debating Development Research. https://www.developmentresearch.eu/?p=801",Towards a Non-Extractive and Care-Driven Academia,Extractive,Western-centric research infrastructure,Community impacts and relations,Cross-pipeline,Cross-pipeline,Multi-era,DC,A: none; D: critiques extractive structures in academia; C: proposes care-driven models that redistribute power and value diverse knowledge,"Grey (Reports, blogs, white papers, policy documents, theses, conference papers)","Existing networks, relevant organizations and conferences","academia, decolonization, care-driven research",Not regionally specific,Academic,EU/UK,"University of Antwerp, Belgium",,"Calls for a shift from competitive, output-driven academic norms toward care-driven, collaborative practice in development research. Uses reflective critique to surface extractive structures—commodified knowledge, Western epistemic dominance, and unequal partnerships. Proposes practical changes in mentorship, incentives, and partnership models. While not AI-specific, the analysis informs data-production cultures that shape who researches whom and how communities experience knowledge extraction.",
"Koch et al., 2021","Koch, B., Denton, E., Hanna, A., & Foster, J. G. (2021). Reduced, Reused and Recycled: The Life of a Dataset in Machine Learning Research (No. arXiv:2112.01716). arXiv. https://doi.org/10.48550/arXiv.2112.01716","Reduced, Reused and Recycled: The Life of a Dataset in Machine Learning Research",Extractive,Western-centric research infrastructure,Data practices,ML System Design & Development,Model Training & Evaluation,Era 3,AD,A: analyzes dataset reuse across ML subfields; D: documents concentration around elite-origin benchmarks; C: none,"White (published journal papers, conference proceedings, books)",Citation/reference snowballing,dataset; benchmark; infrastructure,Not regionally specific,Mixed,North America,"UCLA, CA, USA","Google Research, NY, SF, USA","Studies dataset usage from 2015–2020 across ML communities. Finds increasing concentration on a few benchmarks, cross-task adoption, and dominance of datasets from elite institutions. Discusses implications for evaluation, equity, and access—showing how benchmark infrastructures shape AI data production priorities.",
"Koenecke et al., 2020","Koenecke A, Nam A, Lake E, Nudell J, Quartey M, Mengesha Z, Toups C, Rickford JR, Jurafsky D, Goel S. Racial disparities in automated speech recognition. Proc Natl Acad Sci U S A. 2020 Apr 7;117(14):7684-7689. https://doi.org/10.1073/pnas.1915768117 ",Racial disparities in automated speech recognition,Extractive,"""Deploying AI systems that lack local, contextual data""","Data practices, Community impacts and relations",ML System Design & Development,Model Training & Evaluation,Era 3,ADC,A: compares ASR outputs; D: traces bias to acoustic models; C: documents racial disparities in transcription accuracy,"White (published journal papers, conference proceedings, books)",Database search,"USA, ASR, racial disparities, AAVE",North America,Academic,North America,"Cornell University, USA","Stanford University (ICME, Psychology, Linguistics, Management Science & Engineering, Computer Science); Georgetown University (Linguistics), USA",Evaluates five leading ASR systems on matched corpora of 42 white and 73 Black speakers. All systems had higher error rates for Black speakers (0.35 vs. 0.19). Bias traced to acoustic models. Authors propose diversifying training datasets with AAVE to reduce disparities and make ASR more inclusive.,
"Koenigstorfer et al., 2024","Koenigstorfer, F., Haberl, A., Kowald, D., Ross-Hellauer, T., & Thalmann, S. (2024). Black Box or Open Science? Assessing Reproducibility-Related Documentation in AI Research. https://hdl.handle.net/10125/106458",Black Box or Open Science? Assessing Reproducibility-Related Documentation in AI Research,Extractive,Western-centric research infrastructure,"Data practices, Ethics frameworks",ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,AD,A: highlights weak reporting on data and models; D: applies Open Science criteria to assess reproducibility; C: none,"White (published journal papers, conference proceedings, books)",Iterative keyword search,open science; reproducibility; documentation,Not regionally specific,Academic,EU/UK,"BANDAS Center, University of Graz, Austria","Know-Center & TU Graz, Austria","Investigates the reproducibility of AI research by examining the documentation practices in published papers. The authors assess if sufficient detail is provided regarding training data, source code, and AI models to allow for replication of results. They introduce a framework based on Open Science principles, which emphasizes transparency and accessibility, to evaluate documentation quality across different fields like information systems, computer science, and medicine. The study concludes that many AI development papers lack sufficient documentation, hindering reproducibility and potentially impacting the validity and adoption of AI innovations. ",
"Kojah et al., 2025","Kojah, S. A., Zhang, B. Z., Are, C., Delmonaco, D., & Haimson, O. L. (2025). “Dialing it Back:” Shadowbanning, Invisible Digital Labor, and how Marginalized Content Creators Attempt to Mitigate the Impacts of Opaque Platform Governance. Proc. ACM Hum.-Comput. Interact., 9(1), GROUP12:1-GROUP12:22. https://doi.org/10.1145/3701191","“Dialing it Back:” Shadowbanning, Invisible Digital Labor, and how Marginalized Content Creators Attempt to Mitigate the Impacts of Opaque Platform Governance",Extractive,Keeping communities in the dark through opaque data practices,"Community impacts and relations, Data practices",Deployment & Impact,Product Launch,Era 3,ADC,A: highlights algorithmic opacity in platform systems; D: shows hidden moderation shaping visibility; C: details economic precarity and invisible labor of marginalized creators,"White (published journal papers, conference proceedings, books)",Database search,"USA/UK, platform governance, shadowbanning, marginalized creators",Multiple areas,Mixed,Multiple areas,"School of Information, University of Michigan, Ann Arbor, MI, USA","School of Information, University of Michigan, Ann Arbor, MI, USA; Centre for Digital Citizens, Northumbria University, Newcastle, United Kingdom; Rutgers University Libraries, Rutgers, The State University of New Jersey, Newark, NJ, USA; University of Michigan, Ann Arbor, MI, USA","Diary study + interviews with marginalized creators show shadowbanning’s economic and emotional toll and the extra “invisible labor” to maintain reach. Identifies mental/emotional, misdirected, and community labor forms. Links opaque moderation and data practices to precarity, arguing for transparent governance and participatory recourse mechanisms.",
"Kothari, 1997","Kothari, B. (1997). Rights to the Benefits of Research: Compensating Indigenous Peoples for their Intellectual Contribution. Human Organization, 56(2), 127–137. https://doi.org/10.17730/humo.56.2.j63678502x782100 
",Rights to the Benefits of Research: Compensating Indigenous Peoples for their Intellectual Contribution,Practices less-extractive,Establishing consent and contextually appropriate compensation,"Data labor, Community impacts and relations",ML System Design & Development,"Data Selection, Collection & Annotation",Multi-era,DC,A: none; D: proposes framework for compensation (Rights to the Benefits of Research); C: centers Indigenous empowerment and protection of intellectual property in Ecuado,"White (published journal papers, conference proceedings, books)",Database search,"Ecuador, indigenous knowledge, compensation, ethnobotany",Multiple areas,Mixed,APAC (Asia-Pacific Region),"Indian Institute of Management, Ahmedabad",co-authored with Indígena (FSI) Fundación Sabiduria,"Examines how research on Indigenous knowledge often produces benefits for outsiders without fair compensation to contributing communities. Proposes “Rights to the Benefits of Research” (RBR) as a framework distinct from Intellectual Property Rights, emphasizing reciprocity and empowerment over commercial gain. Using a participatory ethnobotanical project in Ecuador, the article illustrates how communities documented medicinal plant knowledge for themselves while reflecting on extractive, compensatory, and empowering tendencies of the collaboration. The paper argues that embedding compensation within the research process strengthens Indigenous control over cultural data and helps protect knowledge from predatory extraction",
"Kouritzin & Nakagawa, 2018","Kouritzin, S., & Nakagawa, S. (2018). Toward a non-extractive research ethics for transcultural, translingual research: Perspectives from the coloniser and the colonised. Journal of Multilingual and Multicultural Development, 39(8), 675–687. https://doi.org/10.1080/01434632.2018.1427755","Toward a non-extractive research ethics for transcultural, translingual research: Perspectives from the coloniser and the colonised",Extractive,"Prioritizing data wants over community needs, Western-centric research infrastructure",Critical theory/Historical background,Problem Understanding & Formulation,Institutional Prioritization & Funding,Multi-era,DC,A: none; D: critiques extractive research paradigms in applied linguistics; C: analyzes power imbalances between Western researchers and non-Western communities,"White (published journal papers, conference proceedings, books)","Existing networks, relevant organizations and conferences","research ethics, extractive practices, applied linguistics",Not regionally specific,Academic,North America,"University of Manatoba, Canada",,"Argues that current research practices in applied linguistics often operate as extractive, rather than non-extractive processes. The authors problematize the current dominant research paradigm, particularly Western research conducted in non-Western contexts, critiquing its claims of objectivity and neutrality. They argue that research ethics, as currently conceived, perpetuate a system of hegemony, perpetuating a power imbalance between the researcher and the researched. To address these issues, the authors propose several principles for developing a non-extractive research ethics, including intent, integrity, social hostages, and a post-humanist outlook. These principles emphasize reciprocity, responsibility, and a commitment to disrupting traditional power dynamics in research.",
"Kukutai & Cormack, 2020","Kukutai, T., & Cormack, D. (2020). “Pushing the space”: Data sovereignty and self-determination in Aotearoa NZ. In Indigenous Data Sovereignty and Policy (1st Edition, pp. 21–35). Routledge. https://www.taylorfrancis.com/reader/read-online/6abf9fc2-820b-4950-b310-eef574873fbb/chapter/pdf?context=ubx ",“Pushing the space”: Data sovereignty and self-determination in Aotearoa NZ,Principles less-extractive,Participatory data ownership & governance,"Ethics frameworks, Community impacts and relations",Cross-pipeline,Cross-pipeline,Multi-era,DC,A: none; D: theorizes Indigenous data sovereignty frameworks; C: foregrounds Māori self-determination and policy transformations,"White (published journal papers, conference proceedings, books)","Existing networks, relevant organizations and conferences","Oceania, Aotearoa New Zealand, data sovereignty, Māori, self-determination",Oceania,Academic,Oceania,"School of Information Management, Victoria University of Wellington, Wellington, New Zealand
Te Kupenga Hauora Māori, University of Auckland",,"Analyzes Indigenous Data Sovereignty (IDS) as central to Māori aspirations for self-determination in Aotearoa New Zealand. Argues that IDS cannot be fully realized within colonial state structures, but that policy can support iwi-led and community-controlled data systems. Emphasizes the importance of shifting from data dependency to sovereignty, outlining pathways for Indigenous nations to design governance that reflects Māori values and priorities. Connects IDS to broader debates on decolonial data governance and its role in reshaping power relations in digital infrastructures",
"Kukutai & Taylor, 2016","Kukutai, T., & Taylor, J. (Eds.). (2016). Indigenous Data Sovereignty (1st ed.). ANU Press. https://doi.org/10.22459/CAEPR38.11.2016",Indigenous Data Sovereignty,Principles less-extractive,"Participatory data ownership & governance, Decentering Western ontologies","Community impacts and relations, Critical theory/Historical background",Problem Understanding & Formulation,Institutional Prioritization & Funding,Multi-era,DC,"A: none (foundational governance, not AI-specific); D: articulates IDS frameworks and implementation; C: centers sovereignty across sectors","White (published journal papers, conference proceedings, books)",Database search,Oceania; North America; IDS; governance,Multiple areas,Academic,Oceania,"University of Waikato, NZ; The Australian National University, Australia","Tahu Kukutai belongs to the Ngāti Tīpa, Ngāti Maniapoto and Te Aupouri tribes","Seminal edited volume that explores the concept of data sovereignty, which is the right of Indigenous peoples to govern the collection, ownership and application of data about them. Many of the excerpts highlight the historical context of data collection about Indigenous peoples, which has often served to perpetuate harmful stereotypes and justify oppressive policies. The authors argue that achieving data sovereignty is crucial for Indigenous communities to assert their self-determination, improve their social and economic well-being, and preserve their cultural heritage. The book includes diverse perspectives from Indigenous scholars and practitioners across various fields, offering insights into practical strategies for implementing data sovereignty in areas such as health care, education, and resource management.",
"Kwet, 2019","Kwet, M. (2019). Digital colonialism: US empire and the new imperialism in the Global South. Race & Class, 60(4), 3–26. https://journals.sagepub.com/doi/10.1177/0306396818823172",Digital colonialism: US empire and the new imperialism in the Global South,Extractive,Collecting vast amounts of data to train AI systems,"Community impacts and relations, Critical theory/Historical background",Problem Understanding & Formulation,Institutional Prioritization & Funding,Multi-era,DC,"A: none (indirect implications); D: theorizes digital imperialism via platform and infrastructure control that extract data and enable surveillance; C: analyzes Global South harms and advocates decentralized, community-controlled alternatives","White (published journal papers, conference proceedings, books)",Database search,Global South; digital infrastructure; surveillance capitalism,Multiple areas,Academic,North America,"Yale University, CT, USA",,"Conceptualizes “digital colonialism” to explain how US tech firms and allied states dominate software, hardware, and connectivity in the Global South. Shows how platform monopolies and data extraction concentrate power, intensify surveillance, and shape political–cultural life. Uses South Africa to illustrate mechanisms—rent-seeking, architecture control, and big-data surveillance—and calls for decentralized alternatives that return technological control to communities. Links AI data practices to ongoing imperial relations and harms borne by marginalized populations.",
"Kwet, 2021","Kwet, M. (2021, March 4). Digital colonialism: The evolution of US empire. Longreads. https://longreads.tni.org/digital-colonialism-the-evolution-of-us-empire",Digital colonialism: The evolution of US empire,Extractive,Ethics dumping in less-regulated contexts,"Community impacts and relations, Critical theory/Historical background",Deployment & Impact,Product Launch,Multi-era,DC,A: none; D: platform data capture logics; C: theorizes harms from US Big Tech control over Global South digital ecosystems,"Grey (Reports, blogs, white papers, policy documents, theses, conference papers)",Database search,Global South; digital colonialism; platform power; surveillance,Multiple areas,Academic,North America,Yale's Information Society Project. USA,,"Analyzes how US-based transnational Big Tech corporations have gained excessive control over business, labor, social media, and entertainment in the Global South. Traces evolution of digital colonialism through corporate concentration of power and wealth. Positions contemporary tech expansion as continuation of imperial patterns of domination and resource extraction.",
"Lai et al., 2023","Lai, V. D., Ngo, N., Pouran Ben Veyseh, A., Man, H., Dernoncourt, F., Bui, T., & Nguyen, T. H. (2023). ChatGPT Beyond English: Towards a Comprehensive Evaluation of Large Language Models in Multilingual Learning. In H. Bouamor, J. Pino, & K. Bali (Eds.), Findings of the Association for Computational Linguistics: EMNLP 2023 (pp. 13171–13189). Association for Computational Linguistics. https://doi.org/10.18653/v1/2023.findings-emnlp.878",ChatGPT Beyond English: Towards a Comprehensive Evaluation of Large Language Models in Multilingual Learning,Practices less-extractive,Creating culturally inclusive datasets,Data practices,Deployment & Impact,Product Launch,Era 3,ADC,"A: benchmarks multilingual performance across 37 languages; D: documents disparities in low-resource results; C: Focuses on communities and regions with ""low-resource"" languages","White (published journal papers, conference proceedings, books)","Existing networks, relevant organizations and conferences","global, multilingual, LLM, evaluation, low-resource",Multiple areas,Mixed,North America,"Dept. of Computer Science, University of Oregon, OR, USA","Adobe Research, USA","Evaluates LLM performance on seven tasks in 37 languages, revealing substantial gaps between high- and low-resource languages. Benchmarks and analysis highlight structural inequities in multilingual deployment and the need for targeted data and training strategies. The paper provides a broad empirical baseline and calls for research focused on under-served languages to reduce performance disparities that translate into downstream access and quality gaps.",
"Le Ferrand, 2023","Le Ferrand, E. (2023). Leveraging Speech Recognition for Interactive Transcription in Australian Aboriginal Communities [PhD Thesis, Charles Darwin University]. https://hal.science/tel-04128537",Leveraging Speech Recognition for Interactive Transcription in Australian Aboriginal Communities,Practices less-extractive,Community engaged data production,"Critical theory/Historical background, Community impacts and relations",ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,ADC,A: adapts speech recognition workflows; D: analyzes transcription processes; C: works with Aboriginal communities on participatory design,"Grey (Reports, blogs, white papers, policy documents, theses, conference papers)",Iterative keyword search,"Australia. speech recognition, interactive transcription, Aboriginal languages",Oceania,Academic,Oceania,"Charles Darwin University, Australia",,"Proposes a “sparse transcription” workflow combining automated speech recognition with human expertise for Aboriginal languages. Aligns syllable-based transcription with community approaches to language learning. Emphasizes co-design, ethical practice, and respect for Indigenous knowledge systems, demonstrating a less-extractive path for low-resource speech technologies.",
"Lebow-Skelley et al., 2023","Lebow-Skelley, E., Scott Tomlinson, M., Charles, S., Fuller, C., Ames, B., & Pearson, M. A. (2023). A Collaborative Approach to Address Racism in a Community–Academic Partnership. Preventing Chronic Disease, 20, E47. https://doi.org/10.5888/pcd20.220365",A Collaborative Approach to Address Racism in a Community–Academic Partnership,Practices less-extractive,Early co-design and participatory initiatives,"Ethics frameworks, Community impacts and relations",Problem Understanding & Formulation,Institutional Prioritization & Funding,Era 3,DC,A: none; D: details internal practice reforms and governance; C: centers community–academic collaboration addressing racism,"White (published journal papers, conference proceedings, books)",Iterative keyword search,North America; anti-racism; community engagement; governance,Not regionally specific,Industry,North America,"Emory University, USA",,"Describes an anti-racism process co-developed by a research center and a stakeholder advisory board. Details dialogues, commitments, and action items to change policies and operations. While not AI-specific, it offers a model for governance and partnership that shapes how research agendas and data practices affect local communities.",
"Lee & Schultz, 2011","Lee, A., & Schultz, K. A. (2011). Comparing British and French Colonial Legacies: A Discontinuity Analysis of Cameroon (SSRN Scholarly Paper No. 1903316). https://papers.ssrn.com/abstract=1903316",Comparing British and French Colonial Legacies: A Discontinuity Analysis of Cameroon,Extractive,Other/NA (conceptual framing),"Community impacts and relations, Critical theory/Historical background",Problem Understanding & Formulation,Institutional Prioritization & Funding,Multi-era,C,"A: none; D: none; C: historical community outcomes (public goods, wealth)","Grey (Reports, blogs, white papers, policy documents, theses, conference papers)","Existing networks, relevant organizations and conferences","Cameroon, Africa, discontinuity analysis, colonial legacy",Africa,Academic,North America,"Stanford University, USA",,"Investigates the long-term effects of colonial rule on post-independence economic development and public goods provision in Cameroon. Specifically, it compares regions of Cameroon that were colonized by the British to those colonized by the French, utilizing a regression discontinuity research design to control for potential confounding factors. The authors find that rural areas on the British side of the colonial boundary exhibit higher levels of household wealth and access to piped water, a locally provided public good. These findings suggest that British colonial legacies, including indirect rule and common law, may have had a positive impact on rural communities. However, no such effect is found for urban areas or centrally-provided public goods, indicating that post-independence policies play a significant role in shaping outcomes. The authors acknowledge limitations, including the potential for confounding factors and the focus on a single case study, but argue that the Cameroonian case offers a valuable opportunity to study the effects of different colonial legacies while controlling for other variables.",
"Lee & Toliver, 2017","Lee, U., & Toliver, D. (2017). Building Consentful Tech. http://www.consentfultech.io/wp-content/uploads/2019/10/Building-Consentful-Tech.pdf",Building Consentful Tech,Extractive,Soliciting data without reciprocal benefits,Ethics frameworks,ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,DC,A: none; D: examines consent frameworks for digital technology design; C: addresses impacts on marginalized communities through non-consensual technologies,"Grey (Reports, blogs, white papers, policy documents, theses, conference papers)",Database search,"digital consent, design justice, technology ethics",Not regionally specific,Industry,North America,The team behind the Ripple Mapping Tool,"Sponsored by Allied Media Projects; Supported by the Digital Rights Community Grant Program, a partnership between Digital Justice Lab, Tech Reset Canada and Centre for Digital Rights, Canada","Zine about how the principles of consent, vital for physical interactions, are equally crucial in the digital realm. The authors emphasize that consentful technology goes beyond simple agreement, requiring applications and digital spaces to be built upon the ongoing respect for user autonomy and data privacy. They adapt the FRIES acronym (Freely Given, Reversible, Informed, Enthusiastic, and Specific) from Planned Parenthood to illustrate the essential elements of digital consent. The zine stresses that non-consensual technologies disproportionately harm marginalized communities, highlighting the need for design justice and equitable access.",
"Lee et al., 2019","Lee, M. K., Kusbit, D., Kahng, A., Kim, J. T., Yuan, X., Chan, A., See, D., Noothigattu, R., Lee, S., Psomas, A., & Procaccia, A. D. (2019). WeBuildAI: Participatory Framework for Algorithmic Governance. Proceedings of the ACM on Human-Computer Interaction, 3(CSCW), 1–35. https://doi.org/10.1145/3359283",WeBuildAI: Participatory Framework for Algorithmic Governance,Principles less-extractive,"Early co-design and participatory initiatives, Participatory data ownership & governance","Ethics frameworks, Community impacts and relations",Problem Understanding & Formulation,Product Conception & Design,Era 2,ADC,A: develops participatory algorithmic governance systems; D: creates computational models reflecting community values; C: enables stakeholder participation in algorithm design,"White (published journal papers, conference proceedings, books)",Database search,"algorithmic governance, participatory design, stakeholder engagement",Not regionally specific,Academic,North America,"University of Texas at Austin & Carnegie Mellon University, USA",,"Introduces WeBuildAI, enabling stakeholders to encode value preferences and aggregate them via voting to govern matching algorithms. Field case with 412 Food Rescue shows more equitable allocations and higher trust. Frames participatory governance as a practical route to align algorithmic behavior with community priorities, offering a template for co-design that can complement dataset and model documentation practices.",
"Lee, 2024","Lee, P. (2024). Synthetic Data and the Future of AI (SSRN Scholarly Paper No. 4722162). Social Science Research Network. https://papers.ssrn.com/abstract=4722162 
",Synthetic Data and the Future of AI,Extractive,Reproducing biases through synthetic data generation,"Data practices, Community impacts and relations",ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,ADC,"A: analyzes synthetic data's role in ML model training; D: examines data generation processes and quality concerns; C: addresses impacts on privacy, bias, and access to AI development","White (published journal papers, conference proceedings, books)",Database search,"synthetic data, AI development, copyright",North America,Academic,North America,"University of California, Davis - School of Law, CA, USA",,"The future of artificial intelligence (AI) is synthetic. Several of the most prominent technical and legal challenges of AI derive from the need to amass huge amounts of real-world data to train machine learning (ML) models. Collecting such real-world data can be highly difficult and can threaten privacy, introduce bias in automated decision making, and infringe copyrights on a massive scale. This Article explores the emergence of a seemingly paradoxical technical creation that can mitigate—though not completely eliminate—these concerns: synthetic data. Increasingly, data scientists are using simulated driving environments, fabricated medical records, fake images, and other forms of synthetic data to train ML models. Artificial data, in other words, is being used to train artificial intelligence. Synthetic data offers a host of technical and legal benefits; it promises to radically decrease the cost of obtaining data, sidestep privacy issues, reduce automated discrimination, and avoid copyright infringement. Alongside such promise, however, synthetic data offers perils as well. Deficiencies in the development and deployment of synthetic data can exacerbate the dangers of AI and cause significant social harm.

In light of the enormous value and importance of synthetic data, this Article sketches the contours of an innovation ecosystem to promote its robust and responsible development. It identifies three objectives that should guide legal and policy measures shaping the creation of synthetic data: provisioning, disclosure, and democratization. Ideally, such an ecosystem should incentivize the generation of high-quality synthetic data, encourage disclosure of both synthetic data and processes for generating it, and promote multiple sources of innovation. This Article then examines a suite of “innovation mechanisms” that can advance these objectives, ranging from open source production to proprietary approaches based on patents, trade secrets, and copyrights. Throughout, it suggests policy and doctrinal reforms to enhance innovation, transparency, and democratic access to synthetic data. Just as AI will have enormous legal implications, law and policy can play a central role in shaping the future of AI.",
"Lehtiniemi & Ruckenstein, 2022","Lehtiniemi, T., & Ruckenstein, M. (2022). Prisoners training AI: Ghosts, Humans and Values in Data Labour. In S. Pink, M. Berg, D. Lupton, & M. Ruckenstein (Eds.), Everyday Automation (pp. 184–196). Routledge. https://doi.org/10.4324/9781003170884-16","Prisoners training AI: Ghosts, Humans and Values in Data Labour",Extractive,Exploitative and invisible data labor,Data labor,ML System Design & Development,"Data Selection, Collection & Annotation",Multi-era,ADC,A: not central; D: analyzes prison-based annotation pipeline; C: tensions between rehab aims and exploitation risks.,"White (published journal papers, conference proceedings, books)",Database search,"data labor, finland, prisoners",EU/UK,Academic,EU/UK,"University of Helsinki, Finland",,"Despite accounts of how artificial intelligence (AI) is replacing human labour, constant efforts are needed to keep AI-based automation running. In this chapter, we are particularly interested in data work that supports processes of automation. We explore an unconventional arrangement in which Finnish prisoners annotate text to produce training data for a local AI firm. The use of prison labour to train AI invites straightforward conclusions of exploitation of the marginalised. On a closer look, however, attention is drawn to local and situational variations of data labour: how high-tech development can be married with humane penal policies and low-cost labour with rehabilitative aspirations. We argue for an approach that can hold together seemingly contradictory value aims and open novel ways of exploring processes of automated decision-making. By acknowledging what is of value to the different parties involved, we can begin to see alternative paths forward in the study of automation.",
"Leonard et al., 2023","Leonard, K., Russo, S., Martinez, A., McElroy, L., Garba, I., Jennings, L., Oré, C. O., Cummins, J. J., Fernandez, A. A. & Taitingfong, R. (2023). CARE Statement for Indigenous Data Sovereignty. Retrieved from Office of the Secretary-General’s Envoy on Technology Website:
https://www.un.org/techenvoy/global-digital-compact/submissions ",CARE Statement for Indigenous Data Sovereignty,Principles less-extractive,Participatory data ownership & governance,"Community impacts and relations, Critical theory/Historical background",Problem Understanding & Formulation,Institutional Prioritization & Funding,Multi-era,DC,A: none; D: outlines Indigenous data governance frameworks for Global Digital Compact; C: advocates for Indigenous rights and addresses digital colonialism,"Grey (Reports, blogs, white papers, policy documents, theses, conference papers)","Existing networks, relevant organizations and conferences","Indigenous data sovereignty, Global Digital Compact, digital colonialism",North America,Academic,North America,"University of Waterloo Lab, Canada",,"""CARE Statement for Indigenous Data Sovereignty"" authored by the Wampum Lab and the Collaboratory for Indigenous Data Governance. It outlines the need for Indigenous data sovereignty, or the right of Indigenous Peoples to govern the collection, ownership, and application of data about their communities, in the context of the United Nations' Global Digital Compact (GDC). The statement argues that the GDC must prioritize Indigenous rights and address issues such as digital colonialism and the exploitation of Indigenous data. It then proceeds to offer a series of recommendations for the GDC, addressing eight key themes: connecting all people to the internet, avoiding internet fragmentation, protecting data, applying human rights online, introducing accountability criteria for discrimination and misleading content, promoting regulation of artificial intelligence, digital commons as a global public good, and spectrum sovereignty. The statement’s ultimate purpose is to advocate for the inclusion of Indigenous perspectives and principles in the development of the GDC, ensuring a more just and equitable digital future for all.",
"Leone, 2021","Leone, D. Z. (2021). Data Colonialism in Canada: Decolonizing Data Through Indigenous data governance. Carleton University.",Data Colonialism in Canada: Decolonizing Data Through Indigenous data governance,Principles less-extractive,Participatory data ownership & governance,"Community impacts and relations, Critical theory/Historical background, Data practices",ML System Design & Development,"Data Selection, Collection & Annotation",Multi-era,DC,"A: none; D: examines data practices and Indigenous data governance frameworks; C: analyzes impacts on First Nations, Inuit, and Métis peoples","Grey (Reports, blogs, white papers, policy documents, theses, conference papers)",Database search,"Canada, data colonialism, Indigenous data governance",North America,Academic,North America,"Carleton University, Canada",,"M.A. thesis looking at how colonialism continues to impact Indigenous communities through data practices. The author argues that First Nations, Inuit, and Métis peoples in Canada have been systematically excluded from control over data about them, resulting in harmful and inaccurate representations. The dissertation investigates how Indigenous data governance (IDG) can help decolonize data practices. It examines several key aspects of IDG, including data architecture, storage and operations, interoperability and integration, security, quality, and document and content management, especially as they relate to traditional knowledge.",
"Leslie et al., 2022","Leslie, D., Katell, M., Aitken, M., Singh, J., Briggs, M., Powell, R., Rincón, C., Chengeta, T., Birhane, A., Perini, A., Jayadeva, S., & Mazumder, A. (2022, April 6). Advancing Data Justice Research and Practice: An Integrated Literature Review. arXiv.Org. https://doi.org/10.5281/zenodo.6408304",Advancing Data Justice Research and Practice: An Integrated Literature Review,Principles less-extractive,Participatory data ownership & governance,"Data practices, Critical theory/Historical background",Cross-pipeline,Cross-pipeline,Era 3,ADC,A: discusses implications of data justice for AI governance; D: integrates literature into actionable approaches to data use; C: centers perspectives of communities most impacted by inequitable data practices.,"White (published journal papers, conference proceedings, books)",Database search,data justice; governance; impacted communities,Not regionally specific,Mixed,EU/UK,"The Alan Turing Institute, UK","University of Cambridge -- Dept. Computer Science & Technology (Computer Laboratory), UK; Liverpool John Moores University, UK; University College Dublin, Ireland","Integrated review and annotated bibliography expanding data justice beyond narrow lenses. Identifies listening deficits and disciplinary gaps, offering resources to policymakers, practitioners, and communities. Positions participatory governance and rights-sustaining practices as necessary for equitable AI data production and use",
"Lewis et al., 2020","Lewis, J. E., Abdilla, A., Arista, N., Baker, K., Benesiinaabandan, S., Brown, M., Cheung, M., Coleman, M., Cordes, A., Davison, J., Duncan, K., Garzon, S., Harrell, D. F., Jones, P.-L., Kealiikanakaoleohaililani, K., Kelleher, M., Kite, S., Lagon, O., Leigh, J., … Whaanga, H. (2020). Indigenous Protocol and Artificial Intelligence Position Paper. Indigenous Protocol and Artificial Intelligence Working Group and the Canadian Institute for Advanced Research. https://doi.org/10.11573/spectrum.library.concordia.ca.00986506 
",Indigenous Protocol and Artificial Intelligence Position Paper,Principles less-extractive,Decentering Western ontologies,Community impacts and relations,Cross-pipeline,Cross-pipeline,Era 3,ADC,A: proposes Indigenous-led ethical starting points for AI; D: articulates design protocols grounded in sovereignty; C: centers reciprocal relationships with specific communities,"White (published journal papers, conference proceedings, books)","Existing networks, relevant organizations and conferences",Multiple areas; Indigenous protocol; AI design; sovereignty; reciprocity,Multiple areas,Mixed,North America,"Department of Design and Computation Arts, Concordia University, Montréal, Canada","Indigenous Protocol and Artificial Intelligence Working Group: Angie Abdilla, Noelani Arista, Kaipulaumakaniolono Baker, Scott Benesiinaabandan, Michelle Brown, Melanie Cheung, Meredith Coleman, Ashley Cordes, Joel Davison, Kūpono Duncan, Sergio Garzon, D. Fox Harrell, Peter-Lucas Jones, Kekuhi Kealiikanakaoleohaililani, Megan Kelleher, Suzanne Kite, Olin Lagon, Jason Leigh, Maroussia Levesque, Keoni Mahelona, Caleb Moses, Isaac ('Ika'aka) Nahuewai, Kari Noe, Danielle Olson, 'Ōiwi Parker Jones, Caroline Running Wolf, Michael Running Wolf, Silva Marlee, Skawennati Fragnito, Hēmi Whaanga","Outlines how Indigenous protocols can guide AI across contexts. Emphasizes sovereignty, place-based knowledge, and reciprocity rather than generalized “one-size” ethics. Offers protocol-oriented guidance to shift data production and system design toward community authority and long-term relationships.",
"Lewis et al., 2024","Lewis, J. E., Whaanga, H., & Yolgörmez, C. (2024). Abundant intelligences: Placing AI within Indigenous knowledge frameworks. AI & SOCIETY, 40(4), 2141–2157. https://doi.org/10.1007/s00146-024-02099-4 
",Abundant intelligences: Placing AI within Indigenous knowledge frameworks,Principles less-extractive,Decentering Western ontologies,Community impacts and relations,Cross-pipeline,Cross-pipeline,Era 3,ADC,A: critiques dominant epistemologies shaping AI; D: advances an Indigenous-led research agenda; C: positions community knowledge as foundation for future AI work,"White (published journal papers, conference proceedings, books)",Hand-searching key journals,Multiple areas; Indigenous knowledge; epistemology; AI research agenda; community authority,Multiple areas,Mixed,North America,"Department of Design and Computation Arts, Concordia University, Montréal, Canada","Te Putahi-a-Toi, Massey University, Palmerston North, New Zealand; Department of Design and Computation Arts, Concordia University, Montréal, Canada","Presents “Abundant Intelligences,” an Indigenous-majority research program. Argues current AI embeds colonial epistemologies; proposes rebuilding conceptual foundations through Indigenous knowledge systems. Links epistemic reframing to different data practices and community-beneficial trajectories for AI.",
"Li & Wu, 2024","Li, Q., & Wu, S. (2024). “I Want to Publicize My Stutter”: Community-led Collection and Curation of Chinese Stuttered Speech Data. Proc. ACM Hum.-Comput. Interact., 8(CSCW2), 475:1-475:27. https://doi.org/10.1145/3687014",“I Want to Publicize My Stutter”: Community-led Collection and Curation of Chinese Stuttered Speech Data,Practices less-extractive,Community engaged data production,"Data practices, Community impacts and relations",ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,ADC,A: develops speech AI datasets for stuttered speech; D: community curates and governs data; C: empowers community by embracing stuttering identity,"White (published journal papers, conference proceedings, books)",Database search,"Chinese language, stuttered speech, community-led data, disability empowerment",North America,NGO/Non-profit,North America,"AImpower.org, Seattle, Washington, USA","AImpower.org, Mountain View, California, USA","Documents a community-led initiative to collect stuttered speech data among Chinese speakers. Positions people with disabilities as active data curators rather than passive subjects. Shows how grassroots curation empowers participants to embrace identity, foster solidarity, and improve inclusivity in speech AI systems.",
"Li et al., 2023","Li, H., Vincent, N., Chancellor, S., & Hecht, B. (2023). The Dimensions of Data Labor: A Road Map for Researchers, Activists, and Policymakers to Empower Data Producers. 2023 ACM Conference on Fairness, Accountability, and Transparency, 1151–1161. https://doi.org/10.1145/3593013.3594070","The Dimensions of Data Labor: A Road Map for Researchers, Activists, and Policymakers to Empower Data Producers",Principles less-extractive,"Participatory data ownership & governance, Establishing consent and contextually appropriate compensation",Data labor,ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,ADC,"A: guidance for platforms/policy to embed rights; D: six dimensions (legibility, end-use awareness, etc.); C: strategies for collective action/empowerment","White (published journal papers, conference proceedings, books)",Database search,"data labor, legibility, end-use awareness, collaboration requirement, openness, replaceability, livelihood overlap",Not regionally specific,Academic,North America,"University of California, Berkely, USA","University of California, Davis, USA; University of Minnesota, USA; Northwestern University, USA","Argues that technology users who generate data should be recognized as data laborers. The authors highlight the power imbalance between these data producers and technology companies, emphasizing that data producers have little control over how their data is used or who profits from it. To address this, the paper proposes six dimensions of data labor: legibility, end-use awareness, collaboration requirement, openness, replaceability, and livelihood overlap. By analyzing data labor through these dimensions, the authors aim to provide researchers, activists, and policymakers with concrete strategies for empowering data producers, including advocating for data rights, fostering collective action, and promoting transparency in data use.",
"Liang et al., 2021","Liang, C. A., Munson, S. A., & Kientz, J. A. (2021). Embracing Four Tensions in Human-Computer Interaction Research with Marginalized People. ACM Trans. Comput.-Hum. Interact., 28(2), 14:1-14:47. https://doi.org/10.1145/3443686",Embracing Four Tensions in Human-Computer Interaction Research with Marginalized People,Principles less-extractive,Community engaged data production,"Data labor, Community impacts and relations",Deployment & Impact,Product Testing,Multi-era,DC,A: none; D: surfaces exploitation/membership/disclosure/allyship tensions and mitigation; C: centers participant well-being and equity,"White (published journal papers, conference proceedings, books)",Database search,North America; research ethics; marginalized groups; allyship,North America,Academic,North America,"University of Washington, USA",,"Examines the ethical complexities of conducting HCI research with marginalized groups. The authors, drawing on interviews with HCI researchers, identify four key tensions that researchers must navigate: exploitation, membership, disclosure, and allyship. Each tension represents a potential area of harm that could occur when engaging with marginalized participants and researchers, and the article explores how these tensions can manifest in the relationship between the researcher and participant, the researcher and other researchers, and the influence of the broader HCI field on these interactions. The authors argue that while complete resolution of these tensions may not be possible, researchers must recognize them, strive to mitigate potential harms, and engage in ongoing reflection on their own practices and the systemic biases within HCI.",
"Liesenfeld & Dingemanse, 2024","Liesenfeld, A., & Dingemanse, M. (2024). Rethinking open source generative AI: Open washing and the EU AI Act. The 2024 ACM Conference on Fairness, Accountability, and Transparency, 1774–1787. https://doi.org/10.1145/3630106.3659005",Rethinking open source generative AI: Open washing and the EU AI Act,Extractive,Keeping communities in the dark through opaque data practices,"Data practices, Ethics frameworks",ML System Design & Development,Model Architecture Selection & Design,Era 3,AD,A: analyzes generative AI systems claiming open-source status; D: surveys transparency in training datasets and documentation; C: none (indirect implications),"Grey (Reports, blogs, white papers, policy documents, theses, conference papers)",Hand-searching key journals,"open-source AI, open washing, transparency",EU/UK,Academic,EU/UK,"Radboud Universtiy, Netherlands",,"Overview assessment of concept of open-source generative AI, exploring the challenges posed by “open-washing” and the implications of the EU AI Act. The authors argue that openness in generative AI is not a simple binary but rather a composite and gradient characteristic, encompassing various dimensions from training datasets and licensing to documentation and access methods. They surveyed over 45 generative AI systems, revealing that many models claiming to be open source are, in reality, merely “open weight,” withholding crucial information about training data and methods. This lack of transparency, they contend, undermines scientific scrutiny, accountability, and informed decision-making. The authors advocate for evidence-based openness assessments using a multi-dimensional framework to ensure meaningful transparency and responsible development within the field of generative AI.",
"Lignos et al., 2022","Lignos, C., Holley, N., Palen-Michel, C., & Sälevä, J. (2022). Toward More Meaningful Resources for Lower-resourced Languages. In S. Muresan, P. Nakov, & A. Villavicencio (Eds.), Findings of the Association for Computational Linguistics: ACL 2022 (pp. 523–532). Association for Computational Linguistics. https://doi.org/10.18653/v1/2022.findings-acl.44",Toward More Meaningful Resources for Lower-resourced Languages,Principles less-extractive,"Early co-design and participatory initiatives, Community engaged data production, Creating culturally inclusive datasets","Community impacts and relations, Data labor, Data practices",ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,ADC,A: targets NLP dataset development for lower-resourced languages; D: evaluates quality and proposes participatory annotation; C: centers speaker involvement for equity and inclusion.,"White (published journal papers, conference proceedings, books)",Citation/reference snowballing,global; lower-resourced language; dataset; equity,Not regionally specific,Academic,North America,"Michtom School of Computer Science
Brandeis University, USA",,Critiques current multilingual datasets for lower-resourced languages. Finds errors in Wikidata and WikiAnn such as mislabeled entries and non-native representation. Advocates participatory annotation with speakers to improve quality and inclusivity. Proposes guidelines for ethical dataset creation involving communities. Links resource quality to equity in language technologies and representation of underserved languages.,
"Lilley et al., 2024","Lilley, S., Oliver, G., Cranefield, J., & Lewellen, M. (2024). Māori data sovereignty: Contributions to data cultures in the government sector in New Zealand. Information, Communication & Society, 27(16), 2801–2816. https://doi.org/10.1080/1369118X.2024.2302987 
",Māori data sovereignty: Contributions to data cultures in the government sector in New Zealand,Practices less-extractive,Participatory data ownership & governance,Community impacts and relations,Cross-pipeline,Cross-pipeline,Multi-era,DC,A: none; D: analyzes governance and organizational uptake of Māori data sovereignty; C: centers Māori tino-rangatiratanga and collective well-being,"White (published journal papers, conference proceedings, books)","Existing networks, relevant organizations and conferences","Oceania, Aotearoa New Zealand, data sovereignty, Māori self-determination",Oceania,Academic,Oceania,"Department of Human Centred Computing, Monash University, Melbourne, Australia; Faculty of Information Technology at Monash University, Australia; School of Information Management at Victoria University of Wellington, New Zealand",,"Examines how Māori data sovereignty principles are shaping government and organizational data cultures in Aotearoa New Zealand. Drawing on interviews with data professionals, the article highlights values of tino-rangatiratanga, whanaungatanga, and kotahitanga as guiding frameworks. Findings show growing recognition of Māori-led governance but also persistent power imbalances and limited institutional awareness. Argues that applying kaupapa Māori approaches to data management is critical for fostering inclusive and rights-based data cultures that advance Indigenous aspirations",
"Lin et al., 2024","Lin, H., Karusala, N., Okolo, C. T., D’Ignazio, C., & Gajos, K. Z. (2024). “Come to us first”: Centering Community Organizations in Artificial Intelligence for Social Good Partnerships. Proc. ACM Hum.-Comput. Interact., 8(CSCW2), 470:1-470:28. https://doi.org/10.1145/3687009 
", “Come to us first”: Centering Community Organizations in Artificial Intelligence for Social Good Partnerships,Practices less-extractive,Early co-design and participatory initiatives,Community impacts and relations,Problem Understanding & Formulation,Institutional Prioritization & Funding,Era 3,ADC,A: discusses AI4SG development partnerships; D: analyzes data and project governance in collaborations; C: centers community organizations’ perspectives and aspirations,"White (published journal papers, conference proceedings, books)",Hand-searching key journals,multiple areas; AI4SG; community organization; partnership,Multiple areas,Mixed,North America,"Harvard University, USA","The Brookings Institution, Washington, DC, USA; MIT, Cambridge, Massachusetts, USA","Examines AI for Social Good (AI4SG) partnerships with community organizations. Sixteen interviews with non-profits and agencies analyzed via Data Feminism framework. Finds organizations contribute labor and ideas but are sidelined by funders and AI teams. Only two of fourteen projects deployed. Proposes “data co-liberation” and co-leadership for sustainable, ethical collaborations",
"LingoAI, n.d.","LingoAI. (n.d.). LingoAI | Home. Retrieved September 7, 2025, from https://lingoai.io/",LingoAI,Practices less-extractive,Crowdsourcing data collection,"Community impacts and relations, Data practices",ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,ADC,"A: positions platform for AI data provisioning; D: enables decentralized, verified crowdsourcing and data custody controls; C: frames “people’s AI” via shared value and safer exchange","Grey (Reports, blogs, white papers, policy documents, theses, conference papers)","Existing networks, relevant organizations and conferences",global; decentralized data; crowdsourcing; verification,Multiple areas,Industry,APAC (Asia-Pacific Region),"LingoAI, Singapore",,"A decentralized data platform using verification and separation-of-concerns protocols to crowdsource, govern, and deploy AI data. Emphasizes data sovereignty and privacy-preserving exchanges. Claims aim to widen participation in AI data production and yield community benefit through controlled contribution and reuse; concrete adoption details should be validated in future empirical studies.",
"Liu et al., 2022","Liu, Z., Richardson, C., Hatcher, R., & Prud’hommeaux, E. (2022). Not always about you: Prioritizing community needs when developing endangered language technology. In S. Muresan, P. Nakov, & A. Villavicencio (Eds.), Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) (pp. 3933–3944). Association for Computational Linguistics. https://doi.org/10.18653/v1/2022.acl-long.272",Not always about you: Prioritizing community needs when developing endangered language technology,Practices less-extractive,Taking a needs-based approach to developing AI,"Critical theory/Historical background, Community impacts and relations",Problem Understanding & Formulation,Product Conception & Design,Multi-era,ADC,"A: develops language tech with endangered communities; D: frames collaboration around needs and ownership; C: foregrounds elders, teachers, and cultural priorities","White (published journal papers, conference proceedings, books)","Existing networks, relevant organizations and conferences",endangered language tech; Indigenous communities; community needs,Not regionally specific,Academic,North America,"Boston College, USA","University of California, Davis; University at Buffalo; Boston College, USA","Investigates the challenges of developing language technology for endangered languages, highlighting the significant differences compared to well-resourced languages. The authors use the metaphor of three speech communities – Elephant, Ocelot, and Coyote – to illustrate the varying levels of resources and support available to languages with different speaker populations. The paper emphasizes that the “one-size-fits-all” approach to language technology development is inappropriate for endangered languages, as it often fails to consider the unique cultural, practical, and ethical considerations involved. Drawing on perspectives from language teachers, elders, and a case study of the Cayuga language, the authors advocate for a collaborative approach to language technology development that prioritizes the needs and preferences of endangered speech communities. They conclude by providing recommendations for ethical collaborations between researchers and indigenous communities, emphasizing the importance of building meaningful bonds, respecting data ownership, and ensuring the accessibility and usefulness of developed technologies for language revitalization efforts.",
"Liu et al., 2024","Liu, R., Wei, J., Liu, F., Si, C., Zhang, Y., Rao, J., Zheng, S., Peng, D., Yang, D., Zhou, D., & Dai, A. M. (2024). Best Practices and Lessons Learned on Synthetic Data (No. arXiv:2404.07503). arXiv. https://doi.org/10.48550/arXiv.2404.07503",Best Practices and Lessons Learned on Synthetic Data,Extractive,Reproducing biases through synthetic data generation,Data practices,ML System Design & Development,Model Training & Evaluation,Era 3,AD,"A: addresses synthetic data impact on AI model development; D: examines data scaling, quality, and generation practices; C: none (indirect implications)","White (published journal papers, conference proceedings, books)",Citation/reference snowballing,"synthetic data, model training, data scaling",Not regionally specific,Mixed,North America,"Google DeepMind, USA","Stanford University, Georgia Institute of Technology, USA","Explores the rapidly growing field of synthetic data and its impact on AI model development. It addresses how synthetic data is being used to overcome limitations like data scarcity, privacy concerns, and high costs associated with real-world datasets. The authors present current research, applications in training and evaluation, and the challenges of ensuring factuality, fidelity, and unbiasedness. A key emphasis is on the responsible use of synthetic data to create powerful, inclusive, and trustworthy language models, while also acknowledging and addressing potential misuses and limitations. Finally, the paper offers future research directions such as synthetic data scaling, quality improvement, and scalable oversight to improve the trustworthiness of AI technologies.",
"Longpre et al., 2024a","Longpre, S., Singh, N., Cherep, M., Tiwary, K., Materzynska, J., Brannon, W., Mahari, R., Dey, M., Hamdy, M., Saxena, N., Anis, A. M., Alghamdi, E. A., Chien, V. M., Obeng-Marnu, N., Yin, D., Qian, K., Li, Y., Liang, M., Dinh, A., … Kabbara, J. (2024). Bridging the Data Provenance Gap Across Text, Speech and Video (No. arXiv:2412.17847). arXiv. https://doi.org/10.48550/arXiv.2412.17847","Bridging the Data Provenance Gap Across Text, Speech and Video",Extractive,Keeping communities in the dark through opaque data practices,Data practices,ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,AD,A: analyzes AI datasets across modalities; D: documents provenance and licensing gaps; C: none,"White (published journal papers, conference proceedings, books)",Iterative keyword search,"Data provenance, multimodal data, linguistic representation, dataset licenses",Not regionally specific,Mixed,North America,"Data Provenance Institute, USA",,"Large-scale audit of ~4,000 datasets spanning text, speech, and video. Analyzes sourcing trends, licensing, and geographic/linguistic representation. Finds increasing reliance on web and social media sources, inconsistent licenses and restrictions, and persistent representational imbalance. Releases an audit, data, and tools to improve transparency and inform data creators and developers.",
"Longpre et al., 2024b","Longpre, S., Mahari, R., Obeng-Marnu, N., Brannon, W., South, T., Kabbara, J., & Pentland, S. (2024). Data Authenticity, Consent, and Provenance for AI Are All Broken: What Will It Take to Fix Them? An MIT Exploration of Generative AI. https://doi.org/10.21428/e4baedd9.a650f77d","Data Authenticity, Consent, and Provenance for AI Are All Broken: What Will It Take to Fix Them?",Extractive,Keeping communities in the dark through opaque data practices,Data practices,ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,AD,A: diagnoses failures in consent and provenance for AI; D: recommends structured documentation and governance; C: none,"White (published journal papers, conference proceedings, books)",Iterative keyword search,data provenance; regulation; transparency,Not regionally specific,Mixed,North America,"MIT, USA",,"Analysis of broken data authenticity, consent, and provenance in AI and proposes a multi-stakeholder approach to fix them. It argues that the current lack of transparency in AI training data leads to ethical, legal, and transparency crises. The authors call for a unified framework for structured documentation of data properties, involving data creators, AI developers, lawmakers, and researchers. The paper further analyzes existing data provenance solutions, highlighting their limitations, and concludes with recommendations for establishing a standardized data infrastructure to foster responsible and trustworthy AI development.",
"Longpre et al., 2024c","Longpre, S., Mahari, R., Chen, A., Obeng-Marnu, N., Sileo, D., Brannon, W., Muennighoff, N., Khazam, N., Kabbara, J., Perisetla, K., Wu, X. (Alexis), Shippole, E., Bollacker, K., Wu, T., Villa, L., Pentland, S., & Hooker, S. (2024). A large-scale audit of dataset licensing and attribution in AI. Nature Machine Intelligence, 6(8), 975–987. https://doi.org/10.1038/s42256-024-00878-8",A large-scale audit of dataset licensing and attribution in AI. Nature Machine Intelligence,Extractive,Collecting vast amounts of data to train AI systems,Data practices,ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,ADC,"A: audits text-dataset licensing at scale; D: traces provenance and license quality across 1,800+ datasets; C: surfaces misattribution risks affecting creators and users","White (published journal papers, conference proceedings, books)",Citation/reference snowballing,global; dataset licensing; provenance; attribution,Multiple areas,Mixed,North America,"MIT, MA, USA; Media Lab, Massachusetts Institute of Technology, Cambridge, MA, USA
Harvard Law School, Harvard University, Cambridge, MA, USA (first 2 authors contributed equally)","University of California, Irvine, CA, USA; Inria Centre, University of Lille, Lille, France; Contextual AI, Mountain View, CA, USA; University of Colorado Boulder, Boulder, CO, USA; Data Provenance Initiative, Cambridge, MA, USA:Olin College of Engineering, Needham, MA, USA; Teraflop AI, Boca Raton, FL, USA; ML Commons, San Francisco, CA, USA; Carnegie Mellon University, Pittsburgh, PA, USA; Tidelift, Boston, MA, USA; Cohere For AI, Toronto, Ontario, Canada","Conducts a cross-dataset licensing audit and builds tools to trace sources, creators, and licenses. Finds high omission/error rates on hosting platforms and sharper restrictions for low-resource languages and creative tasks. Releases the Data Provenance Explorer to enable filtering by source and license. Argues that opacity and misattribution in training data undermine accountability and fair value flows, with downstream risks for affected creators and communities.",
"Lotfian et al., 2021","Lotfian, M., Ingensand, J., & Brovelli, M. A. (2021). The Partnership of Citizen Science and Machine Learning: Benefits, Risks, and Future Challenges for Engagement, Data Collection, and Data Quality. Sustainability, 13(14), Article 14. https://doi.org/10.3390/su13148087","The Partnership of Citizen Science and Machine Learning: Benefits, Risks, and Future Challenges for Engagement, Data Collection, and Data Quality",Principles less-extractive,Community engaged data production,Community impacts and relations,ML System Design & Development,"Data Selection, Collection & Annotation",Multi-era,ADC,A: connects ML methods with citizen-science pipelines; D: evaluates engagement and data-quality practices; C: weighs benefits/risks for volunteers and communities,"White (published journal papers, conference proceedings, books)",Database search,EU/UK; citizen science; machine learning; engagement; data quality,Not regionally specific,Academic,EU/UK,"HES-SO, University of Applied Sciences Western Switzerland","Politecnico di Milano, Italy","Review article exploring the burgeoning synergy between citizen science and machine learning (ML). Citizen science, engaging the public in scientific research, is producing large datasets ideal for training ML algorithms. The article examines various use cases across fields like environmental science, astronomy, and neuroscience. It finds ML can automate tasks in citizen science projects, such as species identification from images, classifying galaxies, or validating data quality. The authors argue this partnership benefits both fields, offering new insights, enhancing data collection, and improving engagement. However, the article also cautions about potential risks, including ethical considerations around data privacy and the potential displacement of volunteers if tasks become fully automated.",
"Lovett et al., 2019","Lovett, R., Lee, V., Kukutai, T., Cormack, D., Carroll Rainie, S., & Walker, J. (2019). Good data practices for Indigenous Data Sovereignty and Governance. Institute of Network Cultures. http://hdl.handle.net/1885/300245",Good data practices for Indigenous Data Sovereignty and Governance,Principles less-extractive,Participatory data ownership & governance,"Community impacts and relations, Critical theory/Historical background",Problem Understanding & Formulation,Institutional Prioritization & Funding,Multi-era,DC,A: none; D: outlines Indigenous Data Governance operationalization; C: centers Indigenous peoples' rights to govern data about themselves,"White (published journal papers, conference proceedings, books)",Database search,"Indigenous data sovereignty, data governance, UNDRIP",Multiple areas,Industry,Oceania,"Australian National University, Australia",,"Explores Indigenous Data Sovereignty operationalization through Indigenous Data Governance frameworks. Traces historical data collection on Indigenous populations as colonial control tool. Uses UNDRIP framework for self-determination including data governance, drawing examples from Australia, Aotearoa New Zealand, and North America to advocate equitable practices.",
"Lu et al., 2024","Lu, Q., Zhu, L., Xu, X., Whittle, J., Zowghi, D., & Jacquet, A. (2024). Responsible AI Pattern Catalogue: A Collection of Best Practices for AI Governance and Engineering. ACM Computing Surveys, 56(7), 1–35. https://doi.org/10.1145/3626234",Responsible AI Pattern Catalogue: A Collection of Best Practices for AI Governance and Engineering,Principles less-extractive,Early co-design and participatory initiatives,"Data practices, Ethics frameworks",Problem Understanding & Formulation,Product Conception & Design,Era 3,ADC,A: compiles patterns for AI governance and engineering; D: systematizes responsible data and process practices; C: links practices to accountability across stakeholders,"White (published journal papers, conference proceedings, books)",Database search,global; responsible AI; governance; accountability,Not regionally specific,Industry,Oceania,"Data61 and CSIRO, Australia",,"Presents Responsible AI Pattern Catalogue bridging principles and practice. Multivocal review identifies governance, process, and product patterns across AI lifecycle. Provides practical guidance for risk assessment, privacy, and accountability. Classifies strategies into oversight, embedded processes, and system design, offering tools for aligning ethics with engineering. Positions pattern catalogue as pathway to responsible implementation.",
"MacDonald et al., 2021","MacDonald, R. L., Jiang, P.-P., Cattiau, J., Heywood, R., Cave, R., Seaver, K., Ladewig, M. A., Tobin, J., Brenner, M. P., Nelson, P. C., Green, J. R., & Tomanek, K. (2021). Disordered Speech Data Collection: Lessons Learned at 1 Million Utterances from Project Euphonia. Interspeech 2021, 4833–4837. https://doi.org/10.21437/Interspeech.2021-697 
",Disordered Speech Data Collection: Lessons Learned at 1 Million Utterances from Project Euphonia,Practices less-extractive,"Community engaged data production, Creating culturally inclusive datasets","Community impacts and relations, Data practices",ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,ADC,A: targets ASR inclusion for disordered speech; D: details large-scale participatory data collection and QA; C: improves access for speakers with impaired speech,"White (published journal papers, conference proceedings, books)",Database search,multiple areas; speech recognition; disordered speech; disability,Multiple areas,Mixed,North America,"Google Research, USA","MND Association, UK; MGH Institute of Health Professions, USA; Cerebral Palsy Associations of New York State, USA; Harvard University, USA ","Presents lessons from building a speech corpus of over one million utterances from people with disordered speech. Researchers collected both prompted and extemporaneous speech from more than 1,000 participants, applying quality checks and metadata standards. The findings reveal how inclusive corpus design improves ASR models while ensuring participants’ experiences remain central. Technical advances include better recognition performance and improved dataset usability, while social lessons emphasize collaboration with clinical and community partners. The project demonstrates how participatory data production can expand accessibility, linking dataset design and documentation directly to equitable AI applications for people with disabilities.",
"Mack et al., 2024","Mack, K. A., Qadri, R., Denton, R., Kane, S. K., & Bennett, C. L. (2024). “They only care to show us the wheelchair”: Disability representation in text-to-image AI models. Proceedings of the CHI Conference on Human Factors in Computing Systems, 1–23. https://doi.org/10.1145/3613904.3642166", “They only care to show us the wheelchair”: Disability representation in text-to-image AI models,Extractive,"""Deploying AI systems that lack local, contextual data""","Data practices, Community impacts and relations",ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,ADC,A: audits T2I outputs; D: identifies reductive training categories; C: centers disability community perspectives on harms,"White (published journal papers, conference proceedings, books)",Iterative keyword search,"disability, text-to-image, stereotypes",North America,Mixed,North America,"Paul G. Allen School of Computer Science and Engineering, University of Washington, USA; Google Research, USA",,"Eight focus groups with 25 disabled participants examined disability representation in T2I models. Findings showed outputs often reproduce reductive stereotypes—e.g., wheelchair users as default, sad, or inactive. Participants highlighted risks of reinforcing stigma. Authors propose design interventions such as diverse prompts, metadata, and training data reforms.",
"Mager et al., 2023","Mager, M., Mager, E., Kann, K., & Vu, N. T. (2023). Ethical Considerations for Machine Translation of Indigenous Languages: Giving a Voice to the Speakers (No. arXiv:2305.19474). arXiv. https://doi.org/10.48550/arXiv.2305.19474",Ethical Considerations for Machine Translation of Indigenous Languages: Giving a Voice to the Speakers ,Extractive,Scraping or repurposing sensitive data,"Community impacts and relations, Critical theory/Historical background",ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,ADC,A: examines machine translation systems for Indigenous languages; D: analyzes data collection and ownership practices; C: documents community concerns about cultural knowledge misuse and data sovereignty,"Grey (Reports, blogs, white papers, policy documents, theses, conference papers)",Database search,"Indigenous languages, machine translation, data sovereignty",Multiple areas,Mixed,North America,"AWS AI Labs, USA","Universidad Nacional Autónoma de México; University of Colorado Boulder, USA; University of Stuttgart, Germany","On MT for endangered Indigenous languages. Reviews ethical frameworks for language documentation and the potential harm of colonial approaches, emphasizing the importance of community consultation, respect for cultural values, and data ownership when working with Indigenous languages. To gather community perspectives, the authors conducted a survey and interviews with language activists, teachers, and community leaders from various Indigenous groups in the Americas. The study revealed a general desire for MT systems to support language revitalization, but also concerns about translation quality, misuse of cultural knowledge, and the need for data sovereignty. Gives recommendations for ethical MT development, highlighting the importance of collaboration, capacity building, and recognizing the agency of Indigenous communities in directing language technology research.",
"Magomere et al., 2024","Magomere, J., Ishida, S., Afonja, T., Salama, A., Kochin, D., Yuehgoh, F., Hamzaoui, I., Sefala, R., Alaagib, A., Semenova, E., Crais, L., & Hall, S. M. (2024). You are what you eat? Feeding foundation models a regionally diverse food dataset of World Wide Dishes (No. arXiv:2406.09496). arXiv. http://arxiv.org/abs/2406.09496",You are what you eat? Feeding foundation models a regionally diverse food dataset of World Wide Dishes,Practices less-extractive,"Creating culturally inclusive datasets, Community engaged data production, Crowdsourcing data collection","Data practices, Community impacts and relations",ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,ADC,"A: evaluates LLM/VLM cultural knowledge; D: builds decentralized, community-curated food dataset (765 dishes, 131 languages); C: exposes representational gaps, esp. for Africa","Grey (Reports, blogs, white papers, policy documents, theses, conference papers)",Database search,"multiple regions, Africa; vision-language; cultural representation",Multiple areas,Mixed,EU/UK,"University of Oxford, UK","Oxford Artificial Intelligence Society; Visual Geometry Group, University of Oxford; CISPA Helmholtz Center
for Information Security; AI Saturdays Lagos; Microsoft; Conservatoire National des Arts et Métiers, France; École nationale Supérieure
d’Informatique Algiers, Algeria; McGill University, Canada; Distributed Artificial Intelligence Research Institute, USA; Independent Researcher; Imperial College London; University of Oxford, UK","Introduces dataset, WORLD WIDE DISHES (WWD), designed to assess regional disparities in the performance and fairness of foundation models. This dataset, comprising 765 dishes spanning 131 languages, was collected through a decentralized, community-driven approach to capture local culinary expertise. The authors utilize WWD to evaluate common knowledge understanding in LLMs and investigate representational biases in Vision-Language Models (VLMs) tasked with generating food images. Their findings reveal that these models often fail to produce accurate and culturally sensitive representations of global dishes, particularly those from the African continent, pointing to the urgent need to address capability and representational biases in foundation models to prevent the reinforcement of stereotypes and the erasure of cultural diversity.",
"Maracle, 2024","Maracle, C. (2024, August 12). How AI can help Indigenous language revitalization, and why data sovereignty is important | CBC News. CBC News. https://www.cbc.ca/news/indigenous/ai-indigenous-languages-1.7290740","How AI can help Indigenous language revitalization, and why data sovereignty is important",Principles less-extractive,Community engaged data production,"Community impacts and relations, Critical theory/Historical background",ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,ADC,"A: discusses AI for Indigenous language tech; D: advocates community-led, sovereign data practices; C: centers Indigenous control and benefit","Grey (Reports, blogs, white papers, policy documents, theses, conference papers)","Existing networks, relevant organizations and conferences",North America; Indigenous languages; AI; data sovereignty; community control,North America,Journalist/Other/Not Sure,North America,"CBC (Canada News), Canada",,"News article about AI challenges and potentials in Indigenous language revitalization. Indigenous computer science experts, like Michael Running Wolf, believe that AI can be a valuable tool, comparing it to a “pencil,” but emphasize that it is not a singular solution. One significant challenge is the lack of data available for training AI systems in Indigenous languages, which are often polysynthetic and have fewer speakers. To address this, Running Wolf advocates for community-driven data collection and control, emphasizing the concept of data sovereignty to prevent exploitation and ensure that Indigenous communities retain ownership over their languages and cultural knowledge. Robbie Jimerson, who developed a speech recognition system for Seneca and Oneida, echoes the importance of community involvement and “sweat equity” in creating these valuable resources.",
"Marivate et al., 2023","Marivate, V., Mots’Oehli, M., Wagnerinst, V., Lastrucci, R., & Dzingirai, I. (2023). PuoBERTa: Training and Evaluation of a Curated Language Model for Setswana. In A. Pillay, E. Jembere, & A. J. Gerber (Eds.), Artificial Intelligence Research (pp. 253–266). Springer Nature Switzerland. https://doi.org/10.1007/978-3-031-49002-6_17",PuoBERTa: Training and Evaluation of a Curated Language Model for Setswana,Practices less-extractive,Creating culturally inclusive datasets,"Data practices, Community impacts and relations",ML System Design & Development,Model Training & Evaluation,Era 3,ADC,A: develops a Setswana-specific LM; D: curates monolingual corpus and new news categorization dataset; C: advances NLP capacity for an understudied language,"White (published journal papers, conference proceedings, books)",Citation/reference snowballing,Africa; Setswana NLP; curated corpus; evaluation,Africa,Academic,Africa,"Department of Computer Science, University of Pretoria, Hatfield, South Africa
Lelapa AI, Johannesburg, South Africa","University of Hawaii at Manoa, Honolulu, USA; Sol Plaatje University, Kimberley, South Africa; Department of Computer Science, University of Pretoria, Hatfield, South Africa","Trains PuoBERTa on a curated Setswana corpus; evaluates on POS, NER, and news categorization (introducing a new Setswana news dataset). Demonstrates improved performance and supplies initial benchmarks, strengthening NLP tooling for a low-resource African language.",
"Marivate, 2021","Marivate, V. (2021). Why African natural language processing now? A view from South Africa #AfricaNLP. In Z. Mazibuko-Makena & E. Kraemer-Mbula (Eds.), Leap 4.0. African Perspectives on the Fourth Industrial Revolution (pp. 126–152). Mapungubwe Institute for Strategic Reflection (MISTRA). https://doi.org/10.2307/jj.12406168.11 
",Why African natural language processing now? A view from South Africa #AfricaNLP,Practices less-extractive,Creating culturally inclusive datasets,Community impacts and relations,Cross-pipeline,Cross-pipeline,Era 3,ADC,A: NLP systems landscape; D: data scarcity/creation for SA languages; C: argues benefits/needs for African communities,"White (published journal papers, conference proceedings, books)","Existing networks, relevant organizations and conferences",Africa; nlp; low-resource language; data scarcity; inclusion,Africa,Academic,Africa,"University of Pretoria, South Africa",,"Outlines why African languages must be central to AI’s future. Explains how low-resource conditions constrain model development and deployment, then maps practical data creation pathways for South African languages. Uses a soft-systems lens to structure challenges and solutions. Links targeted corpus building and community partnerships to equitable access and relevance for African users.",
"Martin et al., 2020","Martin, D. Jr., Prabhakaran, V., Kuhlberg, J., Smart, A., & Isaac, W. S. (2020). Participatory Problem Formulation for Fairer Machine Learning Through Community Based System Dynamics (No. arXiv:2005.07572). arXiv. https://doi.org/10.48550/arXiv.2005.07572  
",Participatory Problem Formulation for Fairer Machine Learning Through Community Based System Dynamics,Principles less-extractive,Decentering Western ontologies,"Data practices, Community impacts and relations",Problem Understanding & Formulation,Product Conception & Design,Era 3,ADC,A: targets fairness at problem formulation; D: introduces CBSD to elicit system dynamics; C: includes typically excluded stakeholders in agenda-setting,"White (published journal papers, conference proceedings, books)","Existing networks, relevant organizations and conferences",problem formulation; CBSD; fairness; stakeholder participation,Not regionally specific,Mixed,North America,Google,"Google; System Stars; DeepMind, USA/UK","Argues bias emerges in problem formulation. Introduces Community-Based System Dynamics to surface domain complexities and stakeholder perspectives before modeling. Demonstrates a structured, participatory method to align ML objectives with community needs and fairness outcomes.",
"Martinez & Squire, 2024","Martinez, R., & Squire, K. (2024). Engaging recently incarcerated and gang affiliated Black and Latino/a young adults in designing social collocated applications for mixed reality smart glasses through community-based participatory design workshops. Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems, 1–17. https://doi.org/10.1145/3613904.3642895",Engaging recently incarcerated and gang affiliated Black and Latino/a young adults in designing social collocated applications for mixed reality smart glasses through community-based participatory design workshops,Practices less-extractive,Early co-design and participatory initiatives,"Community impacts and relations, Data practices",Problem Understanding & Formulation,Product Conception & Design,Era 3,ADC,A: applies CBPD to emerging MR systems; D: elicits embodied design elements from participants; C: surfaces critique of exclusionary institutions and supports democratic tech design,"White (published journal papers, conference proceedings, books)",Database search,"USA, participatory design, mixed reality, marginalized youth",Multiple areas,Academic,North America,"Informatics/ Donald Bren School of Information and Computer Sciences (ICS)/ Games+Learning+Society Lab, Connected Learning Lab, CREATE Lab, University of Califiornia Irvine, USA",,"Design-based implementation research and community-based participatory design with recently incarcerated and gang-affiliated youth. Workshops elicit embodied design concepts for social, co-located MR uses, surfacing emotions and lived experience while critiquing exclusionary institutions. Contributes recommendations for MR interactions and demonstrates how participatory methods can democratize early-stage AI/AR design.",
"Medrado & Verdegem, 2024","Medrado, A., & Verdegem, P. (2024). Participatory action research in critical data studies: Interrogating AI from a South–North approach. Big Data & Society, 11(1),  https://doi.org/10.1177/20539517241235869",Participatory action research in critical data studies: Interrogating AI from a South–North approach,Practices less-extractive,Early co-design and participatory initiatives,"Community impacts and relations, Critical theory/Historical background",Problem Understanding & Formulation,Product Conception & Design,Era 3,ADC,"A: critiques AI exclusion of Global South perspectives; D: applies PAR as data production method; C: foregrounds justice, empathy, and collaborative knowledge creation.","White (published journal papers, conference proceedings, books)",Database search,LatAm; participatory action research; data justice; Global South,EU/UK,Academic,EU/UK,"University of Westminster, UK",,"Applies participatory action research (PAR) from Latin American traditions to AI and data justice. Workshops in London illustrate collaborative knowledge creation surfacing concerns about empathy, autonomy, and dialogue. Argues conventional AI marginalizes Global South perspectives, reproducing inequality. PAR reframes debates by elevating excluded voices and fostering solidarity across regions.",
"Meighan, 2021","Meighan, P. J. (2021). Decolonizing the digital landscape: The role of technology in Indigenous language revitalization. AlterNative: An International Journal of Indigenous Peoples, 17(3), 397–405. https://doi.org/10.1177/11771801211037672",Decolonizing the digital landscape: The role of technology in Indigenous language revitalization,Principles less-extractive,"Participatory data ownership & governance, Decentering Western ontologies","Community impacts and relations, Critical theory/Historical background",Cross-pipeline,Cross-pipeline,Multi-era,ADC,A: applies to AI-adjacent language tech ecosystems; D: maps ILR use across Web 1.0–3.0; C: highlights community control and cultural expression,"White (published journal papers, conference proceedings, books)",Database search,Scotland; Turtle Island; ILR; technology,Multiple areas,Academic,North America,"McGill University, Canada",,"Argues that technology is not a neutral tool and has historically reflected dominant Western perspectives, but Indigenous communities are actively reclaiming technology to revitalize their languages. The article analyzes the evolution of technology used in ILR through three eras: Web 1.0, Web 2.0, and Web 3.0. While early initiatives focused on disseminating digital information, recent trends highlight a shift towards Indigenous communities becoming creators and negotiators of technology. Meighan emphasizes the importance of decolonizing the digital landscape by ensuring that Indigenous languages and worldviews are represented and celebrated online. The article concludes on an optimistic note, pointing to a future where technology can be a powerful tool for Indigenous language reclamation and cultural expression.",
"Mejias & Couldry, 2024","Mejias, U. A., & Couldry, N. (2024). Data Grab: The New Colonialism of Big Tech and How to Fight Back. University of Chicago Press.",Data Grab: The New Colonialism of Big Tech and How to Fight Back,Extractive,"Collecting vast amounts of data to train AI systems, Soliciting data without reciprocal benefits, Prioritizing data wants over community needs","Community impacts and relations, Critical theory/Historical background",Cross-pipeline,Cross-pipeline,Era 3,DC,A: none (indirect implications); D: theorizes data colonialism as extraction without return; C: documents harms and community resistance strategies,"White (published journal papers, conference proceedings, books)","Existing networks, relevant organizations and conferences",Global South; data colonialism; extraction; resistance,Not regionally specific,Academic,North America,"State University of New York, USA","London School of Economics, UK; Harvard, MA, USA","Traces how Big Tech consolidates power through systematic data capture that mirrors colonial resource extraction. Details how platform infrastructures convert life into data assets without reciprocity, deepening inequality and enabling discriminatory systems. Surveys resistance—legal, labor, and community organizing—and articulates pathways to reassert control. Frames “data grab” as a political economy of extraction that reorders social life and demands countermeasures grounded in justice.",
"Mezzadra & Neilson, 2017","Mezzadra, S., & Neilson, B. (2017). On the multiple frontiers of extraction: Excavating contemporary capitalism. Cultural Studies, 31(2–3), 185–204. https://doi.org/10.1080/09502386.2017.1303425",On the multiple frontiers of extraction: Excavating contemporary capitalism,Extractive,Soliciting data without reciprocal benefits,Data practices,Problem Understanding & Formulation,Institutional Prioritization & Funding,Multi-era,DC,"A: none; D: analyzes extraction across logistics, finance, and digital domains; C: examines appropriation of social cooperation and human activity","White (published journal papers, conference proceedings, books)",Database search,"extraction, contemporary capitalism, data appropriation",Not regionally specific,Academic,EU/UK,"University of Bologna, Italy","Western Sydney University, Australia","Argues that the concept of ""extraction"" in contemporary capitalism should be understood beyond its traditional association with mining and agribusiness. They propose the idea of ""operations of capital"" to highlight the extractive nature of capitalist activities across various domains like logistics and finance. The authors emphasize that extraction involves not only the physical removal of resources but also the appropriation of social cooperation, human activity, and data. They examine different manifestations of extraction in the digital realm, biocapitalism, urban landscapes, and even within the realm of finance, highlighting the interconnection between these diverse forms of extraction. ",
"Mhlambi & Tiribelli, 2023","Mhlambi, S., Tiribelli, S. Decolonizing AI Ethics: Relational Autonomy as a Means to Counter AI Harms. Topoi 42, 867–880 (2023). https://doi.org/10.1007/s11245-022-09874-2",Decolonizing AI Ethics: Relational Autonomy as a Means to Counter AI Harms,Principles less-extractive,Decentering Western ontologies,"Ethics frameworks, Critical theory/Historical background",Problem Understanding & Formulation,Product Conception & Design,Era 3,AD,A: critiques autonomy in mainstream AI ethics; D: proposes relational autonomy grounded in Ubuntu; C: none (indirect implications),"White (published journal papers, conference proceedings, books)",Database search,ethics; relational autonomy; Ubuntu; harms,Not regionally specific,Academic,North America,"Harvard University, USA",,"Critiques liberal autonomy as insufficient for AI harms affecting marginalized populations. Reframes autonomy as relational, drawing on Ubuntu and moral philosophy. Provides normative guidance for AI design and governance, shifting evaluative focus from isolated individuals to networks of care and obligation.",
"Miceli & Posada, 2022","Miceli, M., & Posada, J. (2022). The Data-Production Dispositif. Proceedings of the ACM on Human-Computer Interaction, 6(CSCW2), 1–37. https://doi.org/10.1145/3555561",The Data-Production Dispositif,Extractive,Exploitative and invisible data labor,Data labor,ML System Design & Development,"Data Selection, Collection & Annotation",Multi-era,ADC,A: analyzes machine learning dataset creation; D: examines task instructions and classification practices; C: documents precarious working conditions and power imbalances affecting Latin American workers,"White (published journal papers, conference proceedings, books)",Citation/reference snowballing,"AI data work, microwork platforms, typology","LatAm (includes Central America, South America & Carribbean)",Academic,EU/UK,"DAIR institute, USA; TU Berlin and Weizenbaum Institute, Germany","Yale University, USA","Analyzes human labor in machine learning dataset creation through task instructions and interviews with workers and managers. Identifies ""data-production dispositif"" that normalizes worker exploitation by prioritizing speed and obedience over well-being. Finds normalized classifications and binary categories in instructions shape data labeling while marginalizing worker input and agency.",
"Miceli et al., 2021","Miceli, M., Yang, T., Naudts, L., Schuessler, M., Serbanescu, D., & Hanna, A. (2021). Documenting Computer Vision Datasets: An Invitation to Reflexive Data Practices. Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency, 161–172. https://doi.org/10.1145/3442188.3445880",Documenting Computer Vision Datasets: An Invitation to Reflexive Data Practices,Principles less-extractive,Building public visibility in dataset development,"Data practices, Data labor",ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,AD,"A: links to AI through dataset documentation for computer vision; D: surfaces production contexts and data worker practices;
C: none (implicit and indirect)","White (published journal papers, conference proceedings, books)",Database search,"Dataset documentation, computer vision, labor",Multiple areas,Mixed,EU/UK,"Technische Universität Berlin, Germany","Centre for IT & IP Law (CiTiP), KU Leuven, BE;
Google Research, USA","Ethnography/interviews at two data-processing firms plus 30 interviews show why documentation rarely captures labor and decision histories. Proposes reflexive documentation to render context, incentives, and power visible—improving accountability for how CV datasets are made and maintained.",
"Mihalcea et al., 2024","Mihalcea, R., Ignat, O., Bai, L., Borah, A., Chiruzzo, L., Jin, Z., Kwizera, C., Nwatu, J., Poria, S., & Solorio, T. (2025). Why AI is WEIRD and shouldn’t be this way: Towards AI for everyone, with everyone, by everyone. Proceedings of the Thirty-Ninth AAAI Conference on Artificial Intelligence and Thirty-Seventh Conference on Innovative Applications of Artificial Intelligence and Fifteenth Symposium on Educational Advances in Artificial Intelligence, 39, 28657–28670. https://doi.org/10.1609/aaai.v39i27.35092 
","Why AI Is WEIRD and Should Not Be This Way: Towards AI For Everyone, With Everyone, By Everyone",Principles less-extractive,Creating culturally inclusive datasets,"Data practices, Community impacts and relations",Cross-pipeline,Cross-pipeline,Era 3,ADC,"A: argues WEIRD AI underperforms globally; D: recommends diverse data, teams, and metrics; C: centers inclusion and equitable benefit","White (published journal papers, conference proceedings, books)",Citation/reference snowballing,global; AI inclusion; data diversity; evaluation,Not regionally specific,Academic,North America,University of Michigan USA,"Santa Clara University; Universidad de la Republica Uruguay; Max Plank Institute; CMU Africa; Singapore University of Technology and Design, Singapore; MBZUAI, UAE","Argues for a fundamental shift towards inclusive AI systems that are developed for everyone, with everyone, and by everyone. The authors identify that current AI development is ""WEIRD"" (Western, Educated, Industrialized, Rich, and Democratic), leading to data biases, uneven model performance, and a lack of cultural knowledge. They propose actionable recommendations across the entire AI pipeline, from data collection and annotation to model design and evaluation, emphasizing the need for diverse teams, fair incentives, and a focus on real-world applications to ensure that AI benefits all of humanity, not just a privileged segment. The text is structured around five key areas, data, models, evaluations, incentives and people",
"Milan & Treré, 2019 ","Milan, S., & Treré, E. (2019). Big Data from the South(s): Beyond Data Universalism. Television & New Media, 20(4), 319–335. https://doi.org/10.1177/1527476419837739",Big Data from the South(s): Beyond Data Universalism,Principles less-extractive,Decentering Western ontologies,"Community impacts and relations, Critical theory/Historical background",Problem Understanding & Formulation,Institutional Prioritization & Funding,Era 2,DC,A: none (agenda for data studies broadly); D: critiques data universalism and proposes de-Westernizing operations; C: centers agency and epistemic justice in the Global South,"White (published journal papers, conference proceedings, books)",Citation/reference snowballing,Latin America; Global South; data universalism; decolonial theory,"LatAm (includes Central America, South America & Carribbean)",Academic,EU/UK,"University of Amsterdam, NL","School of Journalism, Media and Culture, Cardiff University, UK","Introduces the concept of “Big Data from the South(s)” as a framework for challenging the “data universalism” that dominates current data studies. The authors argue that existing research often overlooks the unique experiences and challenges of the Global South, where datafication can exacerbate existing inequalities and power imbalances. They propose five key operations to de-Westernize data studies: moving beyond data universalism, understanding the South as a plural entity, engaging with decolonial theory, re-centering agency, and exploring new data imaginaries emerging from the margins. By highlighting the perspectives and experiences of the Global South, this research agenda seeks to promote epistemic justice and develop more inclusive and equitable approaches to datafication.",
"Milan & Treré, 2024","Milan, S., & Treré, E. (2024). Against decolonial reductionism: The impact of Latin American thinking on the data decolonization project. Big Data & Society, 11(4), 20539517241270694. https://doi.org/10.1177/20539517241270694",Against decolonial reductionism: The impact of Latin American thinking on the data decolonization project,Principles less-extractive,Decentering Western ontologies,"Community impacts and relations, Critical theory/Historical background",Problem Understanding & Formulation,Institutional Prioritization & Funding,Era 3,DC,A: none; D: critiques reductionist invocations of decoloniality in data contexts; C: foregrounds Latin American traditions and community-grounded alternatives,"White (published journal papers, conference proceedings, books)",Hand-searching key journals,"decolonial reductionism, datafied society, social movements, epistemic disobedience, multilingualism, public scholarship, mentorship","LatAm (includes Central America, South America & Carribbean)",Academic,EU/UK,"University of Amsterdam, Amsterdam, the Netherlands",,"Argues that Latin American scholarship offers crucial insights for decolonizing our understanding of datafication. It highlights the Big Data from the South Initiative (BigDataSur) as an example, emphasizing how it draws inspiration from Latin American thinkers like Martín-Barbero, Freire, and Mignolo. The authors caution against ""decolonial reductionism,"" where decolonial ideas are superficially invoked without genuine practical commitment. The text concludes by outlining practical strategies like multilingualism, public scholarship, and mentorship to foster a more open and inclusive dialogue on alternative approaches to datafication and knowledge production.",
"Milner & Traub, 2021","Milner, Y., & Traub, A. (2021). Data Capitalism and Algorithmic Racism. Demos. https://www.demos.org/research/data-capitalism-and-algorithmic-racism",Data Capitalism and Algorithmic Racism,Extractive,Collecting vast amounts of data to train AI systems,Critical theory/Historical background,Cross-pipeline,Cross-pipeline,Multi-era,ADC,A: connects algorithmic systems to racialized extraction; D: critiques data commodification across sectors; C: proposes reforms to empower impacted communities,"Grey (Reports, blogs, white papers, policy documents, theses, conference papers)","Existing networks, relevant organizations and conferences","data capitalism, algorigthmic racism, harm",North America,NGO/Non-profit,North America,"Data for Black Lives; Demos, USA",,"Argues that data capitalism, an economic model built on the extraction and commodification of data, exacerbates racial and economic inequalities. The report details how data capitalism is rooted in chattel slavery and has evolved into ubiquitous surveillance and algorithmic decision-making that reinforces existing power disparities. The authors outline the problem of data capitalism in various spheres, including the workplace, the consumer marketplace, and the public sphere, highlighting how algorithms and automated decisions often perpetuate racial bias. The report concludes with a call to action, urging policymakers, movement leaders, and thinkers to address the challenges posed by data capitalism through transparency, regulation, structural change, and governance. These solutions aim to democratize data, provide equitable access to technology, and empower communities most impacted by data capitalism's harmful effects.",
"Mitchell et al., 2019","Mitchell, M., Wu, S., Zaldivar, A., Barnes, P., Vasserman, L., Hutchinson, B., Spitzer, E., Raji, I. D., & Gebru, T. (2019). Model Cards for Model Reporting. Proceedings of the Conference on Fairness, Accountability, and Transparency, 220–229. https://doi.org/10.1145/3287560.3287596 
",Model Cards for Model Reporting,Practices less-extractive,Building public visibility in dataset development,Data practices,ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,ADC,A: formalizes model reporting; D: specifies standardized documentation of performance across subgroups/contexts; C: supports user/community understanding and limits misuse,"White (published journal papers, conference proceedings, books)",Database search,"dataset development, accountability, documentation, framework",Not regionally specific,Mixed,North America,"Google LLC, USA","University of California, Berkeley, USA","Introduces “model cards,” concise documentation accompanying trained models. Cards report intended use, evaluation procedures, and performance across demographic/phenotypic and intersectional groups. Demonstrates cards for vision and NLP models, arguing standardized reporting curbs misuse, clarifies limits, and improves accountability. Links model transparency to upstream data and evaluation choices with implications for impacted communities.",
"Mohamed et al., 2020","Mohamed, S., Png, M.-T., & Isaac, W. (2020). Decolonial AI: Decolonial Theory as Sociotechnical Foresight in Artificial Intelligence. Philosophy & Technology, 33(4), 659–684. https://doi.org/10.1007/s13347-020-00405-8",Decolonial AI: Decolonial Theory as Sociotechnical Foresight in Artificial Intelligence,Extractive,"Excluding underrepresented groups from decision-making, Ethics dumping in less-regulated contexts",Critical theory/Historical background,Problem Understanding & Formulation,Product Conception & Design,Era 3,ADC,A: critical technical practice for decolonial design; D: critiques colonial data pipelines; C: reciprocal engagement & reverse tutelage,"White (published journal papers, conference proceedings, books)",Database search,"Decolonizing, algorithmic colonialism",Not regionally specific,Industry,EU/UK,DeepMind London,"University of Oxford, Oxford, UK","Argues that the field of AI must engage with decolonial theory in order to anticipate and prevent the potential harms of AI systems. The authors argue that AI systems, as both objects and subjects, are expressions of the coloniality of power. They introduce the term algorithmic colonialism to describe how AI systems can perpetuate and exacerbate existing social inequities and introduce three specific areas of concern: algorithmic oppression, algorithmic exploitation, and algorithmic dispossession. They illustrate each of these problems with specific use cases, grounding the theoretical framework in concrete examples. The authors advocate for the development of a decolonial AI, outlining three broad tactics for resisting algorithmic colonialism: a critical technical practice of AI that acknowledges power imbalances and implicit value systems, reciprocal engagements that center marginalized communities and support reverse tutelage, and the development of renewed affective and political communities that can challenge existing hierarchies and create more just and equitable systems.",
"Montiel & Uyheng, 2022","Montiel, C. J., & Uyheng, J. (2022). Foundations for a decolonial big data psychology. Journal of Social Issues, 78(2), 278–297. https://doi.org/10.1111/josi.12439",Foundations for a decolonial big data psychology,Principles less-extractive,Decentering Western ontologies,Critical theory/Historical background,Problem Understanding & Formulation,Institutional Prioritization & Funding,Multi-era,DC,A: none; D: critiques dominant psychological uses of big data; C: advances decolonial framework centering Global South and Philippine contexts,"White (published journal papers, conference proceedings, books)",Database search,"Philippines, big data, decolonial psychology",APAC (Asia-Pacific Region),Industry,APAC (Asia-Pacific Region),"Ateneo de Manila University, Philippines",,"Argues that a decolonial approach to big data is necessary for psychological research, especially in the context of the Global South. They critique the prevailing tendency in big data psychology to uncritically adopt mainstream, often Western-centric, paradigms of knowledge production, which risk perpetuating the marginalization of non-WEIRD perspectives. Instead, the authors propose a framework for big data psychology that prioritizes collective ontologies, naturalistic epistemologies, and socio-politically sensitive ethical guidelines, all viewed through the lens of reflexivities from the margins. Through two case studies examining social issues in the Philippines, they illustrate how this framework can be operationalized to generate more equitable and insightful psychological research.",
"Morreale et al., 2023","Morreale, F., Bahmanteymouri, E., Burmester, B. et al. The unwitting labourer: extracting humanness in AI training. AI & Soc (2023). https://doi.org/10.1007/s00146-023-01692-3",The unwitting labourer: extracting humanness in AI training,Extractive,Exploitative and invisible data labor,"Data practices, Data labor",ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,ADC,"A: theorizes extraction of “humanness” in AI; D: analyzes reCAPTCHA, recommendations, content generation, spam filtering; C: highlights unconsented, uncompensated public participation","White (published journal papers, conference proceedings, books)",Database search,Oceania; immaterial labour; digital labour; exploitation,Oceania,Academic,Oceania,"The University of Auckland, Auckland, New Zealand","Faculty of Creative Arts and Industries (School of Music), The University of Auckland, Auckland, New Zealand; Faculty of Creative Arts and Industries (Architecture and Planning), The University of Auckland, Auckland, New Zealand; Faculty of Business and Economics (Management and International Business), The University of Auckland, Auckland, New Zealand; Faculty of Arts (Koi Tū - the Centre for Informed Futures), The University of Auckland, Auckland, New Zealand; Faculty of Arts (Anthropology), The University of Auckland, Auckland, New Zealand","Uses Political Discourse Theory to argue that everyday digital interactions conscript “unwitting labourers” into AI training. Through four cases, shows how cognition and perception are commodified without consent or compensation. Frames this as a distinct labor relation within AI supply chains, clarifying opaque data production that burdens users while benefiting firms.",
"Moyo, 2020","Moyo, L. (2020). Decolonial Research Methodologies: Resistance and Liberatory Approaches. In L. Moyo (Ed.), The Decolonial Turn in Media Studies in Africa and the Global South (pp. 187–225). Springer International Publishing. https://doi.org/10.1007/978-3-030-52832-4_6",Decolonial Research Methodologies: Resistance and Liberatory Approaches,Principles less-extractive,"Early co-design and participatory initiatives, Decentering Western ontologies","Community impacts and relations, Critical theory/Historical background",Cross-pipeline,Cross-pipeline,Multi-era,ADC,A: critiques Eurocentric approaches to AI/data debates (indirectly); D: proposes PAR and IRM as decolonial research methods; C: addresses Global South communities’ epistemic marginalization,"White (published journal papers, conference proceedings, books)",Database search,Global South; decolonial methodology; PAR; IRM,"LatAm (includes Central America, South America & Carribbean)",Academic,Africa,"American University of Nigeria, Nigeria",,"Looks at problems of Eurocentric media and communication research methodologies. Moyo argues that dominant Western research methodologies, often rooted in positivist and utilitarian traditions, ultimately perpetuate colonial power structures and fail to capture the lived experiences of the Global South. The chapter critiques the perceived neutrality and objectivity of Western research, highlighting how cultural biases influence research design, data analysis, and interpretation. Instead, Moyo advocates for decolonial research methodologies, like Participatory Action Research (PAR) and Indigenous Research Methodology (IRM), which emphasize collaboration, reflexivity, and the recognition of diverse knowledge systems.",
"Mozilla Common Voice, n.d.","Mozilla Common Voice. (n.d.). Mozilla Common Voice. Retrieved September 7, 2025, from https://commonvoice.mozilla.org/",Mozilla Common Voice,Practices less-extractive,Crowdsourcing data collection,"Community impacts and relations, Data practices",ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,ADC,"A: provides open speech data for ASR and related models; D: community records, validates, and curates speech; C: supports language preservation and inclusive speech technologies","Grey (Reports, blogs, white papers, policy documents, theses, conference papers)","Existing networks, relevant organizations and conferences",global; speech datasets; open source; inclusion,Multiple areas,NGO/Non-profit,Multiple areas,"Mozilla Foundation, USA/global",,"Open, community-led speech data creation platform where volunteers donate and validate voice clips. Targets coverage of many languages and accents to reduce performance gaps in speech technologies and support language revitalization. Stresses transparent licensing and reuse to enable public-interest and commercial ASR with stronger representation of under-served speakers.",
"Muldoon & Wu, 2023","Muldoon, J., & Wu, B. A. (2023). Artificial Intelligence in the Colonial Matrix of Power. Philosophy & Technology, 36(4), 80. https://doi.org/10.1007/s13347-023-00687-8",Artificial Intelligence in the Colonial Matrix of Power,Extractive,Soliciting data without reciprocal benefits,"Data practices, Community impacts and relations, Critical theory/Historical background",Cross-pipeline,Cross-pipeline,Era 3,ADC,A: analyzes AI development within colonial systems; D: examines extractive data collection practices and colonial supply chains; C: identifies impacts on Global Majority communities through ongoing colonialism,"White (published journal papers, conference proceedings, books)",Database search,"AI colonialism, data extraction, colonial supply chain",Not regionally specific,Academic,EU/UK,"University of Essex, UK","Oxford Internet Institute, University of Oxford, Oxford, UK","Argues that the development and deployment of AI systems are embedded within historical and ongoing systems of colonialism, and provides a framework for understanding how AI production relies on a “colonial supply chain” that extracts resources and exploits labor, primarily from the majority world, to benefit Western technology companies. This system perpetuates global power imbalances by concentrating wealth and technological advancement in the West. Moreover, Muldoon and Wu posit that AI reinforces hegemonic knowledge production by prioritizing Western values and epistemologies in its datasets and algorithms that contributes to the marginalization of non-Western perspectives and knowledge systems.",
"Muldoon et al., 2024","Muldoon, J., Cant, C., Wu, B., & Graham, M. (2024). A Typology of AI Data Work. Big Data and Society, 11(1), Article 1. https://doi.org/10.1177/20539517241232632", A Typology of AI Data Work,Extractive,Exploitative and invisible data labor,Data labor,ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,AD,A: conceptualizes AI data pipeline and algorithm preparation; D: categorizes data work institutions and employment relationships; C: none (indirect implications),"White (published journal papers, conference proceedings, books)","Existing networks, relevant organizations and conferences","AI data work, data annotation, microwork platform",Not regionally specific,Academic,EU/UK,"Essex Business School, UK",,"Introduces the concept of ""AI data work,"" which is defined as the human labor involved in preparing and evaluating data for machine learning algorithms. The authors address the confusion surrounding terms like ""microwork"" and ""crowdwork"" by providing a typology of AI data work institutions, differentiating them based on employment relationships (crowdsourced vs. employees), type of service (generalist vs. AI-specific), and organizational structure (internal vs. external). Furthermore, they present a conceptual schema of the ""AI data pipeline"" which breaks down the AI production process into sequential steps, emphasizing the interconnectedness of data collection, curation, annotation, quality assurance, model training, evaluation, and verification, to demonstrate how human practices are commodified within global AI production networks",
"Munn, 2024","Munn, L. (2024). The five tests: Designing and evaluating AI according to indigenous Māori principles. AI & SOCIETY, 39(4), 1673–1681. https://doi.org/10.1007/s00146-023-01636-x
",The five tests: Designing and evaluating AI according to indigenous Māori principles,Principles less-extractive,Participatory data ownership & governance,"Community impacts and relations, Ethics frameworks",Cross-pipeline,Cross-pipeline,Era 3,ADC,A: discusses implications of Māori principles for AI evaluation; D: operationalizes “five tests” as criteria for design and assessment; C: emphasizes decolonial and communal perspectives on sustainable AI outcomes.,"White (published journal papers, conference proceedings, books)",Iterative keyword search,Oceania; Māori principles; AI evaluation; decolonial practice,Oceania,Academic,Oceania,"Digital Cultures & Societies, University of Queensland,
Mianjin/Brisbane, Australia",,"Adapts Sir Hirini Moko Mead’s five tests to guide AI design and assessment. Provides practical and normative criteria rooted in Māori values to evaluate harms, reciprocity, and relationships. Offers a decolonial lens for governance and practice that can redirect data production and system use toward collective benefit",
"Naous et al., 2024","Naous, T., Ryan, M. J., Ritter, A., & Xu, W. (2024). Having Beer after Prayer? Measuring Cultural Bias in Large Language Models. In L.-W. Ku, A. Martins, & V. Srikumar (Eds.), Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) (pp. 16366–16393). Association for Computational Linguistics. https://doi.org/10.18653/v1/2024.acl-long.862",Having Beer after Prayer? Measuring Cultural Bias in Large Language Models,Extractive,"""Deploying AI systems that lack local, contextual data""","Community impacts and relations, Data practices",ML System Design & Development,Model Training & Evaluation,Era 3,ADC,A: evaluates multilingual/Arabic LMs; D: analyzes cultural bias in corpora; C: foregrounds harms of Western default assumptions,"White (published journal papers, conference proceedings, books)",Citation/reference snowballing,"Middle East, cultural bias, Arabic NLP, CAMeL dataset",MENA,Academic,North America,"College of Computing
Georgia Institute of Technology, USA",,"Introduces CAMeL, a benchmark of 628 prompts and 20k+ entities contrasting Arab and Western cultures. Tests 16 language models on Arabic tasks (NER, sentiment, story generation). Finds models stereotype and misrepresent Arab contexts. Corpus analysis shows Wikipedia is ill-suited as an Arabic source without adjustment. Released as public resource, the study highlights cultural misalignments when global systems are deployed without local training data.",
"Nayebare et al., 2023","Nayebare, M., Eglash, R., Kimanuku, U., Baguma, R., Mounsey, J., & Maina, C. (2023). Interim Report for Ubuntu-AI: A Bottom-up Approach to More Democratic and Equitable Training and Outcomes for Machine Learning (Democratic Inputs for AI). OpenAI Foundation. https://generativejustice.org/uai/",Interim Report for Ubuntu-AI: A Bottom-up Approach to More Democratic and Equitable Training and Outcomes for Machine Learning (Democratic Inputs for AI),Practices less-extractive,"Crowdsourcing data collection, Participatory data ownership & governance","Community impacts and relations, Ethics frameworks",ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,ADC,A: frames “generative justice” for ML training; D: designs a platform for equitable collection and governance; C: enables African creatives to control use and share in value,"Grey (Reports, blogs, white papers, policy documents, theses, conference papers)","Existing networks, relevant organizations and conferences",Africa; training data; platform governance; creative workers; equitable benefits,Africa,Academic,North America,"University of Michigan, USA",,"Articulates the “double bind” of exclusion vs. surrendering data. Proposes Ubuntu-AI, a platform where African artists contribute training data under community governance, with profit-sharing and usage control. Links equitable data sourcing to fairer outcomes and stronger participation in AI economies",
"Nekoto et al., 2020","Nekoto, W., Marivate, V., Matsila, T., Fasubaa, T., Fagbohungbe, T., Akinola, S. O., Muhammad, S., Kabongo Kabenamualu, S., Osei, S., Sackey, F., Niyongabo, R. A., Macharm, R., Ogayo, P., Ahia, O., Berhe, M. M., Adeyemi, M., Mokgesi-Selinga, M., Okegbemi, L., Martinus, L., … Bashir, A. (2020). Participatory Research for Low-resourced Machine Translation: A Case Study in African Languages. In T. Cohn, Y. He, & Y. Liu (Eds.), Findings of the Association for Computational Linguistics: EMNLP 2020 (pp. 2144–2160). Association for Computational Linguistics. https://doi.org/10.18653/v1/2020.findings-emnlp.195",Participatory Research for Low-resourced Machine Translation: A Case Study in African Languages,Practices less-extractive,Early co-design and participatory initiatives,"Community impacts and relations, Data practices",ML System Design & Development,"Data Selection, Collection & Annotation",Multi-era,ADC,A: reframes “low-resourced-ness” as socio-historical; D: builds datasets/benchmarks via participatory research; C: mobilizes native speakers and Masakhane networks,"White (published journal papers, conference proceedings, books)",Database search,Africa; machine translation; participatory research; benchmarks; native speakers,Africa,Journalist/Other/Not Sure,Africa,"Masakhane, Africa","Masakhane, Africa; Independent; University of Pretoria; Niger-Volta LTI; African Masters in Machine Intelligence; Federal University of Technology, Akure; University of Johannesburg; Bayero University, Kano; Jomo Kenyatta University of Agriculture and Technology; UESTC; Siseng Consulting Ltd; African Leadership University; InstaDeep Ltd; Sapienza University of Rome; Udacity; Parliament, Republic of South Africa; Explore Data Science Academy; UCD, Konta; AI4Dev; Google Research; Percept; Retro Rabbit; Di-Hub; Stellenbosch University; Naver Labs Europe; Retina AI; Lori Systems; SIL International; Federal College of Dental Technology and Therapy, Enugu; Jacobs University; Namibia University of Science and Technology; Data Science Nigeria; Praekelt Consulting; Translators without Borders; Amazon; Max Planck Institute for Informatics, University of Saarland; Lancaster University; University of Porto; Technical University of Munich","Explicitly community-driven MT for 30+ African languages. Develops datasets, benchmarks, and first-time human evaluations, arguing that data scarcity reflects systemic exclusion. Shows participatory pathways to sustainable research capacity and better language technologies.",
"Nkrumah, 1965","Nkrumah, K. (1965). Neocolonialism, the Last Stage of Imperialism. Thomas Nelson & Sons, Ltd., London","Neocolonialism, the Last Stage of Imperialism.",Extractive,Other/NA (conceptual framing),Critical theory/Historical background,Cross-pipeline,Cross-pipeline,Multi-era,C,"A: none; D: details mechanisms of neocolonial control via trade, finance, and institutions; C: centers African nations’ political-economic struggles against dependency.","White (published journal papers, conference proceedings, books)","Existing networks, relevant organizations and conferences",Africa; neocolonialism; trade; dependency,Africa,Government,Africa,"Ghanaian politician, political theorist, and revolutionary",,"Foundational work arguing that, despite the decline of overt colonial rule, Western powers, particularly those representing giant financial interests, continue to exert economic and political control over formerly colonized nations. This “neo-colonialism” functions through a variety of mechanisms, including unfavorable trade agreements, strategic investment in primary industries that discourages broader economic development, and the manipulation of international organizations to advance Western interests. Nkrumah provides a detailed analysis of specific industries, such as mining and rubber production, to illustrate how these mechanisms operate to enrich Western corporations and keep developing nations in a state of dependency.",
"NL AI Coalition, 2023","NL AI Coalition. (2023). Towards a federation of AI data spaces: NL AIC reference guide to federated and interoperable AI data spaces. NL AI Coalition. https://coe-dsc.nl/nl-aic-publishes-guide-towards-a-federation-of-ai-data-spaces/ 
",Towards a federation of AI data spaces: NL AIC reference guide to federated and interoperable AI data spaces,Practices less-extractive,Developing federated data spaces,Data practices,ML System Design & Development,Model Architecture Selection & Design,Era 3,AD,"A: prescribes AI-focused data-space federation; D: provides methodologies, tooling, and interoperability guidance; C: none (indirect public-benefit claims)","Grey (Reports, blogs, white papers, policy documents, theses, conference papers)",Iterative keyword search,EU; AI data spaces; federation; interoperability,EU/UK,NGO/Non-profit,EU/UK,"NL AI Coalition (founding partner CoE-DSC), NL",,"Reference guide to design interoperable, federated AI data spaces. Details goals (trust, interoperability), identifies gaps, and sets a roadmap (2021–2024) to realize ten AI data spaces. Provides prescriptive methods and building blocks aimed at practical adoption across sectors to support trustworthy AI data sharing at scale.",
"Nothias, 2020","Nothias, T. (2020). Access granted: Facebook’s free basics in Africa. Media, Culture & Society, 42(3), 329-348. https://journals.sagepub.com/doi/full/10.1177/0163443719890530","Access granted: Facebook’s free basics in Africa
",Extractive,Ethics dumping in less-regulated contexts,Data practices,Deployment & Impact,Product Launch,Multi-era,DC,A: none; D: examines extractive practices of Free Basics deployment; C: foregrounds African digital rights activism and impacts of corporate strategies,"White (published journal papers, conference proceedings, books)",Iterative keyword search,"Facebook, Africa, free basics, digital rights",Africa,Academic,North America,"Stanford, USA",,"Analyzes Facebook’s Free Basics initiative, which sought to expand internet access across the Global South but raised concerns about net neutrality, data extraction, and governance. While banned in India, the program quietly spread to 32 African countries with limited public scrutiny. Using a VPN-based method, the study tracks Free Basics’ rollout and examines responses from civil society. Findings show how Facebook leveraged weak regulatory environments to entrench corporate influence while framing connectivity as philanthropy. African digital rights activists countered by foregrounding issues such as surveillance, internet shutdowns, and data privacy. The article highlights how connectivity projects function as extractive infrastructures with direct impacts on community rights and autonomy.",
"O'Connell, 2016","O’Connell, A. (2016). My Entire Life is Online: Informed Consent, Big Data, and Decolonial Knowledge. Intersectionalities: A Global Journal of Social Work Analysis, Research, Polity, and Practice, 5(1), Article 1. https://doi.org/10.48336/IJBIOJ2019","My Entire Life is Online: Informed Consent, Big Data, and Decolonial Knowledge",Extractive,Soliciting data without reciprocal benefits,Critical theory/Historical background,ML System Design & Development,"Data Selection, Collection & Annotation",Era 2,DC,A: none; D: critiques informed consent practices in big data contexts; C: advocates for Indigenous research protocols emphasizing community ownership and collective rights,"White (published journal papers, conference proceedings, books)",Database search,"informed consent, big data, decolonial knowledge",Not regionally specific,Academic,North America,"York University, Canada",,"Critiques the limitations of current informed consent practices in research, particularly in light of “big data” practices. O’Connell argues that traditional, individualistic models of consent, rooted in Western liberal ideology, fail to address the complexities of digital data collection and its implications for privacy and knowledge production. Highlights how the public-private entanglements inherent in internet systems, coupled with increasing government surveillance, complicate notions of privacy and consent. Drawing on Indigenous research protocols that emphasize community ownership and control over data, O’Connell advocates for a more critical approach to research ethics in the digital age. This necessitates recognizing the limitations of existing consent frameworks and engaging with alternative models that prioritize collective rights and challenge the commodification of personal data under “informational capitalism.”",
"Offenhuber, 2024","Offenhuber, D. (2024). Shapes and frictions of synthetic data. Big Data & Society, 11(2), 20539517241249390. https://doi.org/10.1177/20539517241249390 
",Shapes and frictions of synthetic data,Extractive,Reproducing biases through synthetic data generation,"Data practices, Community impacts and relations",ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,ADC,A: critiques AI-driven assumptions that synthetic data can substitute empirical observation; D: analyzes synthetic data across privacy protection and simulation contexts; C: examines implications for census and community survey data,"White (published journal papers, conference proceedings, books)",Database search,"synthetic data, representation, epistemology",Not regionally specific,Academic,North America,"Northeastern University, USA",,"Argues that contemporary research, amplified by audit cultures, often treats the child-as-data, reproducing epistemic extractivism. Critiques “fast” data collection and coding that strips knowledge from context and accountability. Proposes non-extractivist, relation-centered methods grounded in reciprocity and mutuality, drawing on Indigenous and transformative research ethics (“knowing-with,” not “knowing-about”). Urges slow, co-produced scholarship that prioritizes respect, care, and community benefit—even if that means not recording or publishing some material. Links these commitments to datafication and AI-adjacent practices with minors: emphasize consent as ongoing, power-aware, and collective; prevent harm; and ensure tangible returns to children and their communities.",
"Ofosu-Asare, 2024","Ofosu-Asare, Y. (2024). Cognitive imperialism in artificial intelligence: Counteracting bias with indigenous epistemologies. AI & SOCIETY. https://doi.org/10.1007/s00146-024-02065-0",Cognitive imperialism in artificial intelligence: Counteracting bias with indigenous epistemologies,Principles less-extractive,Decentering Western ontologies,"Critical theory/Historical background, Community impacts and relations",Problem Understanding & Formulation,Product Conception & Design,Era 3,AD,A: analyzes implications for AI design and evaluation; D: none (indirect implications); C: centers Indigenous epistemologies and community authority,"White (published journal papers, conference proceedings, books)",Database search,"Indigenous epistemologies, postcolonial, AI ethics, participatory design",Not regionally specific,Academic,APAC (Asia-Pacific Region),"Southern Cross University, Lismore, Australia",,"Critiques cognitive imperialism in AI and advances Indigenous epistemologies as design foundations. Method: theoretical synthesis across AI ethics, Indigenous studies, postcolonial theory with case illustrations. Findings: Western ontologies shape categories and metrics that marginalize communities; Indigenous frameworks reconfigure values and objectives. Link: directs upstream shifts in problem framing and design priorities so AI data practices reflect community knowledge and reduce harms",
"Ogueji et al., 2021","Ogueji, K., Zhu, Y., & Lin, J. (2021). Small Data? No Problem! Exploring the Viability of Pretrained Multilingual Language Models for Low-resourced Languages. In D. Ataman, A. Birch, A. Conneau, O. Firat, S. Ruder, & G. G. Sahin (Eds.), Proceedings of the 1st Workshop on Multilingual Representation Learning (pp. 116–126). Association for Computational Linguistics. https://doi.org/10.18653/v1/2021.mrl-1.11",Small Data? No Problem! Exploring the Viability of Pretrained Multilingual Language Models for Low-resourced Languages,Practices less-extractive,Taking a needs-based approach to developing AI,"Data practices, Community impacts and relations",ML System Design & Development,Model Training & Evaluation,Era 3,ADC,A: develops AfriBERTa for African languages; D: demonstrates training viability on small data; C: expands access for underserved linguistic communities,"White (published journal papers, conference proceedings, books)",Citation/reference snowballing,Africa; multilingual LM; low-resource languages,Africa,Academic,North America,"David R. Cheriton School of Computer Science
University of Waterloo, Canada",,"resource African languages, covering 11 total (first models for 4). Shows models can be competitive with less than 1GB of text, outperforming mBERT/XLM-R on some tasks. Releases data/code openly. Expands access to NLP for African languages, demonstrating community-beneficial approaches to data-efficient training.",
"Ojo et al., 2025","Ojo, J., Ogundepo, O., Oladipo, A., Ogueji, K., Lin, J., Stenetorp, P., & Adelani, D. I. (2025). AfroBench: How Good are Large Language Models on African Languages? (No. arXiv:2311.07978). arXiv. https://arxiv.org/abs/2311.07978v3 ",AfroBench: How Good are Large Language Models on African Languages?,Practices less-extractive,"Community engaged data production, Creating culturally inclusive datasets","Data practices, Community impacts and relations",ML System Design & Development,Model Training & Evaluation,Era 3,ADC,A: evaluates LLMs on 64 African languages; D: curates multi-task benchmark across datasets/tasks; C: evidences performance gaps and motivates inclusion efforts,"Grey (Reports, blogs, white papers, policy documents, theses, conference papers)",Citation/reference snowballing,"snowballing
Africa; benchmark; LLM evaluation; inclusion",Africa,Mixed,Multiple areas,"Mila, McGill University, Canada; Lelapa AI, Johannesburg, South Africa; Masakhane NLP","Canada CIFAR AI Chair, Canada; The African Research Collective; University of Waterloo, University College London, UK","Introduces a benchmark to evaluate large language models across 64 African languages and 15 tasks. The team compiles 22 datasets spanning understanding, generation, question answering, and reasoning. Results reveal significant performance gaps between African and high-resource languages, with outcomes varying by data availability. By establishing a common evaluation platform, the benchmark enables systematic measurement of disparities and directs attention to where data creation is most needed. AfroBench connects evaluation to data production by making performance deficits visible, motivating investment in African datasets and highlighting community impacts when linguistic diversity is overlooked in AI development.",
"Okolo et al., 2023","Okolo, C. T., Aruleba, K., & Obaido, G. (2023). Responsible AI in Africa—Challenges and opportunities. Responsible AI in Africa: Challenges and opportunities, 35-64. https://link.springer.com/book/10.1007/978-3-031-08215-3","Responsible AI in Africa—Challenges and Opportunities
",Extractive,Excluding underrepresented groups from decision-making,Community impacts and relations,Cross-pipeline,Cross-pipeline,Era 3,ADC,"A: Responsible AI across design/deployment and sector domains; D: various treatment of data production across chapters; C: African societal, cultural, and policy impacts throughout","White (published journal papers, conference proceedings, books)","Existing networks, relevant organizations and conferences","Africa, responsible AI, governance, exclusion",Africa,Academic,North America,"Cornell University, USA","University of Leicester, Leicester, UK; University of California, Berkeley, CA, USA","Synthesizes African perspectives on Responsible AI, spanning epistemic injustice, policy, gender, labor, and culturally grounded frameworks (e.g., Ubuntu). Highlights how data practices and governance shape who benefits or is burdened by AI. Argues for principles, institutions, and community engagement tailored to African contexts rather than importing external templates.",
"Okorie and Omino, 2024","Okorie, C., & Omino, M. (2024). Licensing African Datasets [Dataset]. https://licensingafricandatasets.com/",Licensing African Datasets,Practices less-extractive,Developing equitable data licensing models,"Data practices, Community impacts and relations",ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,ADC,A: articulates equitable openness for African language data; D: provides community-oriented license terms; C: centers source community benefit and control,"Grey (Reports, blogs, white papers, policy documents, theses, conference papers)",Citation/reference snowballing,Africa; dataset licensing; governance; language data; community benefit,Africa,Mixed,Africa,"University of Pretoria, South Africa","Strathmore University, Kenya; University of Pretoria, South Africa","Presents the Nwulite Obodo Open Data License for African language datasets. Balances openness with safeguards for source communities, specifying benefit sharing and governance mechanisms. Targets recurring extraction in language resources by formalizing community control within licensing",
"Oprescu et al., 2022","Oprescu, A. M., Miró-Amarante, G., García-Díaz, L., Rey, V. E., Chimenea-Toscano, A., Martínez-Martínez, R., & Romero-Ternero, M. C. (2022). Towards a data collection methodology for Responsible Artificial Intelligence in health: A prospective and qualitative study in pregnancy. Information Fusion, 83–84, 53–78. https://doi.org/10.1016/j.inffus.2022.03.011",Towards a data collection methodology for Responsible Artificial Intelligence in health: A prospective and qualitative study in pregnancy,Practices less-extractive,Community engaged data production,"Community impacts and relations, Data practices",ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,ADC,"A: applies RAI to perinatal health; D: proposes multi-step, privacy-aware data-collection methodology; C: centers pregnant participants’ needs and concerns","White (published journal papers, conference proceedings, books)",Database search,EU/UK; health AI; pregnancy data; responsible ai; privacy,EU/UK,Academic,EU/UK,"University of Sevilla, Spain","Hospital Universitario Virgen del Rocío; Clínica Victoria Rey; Universitat de Valencia, Spain","Proposes a new data collection methodology for designing RAI applications in healthcare, particularly focusing on pregnancy health. The authors argue that traditional approaches to AI in pregnancy health are limited, often neglecting the crucial role of emotional and psychological factors in pregnancy outcomes. They advocate for a more holistic approach that incorporates data from various sources, including medical records, wearable devices, and psychological assessments. The paper presents a multi-step methodology to guide the development of RAI solutions, emphasizing the need for user-centered design, explainable AI, and robust privacy and security measures. This methodology is then applied to a case study involving pregnant women in Spain, analyzing their needs, expectations, and potential concerns related to RAI-based pregnancy health solutions. ",
"Orife et al., 2020","Orife, I., Kreutzer, J., Sibanda, B., Whitenack, D., Siminyu, K., Martinus, L., Ali, J. T., Abbott, J., Marivate, V., Kabongo, S., Meressa, M., Murhabazi, E., Ahia, O., Biljon, E. van, Ramkilowan, A., Akinfaderin, A., Öktem, A., Akin, W., Kioko, G., … Bashir, A. (2020). Masakhane—Machine Translation For Africa (No. arXiv:2003.11529). arXiv. https://doi.org/10.48550/arXiv.2003.11529",Masakhane—Machine Translation For Africa,Practices less-extractive,"Creating culturally inclusive datasets, Community engaged data production","Data practices, Community impacts and relations",ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,ADC,A: organizes Africa-wide MT effort; D: builds datasets and baselines collaboratively; C: grows local capacity and benchmarks for African languages,"Grey (Reports, blogs, white papers, policy documents, theses, conference papers)","Existing networks, relevant organizations and conferences",Africa; MT; community research; low-resource,Africa,Mixed,Africa,"Masakhane, Africa","∗ In rebellion against the status attributed to author order, the order of authors has been randomised (Strange, 2008).
The symbol ∀ furthermore takes the place as first author to represent the whole community.","Documents a distributed, community-driven MT initiative spanning African languages. Addresses barriers—funding, discoverability, reproducibility—by pooling regional expertise, corpora, and evaluation. Establishes shared practices and resources to accelerate inclusive NLP capacity on the continent.",
"Papakyriakopoulos et al., 2023","Papakyriakopoulos, O., Choi, A. S. G., Thong, W., Zhao, D., Andrews, J., Bourke, R., Xiang, A., & Koenecke, A. (2023). Augmented Datasheets for Speech Datasets and Ethical Decision-Making. 2023 ACM Conference on Fairness, Accountability, and Transparency, 881–904. https://doi.org/10.1145/3593013.3594049",Augmented Datasheets for Speech Datasets and Ethical Decision-Making,Practices less-extractive,Building public visibility in dataset development,Data practices,ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,ADC,A: targets SLT dataset documentation; D: extends datasheets with speech-specific questions and ethics considerations; C: centers protection/empowerment of speech communities,"White (published journal papers, conference proceedings, books)",Database search,speech dataset; datasheet; accent/dialect; documentation,Not regionally specific,Mixed,North America,"Sony AI, USA",,"Proposes an “augmented datasheet” tailored to speech datasets, motivated by harms from non-diverse training data across language, accent, dialect, and impairment. Provides domain-specific questions and ethical prompts, drawing on literature across ML, linguistics, and health. Aims to standardize documentation and foreground community protection and empowerment in SLT pipelines.",
"Park et al., 2021","Park, J. S., Bragg, D., Kamar, E., & Morris, M. R. (2021). Designing an Online Infrastructure for Collecting AI Data From People With Disabilities. Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency, 52–63. https://doi.org/10.1145/3442188.3445870",Designing an Online Infrastructure for Collecting AI Data From People With Disabilities,Practices less-extractive,"Community engaged data production, Creating culturally inclusive datasets, Establishing consent and contextually appropriate compensation","Community impacts and relations, Data practices",ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,ADC,"A: proposes infrastructure to collect AI data from PWD; D: specifies accessibility, consent, and compensation mechanisms; C: centers inclusion and agency","White (published journal papers, conference proceedings, books)",Database search,North America; disability; AI data collection; accessibility; compensation,North America,Industry,North America,"Microsoft Research, USA",,"On the lack of representation of people with disabilities (PWD) in AI datasets and its impact on the development of fair and inclusive AI systems. The authors argue that collecting data from PWD is crucial to mitigate bias and discrimination in AI applications. As a solution, they propose the development of an online infrastructure for large-scale, remote data collection from disability communities. The paper presents findings from interviews and an online survey that simulated data contribution, highlighting PWD’s motivations, concerns, and challenges. The authors conclude with design guidelines for building accessible and inclusive data collection processes, emphasizing ethical considerations such as compensation, privacy, and accessibility for a diverse range of disabilities.",
"Partnership on AI, n.d.","Partnership on AI. (n.d.). Guidance for Inclusive AI: Guidance for Inclusive AI Practicing Participatory Engagement. Partnership on AI. Retrieved September 1, 2025, from https://partnershiponai.org/guidance-for-inclusive-ai-new-practitioners/ 
",Guidance for Inclusive AI: Guidance for Inclusive AI Practicing Participatory Engagement,Practices less-extractive,Early co-design and participatory initiatives,"Data practices, Community impacts and relations",Cross-pipeline,Cross-pipeline,Era 3,AC,A: applies participatory methods to AI engagement; D: none (indirect implications); C: centers community voice in development processes,"Grey (Reports, blogs, white papers, policy documents, theses, conference papers)","Existing networks, relevant organizations and conferences","Global, engagement, participatory methods, inclusivity",Not regionally specific,Mixed,Multiple areas,"Partnership on AI, USA",,"The Guidance for Inclusive AI serves as a starting point, a means to break down the complexity of public engagement strategies to more digestible, easier-to-navigate components.

In an ideal world, all data-driven technologies are developed in direct collaboration with the various people who would be impacted by its deployment. Impacted communities would have the decision-making authority to reject harmful technologies.

However, these are not our current circumstances.

Our current circumstances
Today’s AI-driven tools are frequently developed in the absence of these important perspectives. It is important that interventions are introduced to open up the development process — and in ways that do not cause additional harm in the process.

The purpose of this resource is not to establish a single methodology that can be adapted to all use cases. Rather, it is designed to help business leaders, developers, and deployers:

more clearly identify the purpose or aim motivating public engagement
establish a public engagement strategy that is in better alignment with the needs and benefit of the impacted communities whose help is being sought
identify likely pain points or obstructions that might harm the relationship between AI-developing organizations and impacted communities
While public engagement cannot resolve all of the issues that arise with the development and deployment of data-driven technologies, it can create avenues for holding difficult, but necessary, discussions with the people who are directly affected by them. Increasing the capacity of AI developers, particularly those working in private sector companies, to engage with a diverse set of communities can move us closer to more responsible and ethical AI.

There is no perfect solution or one-size-fits-all framework for public engagement
Even well-intended teams or companies will inevitably face obstacles. Many pressures and limitations arise in public engagement led by commercial entities, such as the demand for financial profitability and the perceived pace at which technology needs to be taken to market to be competitive. Such technologies as surveillance-enhancing tools are highly contentious, especially among socially marginalized communities. Plus, the scale of these AI technologies means that impacted communities might involve many people beyond end users, or customers, making it even more difficult for developers to preempt every possible use case of an AI technology. However, these challenges and potential mistakes all offer opportunities to learn how to be more effective in future collaborations with the public.",
"Parvess, 2023","Parvess, J. (2023). BantuBERTa: Using Language Family Grouping in Multilingual Language Modeling for Bantu Languages [University of Pretoria]. https://repository.up.ac.za/items/05b06486-0d53-4099-9c1a-6cb3890a80c1 ",BantuBERTa: Using Language Family Grouping in Multilingual Language Modeling for Bantu Languages,Practices less-extractive,Creating culturally inclusive datasets,Community impacts and relations,ML System Design & Development,Model Training & Evaluation,Era 3,AD,A: targets inclusion of Bantu languages in NLP; D: develops BantuBERTa with HuggingFace and web-scraped corpora; C: none,"White (published journal papers, conference proceedings, books)","Existing networks, relevant organizations and conferences","Africa, Bantu languages, multilingual modeling, low-resource",Africa,Academic,Africa,"University of Pretoria, South Africa",,"Tests whether grouping related Bantu languages in a single pretraining corpus improves transfer for low-resource settings. Trains BantuBERTa on curated/web corpora and evaluates on MasakhaNER and ANTC. Finds mixed results—underperformance on NER, state-of-the-art on some classification tasks—highlighting sensitivity to corpus size/quality. Demonstrates both promise and limits of family-grouped pretraining for inclusive African NLP.",
"Pasquale & Sun, 2024","Pasquale, F., & Sun, H. (2024). Consent and Compensation: Resolving Generative AI’s Copyright Crisis (SSRN Scholarly Paper No. 4826695). Social Science Research Network. https://doi.org/10.2139/ssrn.4826695 
",Consent and Compensation: Resolving Generative AI’s Copyright Crisis,Principles less-extractive,Establishing consent and contextually appropriate compensation,"Data practices, Community impacts and relations",ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,ADC,A: addresses generative AI training uses; D: proposes opt-out plus levy mechanisms for training data governance; C: targets fair remuneration and agency for creators,"White (published journal papers, conference proceedings, books)",Database search,"copyright, generative AI, consent, compensation",Not regionally specific,Academic,North America,"Cornell University - Law School; Cornell Tech, USA","The University of Hong Kong - Faculty of Law, Hong Kong","Argues that genAI’s reliance on creative corpora demands new governance: a streamlined opt-out for objectors and a levy compensating rightsholders whose works train models. Details how such mechanisms rebalance incentives, support sustainable knowledge ecosystems, and clarify accountability—linking dataset provenance and consent to systemic community impacts on creative labor.",
"Paullada et al, 2021","Paullada, A., Raji, I. D., Bender, E. M., Denton, E., & Hanna, A. (2021). Data and its (dis)contents: A survey of dataset development and use in machine learning research. Patterns, 2(11). https://doi.org/10.1016/j.patter.2021.100336",Data and its (dis)contents: A survey of dataset development and use in machine learning research,Extractive,"Collecting vast amounts of data to train AI systems, Scraping or repurposing sensitive data, Biased pre-processing and category erasure",Data practices,ML System Design & Development,Model Training & Evaluation,Multi-era,ADC,"A: surveys dataset-centric ML practices; D: details design, introspection, and cultural/legal issues; C: foregrounds representational and labor harms","White (published journal papers, conference proceedings, books)",Database search,dataset culture; benchmarking; data labor; legal risk,Not regionally specific,Mixed,North America,"University of Washington, USA","Google Research, New York, NY, USA; Mozilla Foundation, Mountain View, CA, USA; Google Research, San Francisco, CA, USA","Synthesizes problems in dataset design and use across CV/NLP: under-representation, stereotyping, spurious correlations, weak documentation, and risky scraping. Reviews inspection methods (audits, interventions) and critiques benchmarking and distribution cultures. Calls for a field-level shift that centers limitations, labor, legality, and social impact in dataset work.",
"Pfohl et al., 2024","Pfohl, S. R., Cole-Lewis, H., Sayres, R., Neal, D., Asiedu, M., Dieng, A., Tomasev, N., Rashid, Q. M., Azizi, S., Rostamzadeh, N., McCoy, L. G., Celi, L. A., Liu, Y., Schaekermann, M., Walton, A., Parrish, A., Nagpal, C., Singh, P., Dewitt, A., … Singhal, K. (2024). A Toolbox for Surfacing Health Equity Harms and Biases in Large Language Models (No. arXiv:2403.12025). arXiv. https://doi.org/10.48550/arXiv.2403.12025",A Toolbox for Surfacing Health Equity Harms and Biases in Large Language Models,Practices less-extractive,Creating culturally inclusive datasets,"Data practices, Ethics frameworks, Community impacts and relations",ML System Design & Development,Model Training & Evaluation,Era 3,ADC,A: targets LLMs in healthcare; D: releases EquityMedQA and multi-stakeholder bias evaluation; C: addresses disparate risks for patient groups,"Grey (Reports, blogs, white papers, policy documents, theses, conference papers)",Database search,multiple areas; health LLMs; equity; bias evaluation,Multiple areas,Industry,North America,"Google Research, USA","Google Research, Mountain View, CA, USA; Google DeepMind, Mountain View, CA, USA; University of Alberta, Edmonton, AB, Canada; Laboratory for Computational Physiology, Massachusetts Institute of Technology, Cambridge, MA, USA; Division of Pulmonary, Critical Care and Sleep Medicine, Beth Israel Deaconess Medical Center, Boston, MA, USA; Department of Biostatistics, Harvard T.H. Chan School of Public Health, Boston, MA, USA","Outlines risks of LLM-driven inequities in clinical settings. Introduces datasets and procedures to detect bias along race, gender, and SES axes, combining clinician, equity-expert, and consumer assessments. Provides a practical toolbox to surface harms and guide safer deployment for diverse patient communities.",
"Pierre et al., 2021","Pierre, J., Crooks, R., Currie, M., Paris, B., & Pasquetto, I. (2021). Getting Ourselves Together: Data-centered participatory design research & epistemic burden. Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems, 1–11. https://doi.org/10.1145/3411764.3445103",Getting Ourselves Together: Data-centered participatory design research & epistemic burden,Extractive,Soliciting data without reciprocal benefits,"Data practices, Community impacts and relations",Problem Understanding & Formulation,Product Conception & Design,Era 3,DC,"A: none (focus on PD, not AI systems per se); D: critiques PD projects placing burdens on communities; C: shows harms of extractive collaboration.","White (published journal papers, conference proceedings, books)",Database search,childhood research; reciprocity; ethics,North America,Academic,North America,"University of California, Los Angeles, USA",,"Critiques participatory design (PD) research, particularly data-centered projects involving marginalized communities. The authors argue that such projects, while often framed as empowering, can place epistemic burdens on these communities. They outline three forms of epistemic burden: researchers prioritizing their own data and solutions over those of the community, neglecting or dismissing community perspectives, and benefiting from research outcomes while communities remain unrecognized and uncompensated. Two case studies, both involving collaborations with anti-police brutality organizations, illustrate these burdens. The authors conclude by urging researchers to “organize themselves” by reflecting on their power and positionality, anticipating and mitigating potential burdens, and prioritizing community needs and goals over extractive research practices.",
"Pinhanez et al., 2024","Pinhanez, C., Cavalin, P., Storto, L., Finbow, T., Cobbinah, A., Nogima, J., Vasconcelos, M., Domingues, P., Mizukami, P. de S., Grell, N., Gongora, M., & Gonçalves, I. (2024a). Harnessing the Power of Artificial Intelligence to Vitalize Endangered Indigenous Languages: Technologies and Experiences (No. arXiv:2407.12620). arXiv. https://doi.org/10.48550/arXiv.2407.12620",Harnessing the Power of Artificial Intelligence to Vitalize Endangered Indigenous Languages: Technologies and Experiences,Practices less-extractive,Taking a needs-based approach to developing AI,"Data practices, Community impacts and relations",ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,ADC,A: develops MT and assistants for Indigenous languages; D: applies culturally sensitive design with communities; C: centers sovereignty and revitalization,"White (published journal papers, conference proceedings, books)","Existing networks, relevant organizations and conferences",Brazil; endangered languages; MT; AI pipeline,"LatAm (includes Central America, South America & Carribbean)",Mixed,"LatAm (includes Central America, South America & Carribbean)","IBM Research, University of São Paulo, Brazil",,"Explores the potential of AI and NLP technologies, particularly LLMs, in preserving and promoting the use of endangered Indigenous languages. Recognizing the ethical challenges and historical exploitation associated with research involving Indigenous communities, the authors advocate for an alternative AI development cycle centered on community engagement and data sovereignty. The study presents findings from projects in Brazil, focusing on developing machine translation tools and writing assistants for languages like Guarani Mbya and Nheengatu, emphasizing the importance of data quality and culturally sensitive application of technology to support language revitalization efforts. The ultimate goal is to empower Indigenous communities to independently manage and govern these AI-driven language technologies",
"Pipatanakul et al., 2023","Pipatanakul, K., Jirabovonvisut, P., Manakul, P., Sripaisarnmongkol, S., Patomwong, R., Chokchainant, P., & Tharnpipitchai, K. (2023). Typhoon: Thai Large Language Models (No. arXiv:2312.13951). arXiv. https://doi.org/10.48550/arXiv.2312.13951",Typhoon: Thai Large Language Models,Practices less-extractive,Creating culturally inclusive datasets,"Community impacts and relations, Data practices",ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,ADC,"A: develops Thai LLMs; D: details Thai corpus prep, continual training, and evaluation; C: expands access for Thai users and tasks","Grey (Reports, blogs, white papers, policy documents, theses, conference papers)",Citation/reference snowballing,APAC; Thai LLM; dataset curation; evaluation,APAC (Asia-Pacific Region),Industry,APAC (Asia-Pacific Region),"SCB 10X, Thailand",,"Presents Thai-specific LLMs via continual training, curated pretraining data, and instruction tuning. Introduces ThaiExam benchmark; shows strong Thai performance with efficient tokenization. Positions targeted corpus work and evaluation as pathways to equitable capability for a low-resource language community.",
"Png, 2023","Png, M.-T. (2023). Paradoxes of Participation In Inclusive AI Governance: Four Key Approaches From Global South and Civil Society Discourse. In B. Prud’homme, C. Régis, G. Farnadi, V. Dreier, S. Rubel, & C. d’Oultremont (Eds.), Missing Links in AI Governance (pp. 269–292). UNESCO. https://unesdoc.unesco.org/ark:/48223/pf0000384787.locale=en ",Paradoxes of Participation In Inclusive AI Governance: Four Key Approaches From Global South and Civil Society Discourse,Extractive,Excluding underrepresented groups from decision-making,"Community impacts and relations, Ethics frameworks",Cross-pipeline,Cross-pipeline,Era 3,ADC,A: targets inclusive AI governance; D: advances data-rights and audit transparency for datasets; C: centers Global South and civil society participation,"Grey (Reports, blogs, white papers, policy documents, theses, conference papers)",Iterative keyword search,multiple areas; AI governance; participation; Global South,Multiple areas,Government,EU/UK,"UNESCO, FR",,"Synthesizes civil society and Global South perspectives on inclusive AI governance. Identifies participation paradoxes and proposes approaches (e.g., Indigenous data rights, third-party dataset audits) to reduce centralization and opacity in AI data infrastructures, linking governance design to community power and accountability.",
"Pool, 2016","Pool, I. (2016). Colonialism’s and postcolonialism’s fellow traveller: The collection, use and misuse of data on indigenous people. In T. Kukutai & J. Taylor (Eds.), Indigenous Data Sovereignty (1st ed.). ANU Press. https://doi.org/10.22459/CAEPR38.11.2016.04
","Colonialism’s and postcolonialism’s fellow traveller: the collection, use and misuse of data on indigenous people",Principles less-extractive,Participatory data ownership & governance,"Critical theory/Historical background, Community impacts and relations",ML System Design & Development,"Data Selection, Collection & Annotation",Multi-era,DC,A: none; D: traces colonial data practices replacing Indigenous systems; C: calls for Indigenous control of data to protect rights and interests,"White (published journal papers, conference proceedings, books)",Database search,"Oceania, Aotearoa New Zealand, colonialism, Indigenous data sovereignty",Oceania,Academic,Oceania,"University of Waikato, New Zealand",,"Analyzes the history of how colonial states collected and misused data on Indigenous peoples, erasing and replacing local knowledge systems. Uses Aotearoa New Zealand as a case study to show how Māori data practices were devalued under colonialism. Argues that regaining data sovereignty is essential to protecting Indigenous rights, preserving cultural knowledge, and enabling equitable development. Links historical data exploitation to ongoing debates about governance and control in contemporary digital contexts",
"Puschmann & Burgess, 2014","Puschmann, C., & Burgess, J. (2014). Big Data, Big Questions| Metaphors of Big Data. International Journal of Communication, 8(0), Article 0.","Big Data, Big Questions",Extractive,Collecting vast amounts of data to train AI systems,Data practices,Problem Understanding & Formulation,Institutional Prioritization & Funding,Multi-era,D,A: none; D: analyzes metaphors that normalize accumulation and control; C: none (indirect implications),"White (published journal papers, conference proceedings, books)",Database search,Europe; big data; media discourse; imaginaries,Not regionally specific,Academic,EU/UK,"University Bremen, Germany",,"Explores how the abstract concept of big data is understood through the metaphors used to describe it. The authors trace the historical evolution of the terms “data” and “big data,” highlighting a shift from data as individually interpreted pieces of information to big data as massive, quantifiable aggregates. By analyzing media discourse, Puschmann and Burgess identify two prominent metaphors: big data as a force of nature to be controlled, emphasizing its overwhelming scale and potential, and big data as nourishment or fuel to be consumed, emphasizing its role in driving decisions and powering economic growth.",
"Qadri et al., 2023","Qadri, R., Shelby, R., Bennett, C. L., & Denton, E. (2023). AI’s Regimes of Representation: A Community-centered Study of Text-to-Image Models in South Asia. 2023 ACM Conference on Fairness, Accountability, and Transparency, 506–517. https://doi.org/10.1145/3593013.3594016",AI’s Regimes of Representation: A Community-centered Study of Text-to-Image Models in South Asia,Extractive,"""Deploying AI systems that lack local, contextual data""","Community impacts and relations, Data practices",ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,ADC,A: audits model representations; D: interrogates training data defaults; C: engages South Asian participants to assess outputs,"White (published journal papers, conference proceedings, books)",Database search,"South Asia, text-to-image, cultural stereotypes",APAC (Asia-Pacific Region),Industry,North America,"Google Research, USA",,"Community study with 36 participants from Pakistan, India, and Bangladesh examined cultural representation in T2I models. Findings showed systematic failures: erasure of cultural subjects, amplification of hegemonic defaults, and reproduction of stereotypes. The work argues these reflect entrenched representational regimes and calls for community involvement in dataset and model design.",
"Qian et al., 2024","Qian, Z., Altam, F., Alqurishi, M., & Souissi, R. (2024). CamelEval: Advancing Culturally Aligned Arabic Language Models and Benchmarks (No. arXiv:2409.12623). arXiv. https://doi.org/10.48550/arXiv.2409.12623 
",CamelEval: Advancing Culturally Aligned Arabic Language Models and Benchmarks,Practices less-extractive,Creating culturally inclusive datasets,"Data practices, Community impacts and relations",ML System Design & Development,Model Training & Evaluation,Era 3,ADC,A: introduces Arabic–English LLM (Juhaina) and new benchmark; D: curates culturally aligned tasks; C: improves regional knowledge and nuance,"Grey (Reports, blogs, white papers, policy documents, theses, conference papers)",Database search,MENA; Arabic LLM; culturally aligned evaluation,MENA,Industry,MENA,"Elm Company, Saudi Arabia",,"Describes Juhaina (Arabic–English) and CamelEval, addressing gaps in Arabic cultural alignment. Reports gains over comparable models in Arabic helpfulness, factuality, and nuance. Argues culture-aware evaluation and training are prerequisites for equitable LLM utility for 400+ million Arabic speakers.",
"QueerInAI et al., 2021","QueerInAI, O. O., Ashwin, S., Agnew, W., Jethwani, H., & Subramonian, A. (2021). Rebuilding Trust: Queer in AI Approach to Artificial Intelligence Risk Management. Queer in AI Workshop at NeurIPS 2021. queerinai.org/risk-management ",Rebuilding Trust: Queer in AI Approach to Artificial Intelligence Risk Management,Extractive,Excluding underrepresented groups from decision-making,Community impacts and relations,Problem Understanding & Formulation,Institutional Prioritization & Funding,Era 3,ADC,A: calls for independent monitoring & risk mgmt; D: guidance on handling gender/sexuality data; C: participatory design shifting power to queer orgs,"Grey (Reports, blogs, white papers, policy documents, theses, conference papers)",Iterative keyword search,"Queer, participatory design, trust, ML harms, monitoring",Not regionally specific,Mixed,North America,"Queer in AI, USA",,"Trustworthy artificial intelligence (AI) has become an important topic because trust in AI systems and their creators has been lost. Researchers, corporations, and governments have long and painful histories of excluding marginalized groups from technology development, deployment, and oversight. As a result, these technologies are less useful and even harmful to minoritized groups. We argue that any AI development, deployment, and monitoring framework that aspires to trust must incorporate both feminist, non-exploitative participatory design principles and strong, outside, and continual monitoring and testing. We additionally explain the importance of considering aspects of trustworthiness beyond just transparency, fairness, and accountability, specifically, to consider justice and shifting power to the disempowered as core values to any trustworthy AI system. Creating trustworthy AI starts by funding, supporting, and empowering grassroots organizations like Queer in AI so the field of AI has the diversity and inclusion to credibly and effectively develop trustworthy AI. We leverage the expert knowledge Queer in AI has developed through its years of work and advocacy to discuss if and how gender, sexuality, and other aspects of queer identity should be used in datasets and AI systems and how harms along these lines should be mitigated.",
"QueerInAI et al., 2023","Queerinai, O. O., Ovalle, A., Subramonian, A., Singh, A., Voelcker, C., Sutherland, D. J., Locatelli, D., Breznik, E., Klubicka, F., Yuan, H., J, H., Zhang, H., Shriram, J., Lehman, K., Soldaini, L., Sap, M., Deisenroth, M. P., Pacheco, M. L., Ryskina, M., … Stark, L. (2023). Queer In AI: A Case Study in Community-Led Participatory AI. 2023 ACM Conference on Fairness, Accountability, and Transparency, 1882–1895. https://doi.org/10.1145/3593013.3594134 
 ",Queer In AI: A Case Study in Community-Led Participatory AI,Practices less-extractive,Early co-design and participatory initiatives,"Community impacts and relations, Data practices",Problem Understanding & Formulation,Product Conception & Design,Era 3,ADC,A: situates Queer in AI as participatory design practice; D: reflects on operationalization of intersectional principles; C: centers LGBTQIA2S+ community activism and institutional influence,"White (published journal papers, conference proceedings, books)",Database search,"Global, queer, participatory, agenda-setting",Not regionally specific,Academic,North America,"Queer in AI, USA","Organizers Of QueerInAI, Anaelia Ovalle, Arjun Subramonian, Ashwin Singh, Claas Voelcker,
Danica J. Sutherland, Davide Locatelli, Eva Breznik, Filip Klubička, Hang Yuan, Hetvi J, Huan Zhang,
Jaidev Shriram, Kruno Lehman, Luca Soldaini, Maarten Sap, Marc Peter Deisenroth, Maria Leonor
Pacheco, Maria Ryskina, Martin Mundt, Milind Agarwal, Nyx McLean, Pan Xu, A Pranav, Raj
Korpan, Ruchira Ray, Sarah Mathew, Sarthak Arora, ST John, Tanvi Anand, Vishakha Agrawal,
William Agnew, Yanan Long, Zijie J. Wang, Zeerak Talat, Avijit Ghosh, Nathaniel Dennler, Michael
Noseworthy, Sharvani Jha, Emi Baylor, Aditya Joshi, Natalia Y. Bilenko, Andrew McNamara, Raphael
Gontijo-Lopes, Alex Markham, Evyn Dong, Jackie Kay, Manu Saraswat, Nikhil Vytla, Luke Stark 
Queer in AI’s mission is to raise awareness of queer issues in AI/ML, foster a community of queer researchers and celebrate the work of queer scientists. We use “queer” as an umbrella term for people with diverse non-normative sexual orientations, romantic orientations, and/or genders, corresponding to acronyms like LGBTQIA2S+. We also explicitly include those questioning their identities.

Queer in AI was established by queer scientists in AI with the mission to make the AI community a safe and inclusive place that welcomes, supports, and values LGBTQIA2S+ people. We work towards this aim by building a visible community of queer AI scientists through conference workshops, social meetups, conference poster sessions, mentoring programs, graduate application financial aid, and many other initiatives. Another crucial part of our mission is to raise awareness of queer issues in the general AI community and to encourage and highlight research on and solutions to these problems.","Presents Queer in AI as a participatory design case. Analyzes how intersectional tenets informed its programs, where participatory ideals fell short, and the organization’s broader impact. Highlights decentralized governance, mutual aid, and activist interventions within and beyond the queer AI community. Concludes that grassroots communities contribute to participatory design in AI by fostering inclusive cultures, critiquing extractive practices, and reshaping institutional participation norms.",
"Quinless, 2022","Quinless, J. M. (2022). Decolonizing Data: Unsettling Conversations about Social Research Methods. University of Toronto Press.",Decolonizing Data: Unsettling Conversations about Social Research Methods,Principles less-extractive,Decentering Western ontologies,"Community impacts and relations, Critical theory/Historical background",Problem Understanding & Formulation,Product Conception & Design,Multi-era,DC,A: none; D: critiques and reimagines research methods through Indigenous and Western frameworks; C: addresses health inequalities and Indigenous perspectives in Canada,"White (published journal papers, conference proceedings, books)",Database search,"Canada, Indigenous methodology, health inequality",North America,Academic,North America,"Center for Indigenous Research and Community Led Engagement, Canada",,"Explores how ongoing structures of colonialization negatively impact the well-being of Indigenous peoples and communities across Canada, resulting in persistent health inequalities. Drawing on both western and Indigenous methodologies, this unique scholarly contribution takes both a sociological perspective and the ""two-eyed seeing"" approach to research methods. By looking at the ways that everyday research practices contribute to the colonization of health outcomes for Indigenous peoples, Decolonizing Data exposes the social dimensions of healthcare and offers a careful and respectful reflection on how to ""unsettle conversations"" about applied social research initiatives for our most vulnerable groups.",
"Rajab et al., 2025","Rajab, J., Aremu, A., Chimoto, E. A., Dunbar, D., Morrissey, G., Thior, F., Potgieter, L., Ojo, J., Tonja, A. L., Chetty, M., Nekoto, W. N., Moiloa, P., Abbott, J., Marivate, V., & Rosman, B. (2025). The Esethu Framework: Reimagining Sustainable Dataset Governance and Curation for Low-Resource Languages (No. arXiv:2502.15916). arXiv. https://doi.org/10.48550/arXiv.2502.15916 
 ",The Esethu Framework: Reimagining Sustainable Dataset Governance and Curation for Low-Resource Languages,Principles less-extractive,Developing equitable data licensing models,"Community impacts and relations, Data labor",ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,ADC,"A: ASR experiments using ViXSD; D: community-centric curation & licensing; C: sovereignty, benefit-sharing, community protection","Grey (Reports, blogs, white papers, policy documents, theses, conference papers)",Citation/reference snowballing,"community-centric data license, Africa, open source licensing",Africa,Mixed,Africa,"Lelapa AI, RAIL Lab - University of the Witwatersrand, South Africa","Way With Words; DSFSI– University of Pretoria; MBZUAI, UAE; Masakhane, Africa; Independent. First 3 authors equal contributions","Introduces the Esethu Framework and license for community-centric governance of language datasets. As proof-of-concept, releases the isiXhosa ViXSD corpus with demographic/linguistic metadata and reports ASR experiments demonstrating utility. The framework prioritizes sovereignty, consent, and benefit-sharing while constraining misuse. Paper links licensing terms to concrete curation practices, arguing sustainable governance is essential for equitable low-resource language technologies in African contexts.",
"Raji & Buolamwini, 2023","Raji, I. D., & Buolamwini, J. (2023). Actionable Auditing Revisited: Investigating the Impact of Publicly Naming Biased Performance Results of Commercial AI Products. Communications of the ACM, 66(1), 101–108. https://doi.org/10.1145/3571151",Actionable Auditing Revisited: Investigating the Impact of Publicly Naming Biased Performance Results of Commercial AI Products,Practices less-extractive,Building public visibility in dataset development,Community impacts and relations,Deployment & Impact,Product Launch,Multi-era,ADC,A: evaluates public AI audits; D: uses PPB dataset and disclosure to shift vendor behavior; C: links naming harms to improvements benefiting affected users,"White (published journal papers, conference proceedings, books)",Citation/reference snowballing,algorithmic audit; facial recognition; PPB; accountability,Not regionally specific,Academic,North America,"University of Toronto, Canada; MIT, USA",,"Reassesses the impact of “Gender Shades,” which publicly named disparate performance in commercial facial recognition. Details the PPB dataset and audit design, then traces vendor performance changes post-publication. Shows how public disclosure can drive remediation while noting limits and the need for systemic governance beyond single audits.",
"Randhawa et al., 2021","Randhawa, S. M., Ahmad, T., Chen, J., & Raza, A. A. (2021). Karamad: A Voice-based Crowdsourcing Platform for Underserved Populations. Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems, 1–15. https://doi.org/10.1145/3411764.3445417",Karamad: A Voice-based Crowdsourcing Platform for Underserved Populations,Practices less-extractive,Crowdsourcing data collection,"Community impacts and relations, Data practices",ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,ADC,A: crowdsourcing platform generates data for AI training tasks; D: voice-based system enables low-resource workers to contribute data via feature phones; C: provides access and income opportunities for underserved communities in Pakistan.,"White (published journal papers, conference proceedings, books)",Database search,Pakistan; crowdsourcing; speech data; accessibility,APAC (Asia-Pacific Region),Academic,MENA,"Computer Science Department New York University, United Arab Emirates","Department of Computer Science Lahore University of Management Sciences, Pakistan; Computer Science ICSI, USA; School of Science and Engineering Lahore University of Management Sciences, Pakistan","Introduces Karamad, a platform enabling low-resource workers to complete AI training tasks via feature phones. Six-month deployment in Pakistan engaged 725 workers completing nearly 4,000 tasks. Demonstrates feasibility of inclusive voice-based crowdwork, highlighting participation of women, unemployed, non-literate, and blind users. Shows potential for both community income and diverse dataset creation.",
"Raza et al., 2024","Raza, S., Ghuge, S., Ding, C., Dolatabadi, E., & Pandya, D. (2024). FAIR Enough: Develop and Assess a FAIR-Compliant Dataset for Large Language Model Training? Data Intelligence, 6(2), 559–585. https://doi.org/10.1162/dint_a_00255",FAIR Enough: Develop and Assess a FAIR-Compliant Dataset for Large Language Model Training?,Principles less-extractive,"Community engaged data production, Early co-design and participatory initiatives, Participatory data ownership & governance",Data practices,ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,ADC,A: addresses LLM data stewardship; D: operationalizes FAIR via framework and checklist; C: targets bias mitigation and responsible reuse,"White (published journal papers, conference proceedings, books)",Database search,FAIR data; LLM training; checklist,Not regionally specific,Mixed,North America,"Vector Institute for Artificial Intelligence in Toronto, ON, Canada","Toronto Metropolitan University, Toronto, Ontario, Canada","Proposes a framework and checklist to embed FAIR (Findable, Accessible, Interoperable, Reusable) principles into LLM dataset lifecycles. Validates via a case study constructing a FAIR-compliant dataset to detect/mitigate bias. Aims to standardize documentation and access while improving integrity and accountability in large-scale training corpora.",
"Reitmaier et al., 2022","Reitmaier, T., Wallington, E., Kalarikalayil Raju, D., Klejch, O., Pearson, J., Jones, M., Bell, P., & Robinson, S. (2022). Opportunities and Challenges of Automatic Speech Recognition Systems for Low-Resource Language Speakers. Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems, 1–17. https://doi.org/10.1145/3491102.3517639",Opportunities and Challenges of Automatic Speech Recognition Systems for Low-Resource Language Speakers,Practices less-extractive,"Community engaged data production, Taking a needs-based approach to developing AI","Data practices, Community impacts and relations",ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,ADC,A: evaluates and field-tests ASR with real use cases; D: collects speech data and tests models with community input; C: addresses needs of low-resource speakers in South Africa and India,"White (published journal papers, conference proceedings, books)",Database search,"Africa, automatic speech recognition, spoken data, community toolkit",Multiple areas,Academic,EU/UK,"Swansea University, UK","University of Edinburgh, United Kingdom; Studio Hasi, India; School of Informatics, University of Edinburgh, United Kingdom","Deploys methods and tools with communities outside Cape Town and in Mumbai to collect speech data, test ASR, and reflect on WhatsApp voice use. Identifies design opportunities, barriers, and ethics for situating ASR in context, demonstrating how engagement improves fit for low-resource speakers.",
"Reitmaier et al., 2023","Reitmaier, T., Wallington, E., Klejch, O., Markl, N., Lam-Yee-Mui, L.-M., Pearson, J., Jones, M., Bell, P., & Robinson, S. (2023). Situating Automatic Speech Recognition Development within Communities of Under-heard Language Speakers. Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems, 1–17. https://doi.org/10.1145/3544548.3581385",Situating Automatic Speech Recognition Development within Communities of Under-heard Language Speakers,Practices less-extractive,"Community engaged data production, Taking a needs-based approach to developing AI","Data practices, Community impacts and relations",ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,ADC,A: demonstrates ASR via community toolkits; D: deploys data collection/crowdsourcing; C: foregrounds under-heard speakers’ needs,"White (published journal papers, conference proceedings, books)",Database search,Africa; ASR; toolkit; community feedback,Africa,Academic,EU/UK,"Swansea University, United Kingdom","University of Edinburgh, United Kingdom; Université Paris-Saclay, CNRS, Laboratoire Interdisciplinaire des Sciences du Numérique, France and Vocapia Research, France; School of Informatics, University of Edinburgh, United Kingdom","Introduces a toolkit for ASR development tailored to under-heard language speakers. Includes appliance for spoken-data collection, mobile app for transcripts, and demonstrators for feedback. Deployed with African communities to align technical development with user needs. Challenges mainstream ASR orthodoxy and highlights benefits of community-grounded engagement.",
"Research Data Alliance International Indigenous Data Sovereignty Interest Group, 2019 ",Research Data Alliance International Indigenous Data Sovereignty Interest Group. (2019). CARE Principles for Indigenous Data Governance. The Global Indigenous Data Alliance.,CARE Principles for Indigenous Data Governance,Principles less-extractive,Participatory data ownership & governance,"Critical theory/Historical background, Community impacts and relations",Problem Understanding & Formulation,Institutional Prioritization & Funding,Multi-era,DC,"A: none; D: specifies collective benefit, authority, responsibility, ethics; C: centers Indigenous sovereignty and self-determination","Grey (Reports, blogs, white papers, policy documents, theses, conference papers)",Database search,global; Indigenous data governance; CARE; sovereignty,Not regionally specific,Academic,North America,"University of Arizona, USA","Campus Montecillo, Mexico; University of Western Cape South Africa; Australian National University; Australia, One Planet Solutions France; University of Waikato, New Zealand","Framework outlining the need to prioritize Indigenous rights and self-determination in the context of increasing global data use. The document emphasizes that while open data initiatives offer potential benefits, they must be implemented in a way that respects Indigenous sovereignty over data derived from their communities, knowledge, and territories. This sovereignty includes the right to govern data use, ensure that benefits from data use return to Indigenous communities, and require ethical data practices that avoid harm and uphold Indigenous values. Above all, CARE Principles is about making sure that data use empowers Indigenous communities and contributes to their self-determination and well-being.",https://docs.google.com/viewer?url=https%3A%2F%2Fwww.gida-global.org%2Fs%2FCAREPrinciples_OnePagersFINAL_Oct_17_2019.pdf
"Rifat et al., 2024","Rifat, M. R., Safir, A. H., Saha, S., Junaed, J. A., Saleki, M., Amin, M. R., & Ahmed, S. I. (2024). Data, Annotation, and Meaning-Making: The Politics of Categorization in Annotating a Dataset of Faith-based Communal Violence. The 2024 ACM Conference on Fairness, Accountability, and Transparency, 2148–2156. https://doi.org/10.1145/3630106.3659030","Data, Annotation, and Meaning-Making: The Politics of Categorization in Annotating a Dataset of Faith-based Communal Violence",Extractive,Biased pre-processing and category erasure,"Data practices, Data labor",ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,ADC,A: bias observed in model training context; D: critiques annotation categories and secular defaults; C: centers South Asian religious/spiritual values overlooked in data practices,"Grey (Reports, blogs, white papers, policy documents, theses, conference papers)",Database search,"South Asia, data annotation, violence, FRS, religion, dataset development, marginalized communities",APAC (Asia-Pacific Region),Academic,North America,"University of Toronto, Canada","University of Cambridge, UK; Shahjalal University of Science and Technology, Bangladesh; Fordham University, USA","Analysis of annotating a South Asia faith-based violence dataset shows how secular “objectivity” and category choices erase religious/spiritual meanings. Authors trace context collapse to label design, crowd norms, and quality control pressures. They argue for reflexive, situated annotation practice and culturally literate categories to avoid harm and misclassification in sensitive domains.",
"Roberts, 2024","Roberts, J. S. (2024, January 23). In Consideration of Indigenous Data Sovereignty: Data Mining as a Colonial Practice. Montreal AI Ethics Institute. https://montrealethics.ai/in-consideration-of-indigenous-data-sovereignty-data-mining-as-a-colonial-practice/",In Consideration of Indigenous Data Sovereignty: Data Mining as a Colonial Practice,Principles less-extractive,Participatory data ownership & governance,"Community impacts and relations, Critical theory/Historical background",ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,ADC,A: critiques AI-adjacent data mining practices; D: applies CARE to ethical data use; C: details harms from ignoring Indigenous rights,"Grey (Reports, blogs, white papers, policy documents, theses, conference papers)",Database search,Multiple regions; data mining; CARE; Indigenous rights,Multiple areas,NGO/Non-profit,North America,"Accel AI institute, USA",,"Argues that data mining practices can mirror colonial practices of exploitation by failing to acknowledge Indigenous data sovereignty, which is the right of Indigenous peoples to control their own data. The authors illustrate how the CARE Principles of Indigenous Data Governance (Collective Benefit, Authority to Control, Responsibility, and Ethics) offer a framework for more ethical data practices. By examining case studies, the paper reveals the potential harm of ignoring Indigenous data rights, such as the violation of privacy and perpetuation of power imbalances. ",
"Rojas et al., 2022","Gaviria Rojas, W., Diamos, S., Kini, K., Kanter, D., Janapa Reddi, V., & Coleman, C. (2022). The Dollar Street Dataset: Images Representing the Geographic and Socioeconomic Diversity of the World. Advances in Neural Information Processing Systems, 35, 12979–12990. https://proceedings.neurips.cc/paper_files/paper/2022/hash/5474d9d43c0519aa176276ff2c1ca528-Abstract-Datasets_and_Benchmarks.html ",The Dollar Street Dataset: Images Representing the Geographic and Socioeconomic Diversity of the World,Practices less-extractive,"Creating culturally inclusive datasets, Crowdsourcing data collection",Data practices,ML System Design & Development,Model Training & Evaluation,Era 3,ADC,A: introduces vision benchmarks targeting underrepresented contexts; D: curates globally distributed household images with socioeconomic labels; C: improves robustness for lower-income settings,"White (published journal papers, conference proceedings, books)",Citation/reference snowballing,global; image dataset; computer vision; socioeconomic diversity,Multiple areas,Mixed,North America,"Coactive AI, USA","Coactive AI; MLCommons; Harvard University, USA","Presents a globally sourced image dataset capturing everyday household objects across income levels to counter narrow distributions in vision data. Documents collection ethics, labeling, and benchmarks, showing accuracy gains on images from lower-income settings. Positions socioeconomic and geographic diversity as necessary dataset dimensions for fairer computer-vision models and downstream applications affecting underserved communities",
"Rostamzadeh et al., 2022","Rostamzadeh, N., Mincu, D., Roy, S., Smart, A., Wilcox, L., Pushkarna, M., Schrouff, J., Amironesei, R., Moorosi, N., & Heller, K. (2022). Healthsheet: Development of a Transparency Artifact for Health Datasets. Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency, 1943–1961. https://doi.org/10.1145/3531146.3533239",Healthsheet: Development of a Transparency Artifact for Health Datasets,Principles less-extractive,Building public visibility in dataset development,"Data practices, Ethics frameworks",ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,AD,"A: positions Healthsheet as a diagnostic for ML datasets in healthcare; D: adapts datasheets through interviews and case studies across creation, use, and maintenance; C: none (high-stakes context but no community focus)","White (published journal papers, conference proceedings, books)",Database search,"North America, health dataset, documentation, accountability",North America,Industry,North America,"Google, Canada","Google, United Kingdom; Google, USA; Google, Ghana","Adapts “datasheets” to high-stakes health by deriving a context-specific questionnaire through interviews and three dataset case studies (EHR, trials, mobile outcomes). Shows inconsistent adoption and gaps in documenting creation, use, and maintenance. Presents Healthsheet as a practical diagnostic to surface limitations, support accountability, and inform safer downstream modeling in clinical contexts.",
"Running Wolf & Arista, 2020","Running Wolf, C., & Arista, N. (2020). Indigenous Protocols in Action. In J. E. Lewis, A. Abdilla, N. Arista, K. Baker, S. Benesiinaabandan, M. Brown, M. Cheung, M. Coleman, A. Cordes, J. Davison, K. Duncan, S. Garzon, D. F. Harrell, P.-L. Jones, K. Kealiikanakaoleohaililani, M. Kelleher, S. Kite, O. Lagon, J. Leigh, … H. Whaanga, Indigenous Protocol and Artificial Intelligence Position Paper (pp. 93–101). Indigenous Protocol and Artificial Intelligence Working Group and the Canadian Institute for Advanced Research. https://doi.org/10.11573/spectrum.library.concordia.ca.00986506 ",Indigenous Protocols in Action,Practices less-extractive,Community engaged data production,"Data practices, Community impacts and relations",ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,ADC,A: connects Indigenous protocols to AI applications; D: documents vocabularies and translation practices; C: centers cultural sovereignty,"White (published journal papers, conference proceedings, books)","Existing networks, relevant organizations and conferences",North America; machine vision; translation; Indigenous language,Multiple areas,Mixed,North America,"Independent Indigenous scholar, Crow Nation, USA; University of Hawaiʻi at Mānoa, USA","Caroline Running Wolf (Crow Nation), née Old Coyote, is an enrolled member of the Apsáalooke  Nation (Crow) in Montana, with a Swabian (German) mother and also Pikuni, Oglala, and Ho-Chunk  heritage. As the daughter of nomadic parents, she grew up between USA, Canada, and Germany.  Thanks to her genuine interest in people and their stories, she is a multilingual Cultural Acclimation  Artist dedicated to supporting Indigenous language and culture vitality. After working for over 15  years as a professional nerd herder and business consultant in various fields, Running Wolf co-founded  a nonprofit, Buffalo Tongue, with her husband, Michael Running Wolf. Together they create virtual  and augmented reality experiences to advocate for Native American voices, languages, and cultures.  Running Wolf has a Master’s degree in Native American Studies from Montana State University in  Bozeman, Montana. She is currently pursuing her PhD in Anthropology at the University of British  Columbia in Vancouver, Canada.  
Dr. Noelani Arista (Kanaka Maoli), Researcher, Writer, Historian, is Associate Professor of  Hawaiian and American History at the University of Hawaiʻi-Mānoa. Her research and writing  focus on Hawaiian religious, legal, and intellectual history. Dr. Arista’s current projects further  the persistence of Hawaiian historical knowledge and Hawaiian language textual archives through  multiple digital mediums including gaming. Dr. Arista is known for her work in developing new  approaches and methods for writing Hawaiian history up from customary modes of keeping Hawaiian  knowledge. Her work has also focused on precision in crafting historical contexts as an important  first step in approaching the interpretation and translation of Hawaiian language sources. Her work  in historiography, the training of Hawaiian intellectuals, as well as translation has prepared her  for considering larger questions of cognition, and how artificial intelligence might be created and  approached on Hawaiian terms. She mentors many students, instructing them in how to conduct  research in Hawaiian language textual archives, and through online digital mediums. She was a  contributing author to “Making Kin with Machines,” an essay about Indigenous views on Artificial  Intelligence, one of ten award winning essays in the MIT competition, Resisting Reduction. Her book  The Kingdom and the Republic: Sovereign Hawaiʻi and the Early USA was published by  PENN press in 2019. Her creative projects include the extensive facebook archive of mele, translation  and photos that she wrote and compiled, 365 Days of Aloha.","Describes prototyping of Hua Kiʻi, a polylingual Indigenous language image-recognition app with geolocation. Details collaborative dictionary-building (Hawaiian, Cheyenne), translation workflows, and constraints of using Western object classifiers. Links show how protocols and community expertise guide dataset concepts and future model training toward culturally meaningful recognition.",
"Sabin, 2024","Sabin, A. (2024). Prioritizing Indigenous Participation and Compensation in Research. Journal of Critical Global Issues, 1(1). https://doi.org/10.62895/2997-0083.1004 
",Prioritizing Indigenous Participation and Compensation in Research,Practices less-extractive,Establishing consent and contextually appropriate compensation,"Data labor, Community impacts and relations",ML System Design & Development,"Data Selection, Collection & Annotation",Multi-era,DC,"A: none; D: advances participatory consent and compensation in data collection with Indigenous partners; C: centers sovereignty, equity, and community-defined benefit","White (published journal papers, conference proceedings, books)",Database search,Indigenous data; consent; compensation,Not regionally specific,Academic,North America,"California Polytechnic State University, San Luis Obispo, USA",,"Argues for ethical partnerships with Indigenous communities across research lifecycles, emphasizing consent, compensation, and sovereignty. Provides practice-oriented guidance—co-design, community participation in analysis, and benefit-sharing—to counter extractive norms in data collection. Offers transferable principles for AI data work that engages Indigenous knowledge holders.",
"Sadowski, 2019","Sadowski, J. (2019). When data is capital: Datafication, accumulation, and extraction. Big Data & Society. https://doi.org/10.1177/2053951718820549","When data is capital: Datafication, accumulation, and extraction",Extractive,"Prioritizing data wants over community needs, Collecting vast amounts of data to train AI systems",Critical theory/Historical background,Problem Understanding & Formulation,Institutional Prioritization & Funding,Multi-era,ADC,A: links data capitalism to AI data accumulation; D: theorizes extraction via opaque consent and infrastructure; C: discusses societal exposure and power imbalance,"White (published journal papers, conference proceedings, books)",Database search,global; data capitalism; extraction; consent,Not regionally specific,Academic,Oceania,"University of Sydney, Australia",,"Argues that data is a new form of capital, similar to economic capital, that is central to 21st-century political economy. Sadowski builds upon the theories of Marx and Bourdieu to illustrate how data acts like capital by circulating and accumulating value. He explains how this data is often unjustly extracted from users of “smart” technologies through intentionally obscured and exploitative methods of consent and compensation. Sadowski concludes by comparing data capitalism to finance capitalism, suggesting that both are systems that create new methods of accumulation through complex, opaque means.",
"Salvaggio, 2024","Salvaggio, E. (2024, June 12). Context, Consent, and Control: The Three C’s of Data Participation in the Age of AI | TechPolicy.Press. Tech Policy Press. https://techpolicy.press/context-consent-and-control-the-three-cs-of-data-participation-in-the-age-of-ai","Context, Consent, and Control: The Three C’s of Data Participation in the Age of AI",Principles less-extractive,Participatory data ownership & governance,Data practices,ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,ADC,A: addresses AI training data participation and creator signals; D: advances policy levers for consent and control; C: centers user agency and harm reduction,"Grey (Reports, blogs, white papers, policy documents, theses, conference papers)",Database search,global; AI training data; consent; participation,Not regionally specific,NGO/Non-profit,North America,"Tech Policy Press, Rochester Institute of Technology's Humanities, Computing, and Design program, USA",,"Examines the growing discomfort surrounding the use of personal data for AI training. Salvaggio argues that the current approach to data collection, often described as ""extractive,"" fails to consider the context, consent, and control that individuals should have over their data. He critiques the notion that datasets are simply collections of ""facts"" devoid of individual ownership or creative expression. Salvaggio highlights the need for policy changes that prioritize user agency, suggesting that preference signals could empower creators to indicate acceptable uses of their data. By emphasizing these three ""C's,"" the article calls for a more nuanced approach to AI development that respects individual rights and fosters a sense of control within the data economy.",
"Sambasivan et al., 2021a","Sambasivan, N., Arnesen, E., Hutchinson, B., Doshi, T., & Prabhakaran, V. (2021). Re-imagining Algorithmic Fairness in India and Beyond (No. arXiv:2101.09995). arXiv. http://arxiv.org/abs/2101.09995",Re-imagining Algorithmic Fairness in India and Beyond,Extractive,Biased pre-processing and category erasure,"Data practices, Community impacts and relations",ML System Design & Development,Model Training & Evaluation,Era 3,ADC,A: critiques fairness models; D: analyzes dataset distortions; C: highlights representational harms for Indian users,"Grey (Reports, blogs, white papers, policy documents, theses, conference papers)",Database search,"India, Global South, algorithmic fairness, dataset development, representational harms, double standards of ML developers, AI euphoria, marginalized communities",APAC (Asia-Pacific Region),Industry,North America,"Google Research, USA",,"Challenges the Western-centric nature of current algorithmic fairness research. The authors highlight data and model distortions stemming from India’s diverse socio-economic factors, arguing that Western assumptions about data reliability and sub-group representation don’t hold true. They expose the double standards employed by some AI developers who treat Indian users as “petri dishes” for intrusive models with limited recourse for harm. Lastly, the authors critique the unquestioning AI aspiration in India, arguing that a lack of critical transparency and a robust ecosystem of stakeholders hinders meaningful fairness.",
"Sambasivan et al., 2021b","Sambasivan, N., Kapania, S., Highfill, H., Akrong, D., Paritosh, P., & Aroyo, L. M. (2021). “Everyone wants to do the model work, not the data work”: Data Cascades in High-Stakes AI. Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems, 1–15. https://doi.org/10.1145/3411764.3445518"," “Everyone wants to do the model work, not the data work”: Data Cascades in High-Stakes AI",Extractive,Biased pre-processing and category erasure,Data practices,Problem Understanding & Formulation,Institutional Prioritization & Funding,Era 3,ADC,A: defines pervasive data cascades in high-stakes AI; D: identifies organizational/process drivers of poor data work; C: links failures to harms in deployed systems,"White (published journal papers, conference proceedings, books)",Database search,data cascade; practitioner interview; data documentation; domain expertise,Multiple areas,Industry,North America,"Google Research, USA","Google Research India, India; Google Inc., United States; Google Research Accra, Ghana; Google, United States","53 interviews across India, East/West Africa, and the USA reveal “data cascades”—compounding data issues with delayed, harmful impacts. Pinpoints incentive misalignment, undervalued domain expertise, and weak documentation. Advocates “data excellence” via training, incentives, and tooling to prevent downstream harms in high-stakes deployments.",
"Sambasivan, 2022","Sambasivan, N. (2022). All equation, no human: The myopia of AI models. Interactions, 29(2), 78–80. https://doi.org/10.1145/3516515","All equation, no human: The myopia of AI models",Extractive,Exploitative and invisible data labor,Data practices,Cross-pipeline,Cross-pipeline,Era 3,AD,A: critiques model-centric AI development approach; D: highlights overlooked data work and domain expertise; C: none (indirect implications),"White (published journal papers, conference proceedings, books)",Citation/reference snowballing,"model-centric approach, data cascades, domain expertise",Not regionally specific,Industry,North America,"Google, USA",,"Critiques the field of AI for its singular focus on model development at the expense of considering real-world impacts. Sambasivan argues that this “model-centric” approach overlooks the crucial roles of data work and domain expertise in building effective and ethical AI systems, particularly in low-resource contexts. Highlights the problem of “data cascades,” where flawed data practices have negative downstream consequences, and emphasizes the need to recognize and value the contributions of domain experts who are often relegated to mere data collectors.",
"Sap et al., 2019","Sap, M., Card, D., Gabriel, S., Choi, Y., & Smith, N. A. (2019). The Risk of Racial Bias in Hate Speech Detection. In A. Korhonen, D. Traum, & L. Màrquez (Eds.), Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics (pp. 1668–1678). Association for Computational Linguistics. https://doi.org/10.18653/v1/P19-1163",The Risk of Racial Bias in Hate Speech Detection,Extractive,Biased pre-processing and category erasure,"Data practices, Community impacts and relations",ML System Design & Development,"Data Selection, Collection & Annotation",Multi-era,ADC,A: evaluates toxicity models; D: shows annotation/data bias tied to AAE markers; C: identifies disparate impacts on AAE users and proposes priming mitigation,"White (published journal papers, conference proceedings, books)",Citation/reference snowballing,North America; AAE; hate speech detection; annotation bias,North America,Mixed,North America,"University of Washington, Seattle, USA","Paul G. Allen School of Computer Science & Engineering, University of Washington; Machine Learning Department, Carnegie Mellon University, PA, USA; Allen Institute for AI, Seattle, WA, USA","Shows tweets with African American English markers are more likely to be labeled offensive in widely used hate-speech datasets, and models learn this bias. Demonstrates “dialect and race priming” to reduce annotation bias. Connects dataset composition and annotator cues to downstream harms for AAE speakers, linking data practices to community impact.",
"Saturday & Nyamwire, 2023","Saturday, B., & Nyamwire, B. (2023). Towards Effective Data Governance in Africa (Progress, Initiatives and Challenges). https://pollicy.org/resource/towards-effective-data-governance-in-africa-progress-initiatives-and-challenges/ 
","Towards Effective Data Governance in Africa (Progress, Initiatives and Challenges)",Extractive,Ethics dumping in less-regulated contexts,"Data practices, Community impacts and relations",Problem Understanding & Formulation,Institutional Prioritization & Funding,Era 3,ADC,A: surveys continental data governance progress and gaps; D: documents weak enforcement and capacity constraints; C: flags risks to communities amid rapid digitization,"Grey (Reports, blogs, white papers, policy documents, theses, conference papers)",Citation/reference snowballing,Africa; data governance; regulation; capacity,Africa,NGO/Non-profit,Africa,"Pollicy, Uganda",,"Desk review of African data governance across regions and sectors. Finds expanding legal frameworks but persistent capacity, coordination, and political barriers. Profiles collaborations (EAC, SADC, ECOWAS) and sector systems. Emphasizes the need for skills, enforcement, and multi-stakeholder engagement to reduce harms from accelerating data production affecting citizens and service delivery.",
"Scheuerman et al., 2020","Scheuerman, M. K., Wade, K., Lustig, C., & Brubaker, J. R. (2020). How We’ve Taught Algorithms to See Identity: Constructing Race and Gender in Image Databases for Facial Analysis. Proc. ACM Hum.-Comput. Interact., 4(CSCW1), 58:1-58:35. https://doi.org/10.1145/3392866",How We’ve Taught Algorithms to See Identity: Constructing Race and Gender in Image Databases for Facial Analysis,Extractive,Biased pre-processing and category erasure,"Data practices, Data labor, Community impacts and relations",ML System Design & Development,"Data Selection, Collection & Annotation",Era 2,ADC,"A: examines facial analysis systems’ dependence on labeled image data; D: shows undefined, apolitical, and undocumented identity labeling practices; C: links these practices to harm, mistrust, and marginalization","White (published journal papers, conference proceedings, books)",Database search,"facial analysis, identity classification, dataset governance",Not regionally specific,Academic,North America,"University of Colorado Boulder, Boulder, CO, USA","University of Colorado Boulder, Boulder, CO, USA; University of Washington, Seattle, WA, USA","Analyzes how race/gender are defined/annotated in facial-analysis datasets. Finds missing provenance and apolitical treatment of categories. Shows how such practices obfuscate sociopolitical histories and erode trust, urging dataset authors to engage positionality and classification histories.",
"Scheuerman et al., 2023","Scheuerman, M. K., Weathington, K., Mugunthan, T., Denton, E., & Fiesler, C. (2023). From Human to Data to Dataset: Mapping the Traceability of Human Subjects in Computer Vision Datasets. Proceedings of the ACM on Human-Computer Interaction, 7(CSCW1), 1–33. https://doi.org/10.1145/3579488","From Human to Data to Dataset: Mapping the Traceability of
Human Subjects in Computer Vision Datasets
",Extractive,Collecting vast amounts of data to train AI systems,Data practices,ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,ADC,A: studies CV dataset curation; D: maps flows from capture to dataset circulation; C: proposes traceability ethics to restore subject awareness/control,"White (published journal papers, conference proceedings, books)",Citation/reference snowballing,North America; computer vision datasets; traceability; consent,North America,Academic,North America,"University of Colorado Boulder, CO, USA",,"Analyzes how images of people move from capture to datasets and into downstream CV applications. Identifies barriers to data-subject awareness and control, even when original sources are removed. Proposes an “ethics of traceability” with interventions across curation steps to improve consent, visibility, and redress for subjects embedded in training corpora. Connects dataset mechanics to lived impacts.",
"Scheuerman, 2024","Scheuerman, M. K. (2024). In the Walled Garden: Challenges and Opportunities for Research on the Practices of the AI Tech Industry. The 2024 ACM Conference on Fairness, Accountability, and Transparency, 456–466. https://doi.org/10.1145/3630106.3658918",In the Walled Garden: Challenges and Opportunities for Research on the Practices of the AI Tech Industry,Extractive,Western-centric research infrastructure,"Data practices, Ethics frameworks",Cross-pipeline,Cross-pipeline,Era 3,AD,"A: studies research access around industry AI practices; D: focuses on documentation, auditing, NDA barriers shaping data workflows; C: none","Grey (Reports, blogs, white papers, policy documents, theses, conference papers)",Hand-searching key journals,"North America, research access, NDAs, auditing",North America,Academic,North America,"University of Colorado, Boulder, CO, USA",,"Examines barriers to studying industry AI practices, including recruitment hurdles, NDA anxieties, and weak incentives for participation. Shows how restricted access constrains external auditing and documentation of data/model workflows. Outlines pragmatic strategies for trust-building and value alignment with firms while urging organizational changes that improve transparency. Links research access dynamics to public accountability in AI data production and evaluation.",
"Schiff et al., 2020","Schiff, D., Rakova, B., Ayesh, A., Fanti, A., & Lennon, M. (2020). Principles to Practices for Responsible AI: Closing the Gap (No. arXiv:2006.04707). arXiv. https://doi.org/10.48550/arXiv.2006.04707",Principles to Practices for Responsible AI: Closing the Gap,Principles less-extractive,Building public visibility in dataset development,"Data practices, Ethics frameworks",Problem Understanding & Formulation,Product Conception & Design,Multi-era,AD,"A: maps principles-to-practices gap; D: proposes participatory, iterative impact assessment as operational practice; C: none (indirect implications)","Grey (Reports, blogs, white papers, policy documents, theses, conference papers)",Database search,impact assessment; organizational practice; tools,Not regionally specific,Mixed,North America,"Georgia Institute of Technology, USA","Also De Monfrot University, UK, Accenture AI, Bar-Ilan University, Israel, and CAIPP.org","Diagnoses why high-level AI principles fail to translate into practice (disciplinary divides, tool overload, complexity). Proposes a broad, guided, iterative, participatory impact-assessment approach and illustrates it with a forest-restoration example. Emphasizes operational processes that surface risks early in conception/design.",
"Schwartz, 2022","Schwartz, L. (2022). Primum Non Nocere: Before working with Indigenous data, the ACL must confront ongoing colonialism. Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), 724–731. https://doi.org/10.18653/v1/2022.acl-short.82","Primum Non Nocere: Before working with Indigenous data, the ACL must confront ongoing colonialism",Principles less-extractive,Taking a needs-based approach to developing AI,"Critical theory/Historical background, Community impacts and relations",ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,ADC,A: critiques NLP field’s focus on dominant languages; D: urges ACL to adopt ethical Indigenous frameworks; C: foregrounds colonial legacies and accountability,"White (published journal papers, conference proceedings, books)",Database search,Indigenous language NLP; colonialism; ACL ethics,Not regionally specific,Academic,North America,"University of Illinois, USA",,"Critiques the field of computational linguistics, arguing that the field has historically focused its research efforts on a small number of prominent languages, largely ignoring Indigenous languages. The authors point out that this lack of attention is not only a matter of linguistic diversity but also of ongoing colonialism, given the historical and ongoing exploitation of Indigenous communities and their data by researchers. Calls for the Association for Computational Linguistics (ACL) to adopt a new ethical framework for research involving Indigenous languages, emphasizing the need for researchers to be cognizant of colonial legacies, ensure their work benefits the communities involved, remain accountable to Indigenous governing bodies, and above all, do no harm.",
SEA-LION,"SEA-LION. (n.d.). SEA-LION. Retrieved September 7, 2025, from https://sea-lion.ai/",SEA-LION,Practices less-extractive,Creating culturally inclusive datasets,"Community impacts and relations, Data practices",ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,ADC,A: builds SEA-focused open LLM family; D: curates regional multilingual data; C: serves under-represented SEA languages and contexts,"Grey (Reports, blogs, white papers, policy documents, theses, conference papers)",Citation/reference snowballing,Southeast Asia; LLM; multilingual data; inclusion,APAC (Asia-Pacific Region),Mixed,APAC (Asia-Pacific Region),"AI Singapore (National Multi-Modal LLM Project), Singapore",,"Describes an open LLM suite centered on Southeast Asian languages and contexts. Anchored by AI Singapore’s NMLP, the project curates regional data and tooling to improve performance for low-resource languages, aiming to counter English dominance and support inclusive downstream applications.",
"Septiandri et al., 2023","Septiandri, A. A., Constantinides, M., Tahaei, M., & Quercia, D. (2023). WEIRD FAccTs: How Western, Educated, Industrialized, Rich, and Democratic is FAccT? 2023 ACM Conference on Fairness, Accountability, and Transparency, 160–171. https://doi.org/10.1145/3593013.3593985","WEIRD FAccTs: How Western, Educated, Industrialized, Rich, and Democratic is FAccT?",Extractive,Western-centric research infrastructure,Community impacts and relations,Problem Understanding & Formulation,Institutional Prioritization & Funding,Era 3,AC,A: evaluates AI fairness research venue; D: none (indirect implications); C: documents WEIRD concentration that skews knowledge and problem framing,"White (published journal papers, conference proceedings, books)",Database search,WEIRD sampling; AI fairness; knowledge distribution,Multiple areas,Industry,EU/UK,"Nokia Bell Labs, UK",,"Audits participant populations in 128 FAccT papers (2018–2022), finding 84% rely solely on Western samples. The study flags generalizability risks and agenda-setting skew, where fairness insights fail to reflect global populations. By evidencing WEIRD concentration, it links venue-wide practices to downstream AI fairness claims and the communities they (mis)represent, highlighting how problem framing and evaluation norms shape data production priorities.",
"Shapiro & McNeish, 2021","Shapiro, J., & McNeish, J.A. (2021). Our Extractive Age: Expressions of Violence and Resistance (1st ed.). Routledge. https://doi.org/10.4324/9781003127611",Our Extractive Age: Expressions of Violence and Resistance,Extractive,Other/NA (conceptual framing),Critical theory/Historical background,Problem Understanding & Formulation,Institutional Prioritization & Funding,Multi-era,C,A: none; D: none; C: frames contemporary extractivism as pervasive violence and resistance,"White (published journal papers, conference proceedings, books)",Database search,"Multiple regions, extraction; violence; resistance",Multiple areas,Academic,North America,"American University, USA","Edited volume with multiple contributors. Second editor: Norwegian University of Life Sciences: Ås, Akershus, NO","Edited collection analyzing contemporary hyper-extractivism across industries (mining, oil, data, tourism). Documents global patterns of dispossession and violence, alongside resistance movements contesting extractive logics. Positions data among wider extractive systems, grounding the landscape of present-day practices.",
"Sharma et al., 2023","Sharma, T., Kwon, Y., Park, J., Liu, Y., Huang, Y., Liu, S., Song, D., Hancock, J., & Wang, Y. (2023). Inclusive.AI: Engaging Underserved Populations in Democratic Decision-Making on AI. OpenAI Grant Interim Report & Underway for Publication. https://socialcomputing.web.illinois.edu/images/Report-InclusiveAI.pdf ",Inclusive.AI: Engaging Underserved Populations in Democratic Decision-Making on AI,Practices less-extractive,Participatory data ownership & governance,Community impacts and relations,Deployment & Impact,Product Testing,Era 3,ADC,A: tests democratic input into AI value decisions; D: evaluates DAO-based voting configurations; C: includes Global South and disability communities,"Grey (Reports, blogs, white papers, policy documents, theses, conference papers)",Iterative keyword search,Global South; USA; DAO; AI governance; underserved group,Multiple areas,Academic,North America,"University of Illinois Urbana-Champaign, USA",,"Research project sponsored by OpenAI called  “InclusiveAI,” designed to give underserved populations a voice in AI decision-making. Underscoring the potential of AI to harm underrepresented groups, the authors argue that traditional methods for gathering user input, such as surveys and interviews, are inadequate in today’s tech landscape. InclusiveAI addresses this challenge by utilizing Decentralized Autonomous Organization (DAO) mechanisms, such as proposals and voting, to facilitate democratic participation. The researchers tested different configurations of InclusiveAI, manipulating voting methods and token distribution to gauge the system’s effectiveness in capturing user preferences related to AI image generation. Results showed a convergence of values among participants despite demographic differences and suggested that quadratic voting with equal token distribution was perceived as the most democratic.",
"Shelby et al., 2023","Shelby, R., Rismani, S., Henne, K., Moon, Aj., Rostamzadeh, N., Nicholas, P., Yilla, N., Gallegos, J., Smart, A., Garcia, E., & Virk, G. (2023). Sociotechnical Harms of Algorithmic Systems: Scoping a Taxonomy for Harm Reduction (No. arXiv:2210.05791). arXiv. http://arxiv.org/abs/2210.05791",Sociotechnical Harms of Algorithmic Systems: Scoping a Taxonomy for Harm Reduction,Extractive,"Excluding underrepresented groups from decision-making, ""Deploying AI systems that lack local, contextual data"", Keeping communities in the dark through opaque data practices",Community impacts and relations,Deployment & Impact,Product Launch,Era 3,AC,A: taxonomy to assess/mitigate harms in system behavior; D: not central; C: covers representational/allocative/QoS/societal harms,"White (published journal papers, conference proceedings, books)",Database search,"Data harms, taxonomy/framework",Not regionally specific,Mixed,North America,"Google Research, JusTech Lab
Australian National University, San Francisco, CA, USA","McGill University, Canada; Australian National University, Australia, Google, USA","Presents a taxonomy of sociotechnical harms associated with algorithmic systems. The authors conducted a scoping review of computing research, identifying five major themes related to these harms: representational, allocative, quality-of-service, interpersonal, and social system/societal harms. These categories highlight how algorithmic systems can perpetuate unjust hierarchies, distribute resources inequitably, and negatively impact individuals, communities, and society at large. The authors argue that understanding these potential harms is essential for practitioners to anticipate and minimize negative consequences, advocating for the development of more responsible and equitable AI systems. The proposed taxonomy serves as a tool to systematically surface and mitigate these harms throughout the lifecycle of algorithmic systems.",
"Shepard, 2022","Shepard, M. (2022). There Are No Facts: Attentive Algorithms, Extractive Data Practices, and the Quantification of Everyday Life. MIT Press.","There Are No Facts: Attentive Algorithms, Extractive Data Practices, and the Quantification of Everyday Life",Extractive,Collecting vast amounts of data to train AI systems,"Data practices, Critical theory/Historical background",ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,ADC,A: links ML governance to extractive sensing and quantification; D: critiques anonymization limits and pervasive data capture; C: details uneven harms and alternative civic practices,"White (published journal papers, conference proceedings, books)",Database search,USA; extractive data practices; surveillance capitalism; positionality,Not regionally specific,Academic,North America,"University at Buffalo, the State University of New York, USA",,"Critically examines how attentive algorithms quantify everyday life through pervasive data capture. Explores positionality, the “statistical imaginary,” and limits of anonymization, showing how reidentification risks persist when datasets are combined. Situates pandemic data practices within surveillance capitalism and documents uneven application across demographics. Argues for civic practices and governance that counter coercive data extraction and center community agency.",
"Silva et al., 2022","Silva, C. M. da, Sauerbronn, F. F., & Thiollent, M. (2022). Decolonial Studies, Non-Extractive Methods, and Participatory Action Research in Accounting. Revista de Administração Contemporânea, 26, e210014. https://doi.org/10.1590/1982-7849rac2022210014.en","Decolonial Studies, Non-Extractive Methods, and Participatory Action Research in Accounting",Principles less-extractive,"Early co-design and participatory initiatives, Decentering Western ontologies","Community impacts and relations, Critical theory/Historical background",ML System Design & Development,"Data Selection, Collection & Annotation",Multi-era,DC,A: none (indirect implications for AI/data fields); D: advances PAR as non-extractive research practice; C: emphasizes Global South community agency and epistemic justice,"White (published journal papers, conference proceedings, books)","Existing networks, relevant organizations and conferences",LatAm; participatory action research; decolonial; Global South,"LatAm (includes Central America, South America & Carribbean)",Academic,"LatAm (includes Central America, South America & Carribbean)","University of Federal Rural do Rio de Janeiro, Brazil",,"Article critiques conventional accounting research for reinforcing financial capitalism and neocolonialism in the Global South. Argues prevailing quantitative methodologies obscure power relations and marginalize alternative knowledge. Proposes participatory action research (PAR) as a decolonial, non-extractive method. Positions PAR as tool for knowledge co-creation, resisting extractive logics, and empowering community agency in research",
"Simson et al., 2024","Simson, J., Fabris, A., & Kern, C. (2024). Lazy Data Practices Harm Fairness Research. The 2024 ACM Conference on Fairness, Accountability, and Transparency, 642–659. https://doi.org/10.1145/3630106.3658931",Lazy Data Practices Harm Fairness Research,Extractive,Biased pre-processing and category erasure,Data practices,ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,AD,A: critiques Fair-ML empirical norms; D: evidences exclusionary preprocessing and weak transparency; C: none (indirect implications),"White (published journal papers, conference proceedings, books)",Hand-searching key journals,fairness research; protected attribute; data usage,Not regionally specific,Mixed,EU/UK,Munich Center for Machine learning (MCML),"MCML (Munich center for machine learning) is a joint initiative of leading researchers of Ludwig-Maximilians-Universität München and Technische Universität München, Germany. MCML is established with permanent institutional funding from the Federal Ministry of Education and Research and the State of Bavaria.","Critiques common data practices in machine learning fairness research, arguing that they hinder the field’s reach and reliability. The authors identify three key concerns: limited representation of certain protected attributes, the exclusion of minorities during data preprocessing, and a lack of transparency in data processing decisions. They illustrate these concerns through case studies, demonstrating how the simplification of data and omission of specific demographic groups can skew algorithmic fairness evaluations. Consequently, the authors advocate for more inclusive data practices that prioritize transparency, the responsible inclusion of diverse populations, and meticulous documentation of data processing methods to ensure the generalizability and reproducibility of fairness research.",
"Singh et al., 2018","Singh, S., Granski, M., Victoria, M. D. P., & Javdani, S. (2018). The Praxis of Decoloniality in Researcher Training and Community‐Based Data Collection. American Journal of Community Psychology, 62(3–4), 385–395. https://doi.org/10.1002/ajcp.12294",The Praxis of Decoloniality in Researcher Training and Community‐Based Data Collection,Principles less-extractive,Community engaged data production,"Community impacts and relations, Critical theory/Historical background",ML System Design & Development,"Data Selection, Collection & Annotation",Multi-era,DC,A: none; D: develops decolonial training and community-based collection; C: advances critical compassion and resistance to structural oppression,"White (published journal papers, conference proceedings, books)",Database search,North America; decoloniality; community research; training; power,North America,Academic,North America,"New York University, USA",,"Argues that quantitative research methods, such as randomized controlled trials, must be used in a way that acknowledges and dismantles colonial power dynamics. The authors present a researcher training model used in their study of an advocacy program for legal system-involved girls, many of whom are girls of color. The training emphasizes conducting research as a site of resistance rather than justification for oppression by highlighting the historical context of systemic racism and challenging deficit-oriented narratives about marginalized communities. Further, the authors emphasize critical compassion, which requires researchers to recognize participants’ complex personhoods and engage in actions that address structural conditions of oppression.",
"Smart et al., 2024","Smart, A., et al. 2024. Socially Responsible Data for Large Multilingual Language Models. ACM conference on Equity and Access in Algorithms, Mechanisms, and Optimization, 2024. https://doi.org/10.48550/arXiv.2409.05247   ",Socially Responsible Data for Large Multilingual Language Models,Principles less-extractive,"Community engaged data production, Establishing consent and contextually appropriate compensation","Ethics frameworks, Community impacts and relations",ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,ADC,"A: targets multilingual LLM data practices; D: offers 12 recommendations for responsible, contextual collection; C: centers Global South languages and data sovereignty","Grey (Reports, blogs, white papers, policy documents, theses, conference papers)","Existing networks, relevant organizations and conferences",multiple areas; multilingual LLM; community engagement; data sovereignty,Multiple areas,Mixed,North America,"Google Research, USA",,"Articulates socially responsible data practices for multilingual LLMs beyond scale-seeking collection. Highlights colonial legacies and English dominance, urging community partnerships, culturally safe consent, accurate representation, and relational ethics (e.g., Ubuntu) to avoid algorithmic colonization and improve inclusion.",
"Smith, 2021","Smith, L. T. (2021). Decolonizing Methodologies: Research and Indigenous Peoples (Third Edition). Bloomsbury Publishing.",Decolonizing Methodologies: Research and Indigenous Peoples,Principles less-extractive,Decentering Western ontologies,"Critical theory/Historical background, Community impacts and relations",Cross-pipeline,Cross-pipeline,Multi-era,DC,A: none; D: critiques Western-centric research paradigms and proposes Indigenous approaches; C: centers empowerment and Indigenous epistemologies,"White (published journal papers, conference proceedings, books)","Existing networks, relevant organizations and conferences","Decolonizing research, Indigenous knowledge",Multiple areas,Academic,Oceania,"Te Whare Wānanga o Awanuiārangi, New Zealand (previously University of Waikato)",,"Seminal work that critiques Western research practices from an indigenous perspective. She argues that “research” is a loaded term for indigenous peoples, often carrying the baggage of colonialism and exploitation. Smith challenges the objectivity of Western knowledge systems, highlighting how they are embedded in cultural, social, and historical contexts. She advocates for “decolonizing methodologies” by recognizing the validity of indigenous knowledge systems and promoting research approaches that empower indigenous communities.",
"Solatorio et al., 2024","Solatorio, A. V., Vicente, G. S., Krambeck, H., & Dupriez, O. (2024). Double Jeopardy and Climate Impact in the Use of Large Language Models: Socio-economic Disparities and Reduced Utility for Non-English Speakers (No. arXiv:2410.10665). arXiv. https://doi.org/10.48550/arXiv.2410.10665",Double Jeopardy and Climate Impact in the Use of Large Language Models: Socio-economic Disparities and Reduced Utility for Non-English Speakers,Extractive,"""Deploying AI systems that lack local, contextual data""","Ethics frameworks, Community impacts and relations",Deployment & Impact,Product Launch,Era 3,ADC,A: assesses tokenization and cost disparities in LLMs; D: documents multilingual design gaps; C: emphasizes harms to low-resource language communities,"Grey (Reports, blogs, white papers, policy documents, theses, conference papers)",Citation/reference snowballing,LLM; language; inequality,Multiple areas,NGO/Non-profit,North America,The World Bank,,"Shows tokenization and pricing structures inflate costs for low-resource language users while performance lags, affecting 1.5B speakers. Links fragmented tokenization to environmental impact. Argues for fairer multilingual design, tying deployment decisions to inequitable access and climate externalities.",
"Speech Accessibility Project, n.d.","Speech Accessibility Project. (n.d.). Speech Accessibility Project. Retrieved September 1, 2025, from https://speechaccessibilityproject.beckman.illinois.edu",Speech Accessibility Project,Practices less-extractive,"Creating culturally inclusive datasets, Community engaged data production, Crowdsourcing data collection, Participatory data ownership & governance","Community impacts and relations, Data practices",ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,ADC,"A: sets shared accessibility goal across firms; D: pays volunteers and curates a private, de-identified dataset under UIUC governance; C: collaborates with disability organizations to recruit and review consent processes","Grey (Reports, blogs, white papers, policy documents, theses, conference papers)","Existing networks, relevant organizations and conferences",North America; speech recognition; dataset; disability community; accessibility,North America,Mixed,North America,"University of Illinois Urbana-Champaign, USA","Tech companies and community organizations, USA","Collects paid speech samples from people with diverse speech patterns to build more inclusive ASR. UIUC manages collection, curation, privacy, and equitable research access; companies support rather than own the dataset. Work with disability groups shapes recruitment and consent. Positions community-informed data production to improve accessibility impacts for millions",
"Spivak, 2015","Spivak, G. C. (2015). Can the Subaltern Speak? (1994). In Patrick Williams & Laura Chrisman (Eds.), Colonial Discourse and Post-Colonial Theory (pp. 66–111). Routledge.",Can the Subaltern Speak?,Principles less-extractive,Other/NA (conceptual framing),Community impacts and relations,Cross-pipeline,Cross-pipeline,Multi-era,C,A: none; D: critiques Western intellectual representation as epistemic violence; C: centers the silencing of subaltern voices in colonial/postcolonial contexts.,"White (published journal papers, conference proceedings, books)","Existing networks, relevant organizations and conferences","epistemic violence, subaltern, imperialist projects, colonial practices",Not regionally specific,Academic,APAC (Asia-Pacific Region),"Columbia University, USA",,"Seminal work that critically examines the representation of marginalized groups, particularly women in the context of colonialism and postcolonialism. She argues that dominant Western intellectual discourse, exemplified by Foucault and Deleuze, perpetuates a ""transparency"" of the intellectual, inadvertently reinscribing the Subject of the West while claiming to speak for the Other. The essay probes the epistemic violence of colonial practices, such as the codification of Hindu Law, and the subsequent silencing of the subaltern voice. Spivak uses Marx's writings on class and representation as a counterpoint, showing how the subject is inherently fragmented and cannot be fully represented. She criticizes the Subaltern Studies group for their essentialist approach to understanding the subaltern, emphasizing the need for a more nuanced and attentive understanding of difference and the limitations of representation. Spivak challenges the very notion of the ""subaltern speaking"" by highlighting the limitations of Western intellectual frameworks and proposing a more self-conscious and critical approach to studying marginalized groups.",
"Spyrou, 2024","Spyrou, S. (2024). From extractivist practices and the child-as-data to an ethics of reciprocity and mutuality in empirical childhood research. Childhood, 31(1), 3–12. https://doi.org/10.1177/09075682231220158",From extractivist practices and the child-as-data to an ethics of reciprocity and mutuality in empirical childhood research,Extractive,"Soliciting data without reciprocal benefits, Western-centric research infrastructure",Critical theory/Historical background,ML System Design & Development,"Data Selection, Collection & Annotation",Multi-era,DC,"A: none (childhood research more broadly, not AI); D: critiques extractive empirical practices; C: advances reciprocity and mutuality","White (published journal papers, conference proceedings, books)",Database search,global; fairness; ML; critique; interdisciplinarity,Not regionally specific,Academic,EU/UK,"European University Cyprus, Cyprus",,"Argues that contemporary research, amplified by audit cultures, often treats the child-as-data, reproducing epistemic extractivism. Critiques “fast” data collection and coding that strips knowledge from context and accountability. Proposes non-extractivist, relation-centered methods grounded in reciprocity and mutuality, drawing on Indigenous and transformative research ethics (“knowing-with,” not “knowing-about”). Urges slow, co-produced scholarship that prioritizes respect, care, and community benefit—even if that means not recording or publishing some material. Links these commitments to datafication and AI-adjacent practices with minors: emphasize consent as ongoing, power-aware, and collective; prevent harm; and ensure tangible returns to children and their communities",
"Stenseth, 2023","Stenseth, A.-M. (2023). “I am Sámi, but I am not a Sámi”: Coastal Sámi students’ articulations of identity in a colonial-blind Norwegian state. Nordic Journal of Comparative and International Education (NJCIE), 7(1). https://doi.org/10.7577/njcie.5036"," “I am Sámi, but I am not a Sámi”: Coastal Sámi students’ articulations of identity in a colonial-blind Norwegian state",Principles less-extractive,Other/NA (conceptual framing),"Community impacts and relations, Critical theory/Historical background",Deployment & Impact,Product Testing,Multi-era,C,A: none; D: none; C: centers Sámi students’ perspectives on identity exclusion in Norway’s education system.,"White (published journal papers, conference proceedings, books)","Existing networks, relevant organizations and conferences","Norway, Sámi, education system, identity",EU/UK,Academic,EU/UK,UiT the Arctic University of Norway,,"Draws on interviews with coastal Sámi students to analyze identity negotiations within Norway’s education system. Shows how narrow state narratives of Sámi culture, tied to reindeer herding, exclude coastal identities. Argues colonial-blind schooling perpetuates cultural misrecognition and forces conformity to limited identity categories.",
"Strengers et al., 2021","Strengers, Y., Sadowski, J., Li, Z., Shimshak, A., & “Floyd” Mueller, F. (2021). What Can HCI Learn from Sexual Consent?: A Feminist Process of Embodied Consent for Interactions with Emerging Technologies. Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems, 1–13. https://doi.org/10.1145/3411764.3445107",What Can HCI Learn from Sexual Consent?: A Feminist Process of Embodied Consent for Interactions with Emerging Technologies,Principles less-extractive,Establishing consent and contextually appropriate compensation,Ethics frameworks,Problem Understanding & Formulation,Product Conception & Design,Multi-era,ADC,"A: reframes interaction design through ongoing, embodied consent; D: proposes TEASE model for practice; C: centers user autonomy and negotiated boundaries","White (published journal papers, conference proceedings, books)",Database search,consent; interaction; embodiment,Not regionally specific,Academic,Oceania,"Monash University, Melbourne, Australia",,"Proposes a consent-centric approach to HCI. Drawing from FRIES and BDSM practices, the authors introduce TEASE to operationalize consent as ongoing, reversible, informed, and embodied across interactions. They illustrate implications for bodily play, persuasive tech, and intimate devices. Links: shifts problem framing and design norms so data/interaction consent is negotiated and revisitable, with clearer protections for impacted communities.",
"Sunbird AI, n.d.","Sunbird AI. (n.d.). About – Sunbird AI. Retrieved September 7, 2025, from https://sunbird.ai/about/",Sunbird AI,Practices less-extractive,"Creating culturally inclusive datasets, Community engaged data production","Data practices, Community impacts and relations",ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,ADC,A: aligns AI work to partner-defined needs; D: develops open systems and resources; C: advances African technical capacity and ethical practice,"Grey (Reports, blogs, white papers, policy documents, theses, conference papers)","Existing networks, relevant organizations and conferences",Africa; applied AI; open source; capacity,Africa,NGO/Non-profit,Africa,"Sunbird, Uganda",,"A Uganda-based nonprofit developing AI systems in response to partner-defined needs. Methods include open system design, public release of tools and datasets, and collaborative project scoping with local organizations. The group emphasizes ethical practice, capacity development, and transparency to ensure reuse and long-term benefit. Findings from its projects show that grounding technology development in local problems produces practical and trusted outcomes. By treating AI data production as an ecosystem activity tied to governance and capacity building, Sunbird AI demonstrates how non-extractive approaches strengthen both technical systems and community impacts.",
"Suresh & Guttag, 2021","Suresh, H., & Guttag, J. V. (2021). A Framework for Understanding Sources of Harm throughout the Machine Learning Life Cycle. Equity and Access in Algorithms, Mechanisms, and Optimization, 1–9. https://doi.org/10.1145/3465416.3483305",A Framework for Understanding Sources of Harm throughout the Machine Learning Life Cycle,Extractive,Biased pre-processing and category erasure,Data practices,Cross-pipeline,Cross-pipeline,Multi-era,AD,A: formalizes harms in ML lifecycle; D: identifies seven distinct data/process biases; C: none (indirect implications),"White (published journal papers, conference proceedings, books)",Database search,"ML lifecycle, bias, harm sources, evaluation",Not regionally specific,Academic,North America,"MIT, USA",,"Proposes a framework identifying seven sources of harm in ML pipelines, from historical to deployment bias. Moves beyond “biased data” as a blanket explanation, showing how each stage introduces distinct risks. Provides formalization of ML as a series of transformations, illustrating how harm compounds across processes. Suggests targeted mitigation strategies, contributing to a more nuanced fairness discourse.",
"Suresh et al., 2022","Suresh, H., Movva, R., Dogan, A. L., Bhargava, R., Cruxen, I., Cuba, A. M., Taurino, G., So, W., & D’Ignazio, C. (2022). Towards Intersectional Feminist and Participatory ML: A Case Study in Supporting Feminicide Counterdata Collection. 2022 ACM Conference on Fairness, Accountability, and Transparency, 667–678. https://doi.org/10.1145/3531146.3533132",Towards Intersectional Feminist and Participatory ML: A Case Study in Supporting Feminicide Counterdata Collection,Practices less-extractive,Early co-design and participatory initiatives,Data practices,ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,ADC,A: explores participatory ML for justice applications; D: details iterative counterdata collection; C: engages organizations confronting feminicide and structural inequality,"White (published journal papers, conference proceedings, books)",Hand-searching key journals,LatAm; participatory ML; feminicide; counterdata,"LatAm (includes Central America, South America & Carribbean)",Academic,North America,"Massachusetts Institute of Technology, USA",,"Case study of participatory ML guided by intersectional feminism. Collaboration with feminicide monitoring groups critiques narrow bias-mitigation ethics. Designs iterative data collection addressing structural inequalities. Framework centers marginalized experiences, embedding participatory co-design in dataset development. Demonstrates feminist principles as means to confront systemic inequities and support counterdata practices for justice.",
"Suresh et al., 2024","Suresh, H., Tseng, E., Young, M., Gray, M., Pierson, E., & Levy, K. (2024). Participation in the age of foundation models. The 2024 ACM Conference on Fairness, Accountability, and Transparency, 1609–1621. https://doi.org/10.1145/3630106.3658992",Participation in the age of foundation models,Principles less-extractive,Early co-design and participatory initiatives,Community impacts and relations,Cross-pipeline,Cross-pipeline,Era 3,ADC,A: examines participatory constraints in foundation models; D: conceptualizes layered governance for data/model pipelines; C: considers communities’ limited influence and possible interventions.,"Grey (Reports, blogs, white papers, policy documents, theses, conference papers)",Hand-searching key journals,global; foundation model; governance; participation,Not regionally specific,Mixed,North America,"Cornell Tech, USA","Microsoft Research, Data & Society Research Institute, USA; Cornell University, USA","Reviews participation in foundation model development, identifying “participatory ceiling.” Case studies in healthcare, journalism, and finance show barriers due to scale and general-purpose scope. Proposes three-tier blueprint: foundation (base models), subfloor (domain governance), surface (applications). Framework illustrates how communities may shape governance and mitigate risks, embedding equity despite scale.",
"Tacheva & Ramasubramanian, 2023","Tacheva, Z., & Ramasubramanian, S. (2023). Challenging AI Empire: Toward a Decolonial and Queer Framework of Data Resurgence. Advance. https://advance.sagepub.com/doi/full/10.31124/advance.22012724.v1",Challenging AI Empire: Toward a Decolonial and Queer Framework of Data Resurgence,Principles less-extractive,"Participatory data ownership & governance, Decentering Western ontologies","Community impacts and relations, Data practices",Cross-pipeline,Cross-pipeline,Era 3,ADC,A: discusses implications of scale-first AI for minority languages; D: contrasts corporate vs. community data production models; C: centers Māori sovereignty and benefit alignment in language data.,"Grey (Reports, blogs, white papers, policy documents, theses, conference papers)",Database search,data colonialism; governance; queer/Indigenous praxis,Not regionally specific,Academic,North America,"Syracuse University, USA",,"Introduces the concept of “AI Empire,” which is driven by hegemony, extractivism, surveillance, and subjugation, manifesting in issues like data colonialism, data commodification, biometric profiling, and technological apartheid. They contend that reforming AI within this existing framework offers only superficial solutions. Instead, the authors propose a “Data Resurgence Framework,” drawing upon Indigenous, decolonial, and queer perspectives. Grounded in the principles of anti-coloniality, relationality, sovereignty, and liberatory praxis.",
"Taylor, 2017","Taylor, L. (2017). What is data justice? The case for connecting digital rights and freedoms globally. Big Data & Society, 4(2), 205395171773633. https://doi.org/10.1177/2053951717736335",What is data justice? The case for connecting digital rights and freedoms globally,Principles less-extractive,Participatory data ownership & governance,"Ethics frameworks, Community impacts and relations",Cross-pipeline,Cross-pipeline,Era 2,DC,"A: none (conceptual, not AI-specific); D: proposes data justice pillars for governance; C: connects rights, representation, and agency","White (published journal papers, conference proceedings, books)",Database search,"Data justice, digital rights, data privacy, data governance, social justice",Not regionally specific,Academic,EU/UK,"Tilburg Institute for Law, Techonology, and Society, Netherlands",,"Outlines concept of ""data justice"" as a crucial framework for addressing the ethical and societal implications of the ever-growing influence of digital data. The author, Linnet Taylor, contends that current frameworks, primarily focused on individual rights and data protection, are insufficient in the face of the increasingly complex and globalized landscape of data collection and analysis. The paper outlines the interconnected problems of data-driven discrimination, the rise of ""dataveillance,"" and the blurring of lines between public and private sector use of data. It proposes a three-pillar framework for data justice: visibility (including representation and privacy), digital (dis)engagement (encompassing the freedom to opt out of data collection and the power to control data-generating technologies), and countering data-driven discrimination. Taylor argues for a broader conceptualization of justice that extends beyond individual rights and incorporates the capabilities approach, which emphasizes both opportunity freedoms (access to valuable resources and opportunities) and process freedoms (agency and the ability to participate in decisions affecting one's data)",
"Te Hiku Media, n.d.","Te Hiku Media. (n.d.). Kaitiakitanga-License/papareo_api.md at tumu · TeHikuMedia/Kaitiakitanga-License [Dataset]. Retrieved September 1, 2025, from https://github.com/TeHikuMedia/Kaitiakitanga-License/blob/tumu/papareo_api.md 
",TeHikuMedia/Kaitiakitanga-License,Practices less-extractive,Developing equitable data licensing models,"Data practices, Community impacts and relations",ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,ADC,A: frames data/model/tool stewardship via kaitiakitanga; D: sets license terms aligned with Māori tikanga; C: protects mana and prioritizes Indigenous benefit,"Grey (Reports, blogs, white papers, policy documents, theses, conference papers)",Citation/reference snowballing,Oceania; licensing; NLP tools; tikanga; Indigenous stewardship,Oceania,NGO/Non-profit,Oceania,"Te Reo Irirangi o Te Hiku o Te Ika (Te Hiku Media), Aotearoa New Zealand",https://www.temanararaunga.maori.nz/,"Establishes a living license grounded in Māori concepts of guardianship to govern access to data, derived models, and tools (e.g., Papa Reo API). Conditions access on alignment with tikanga to prevent digital colonization and support Indigenous innovation and control.",
"Teixeira da Silva, 2022","Teixeira da Silva, J. A. (2022). Handling Ethics Dumping and Neo-Colonial Research: From the Laboratory to the Academic Literature. Journal of Bioethical Inquiry, 19(3), 433–443. https://doi.org/10.1007/s11673-022-10191-x",Handling Ethics Dumping and Neo-Colonial Research: From the Laboratory to the Academic Literature,Extractive,Ethics dumping in less-regulated contexts,"Critical theory/Historical background, Community impacts and relations",ML System Design & Development,"Data Selection, Collection & Annotation",Multi-era,DC,A: none; D: examines research exploitation across genomics and biobanking; C: focuses on protecting Indigenous populations from research exploitation,"White (published journal papers, conference proceedings, books)","Existing networks, relevant organizations and conferences","ethics dumping, Indigenous rights, research exploitation",Not regionally specific,Journalist/Other/Not Sure,APAC (Asia-Pacific Region),"Independent researcher, Japan",,"Investigates ethics dumping where researchers from higher-income countries exploit vulnerabilities in lower-income contexts to conduct unethical research. Provides examples across biobanking, genomics, and GMO research highlighting power imbalances. Proposes stricter journal verification requiring proof of informed consent, human rights compliance, and transparent documentation of Indigenous rights protections.",
"Thatcher et al., 2016","Thatcher, J., O’Sullivan, D., & Mahmoudi, D. (2016). Data colonialism through accumulation by dispossession: New metaphors for daily data. Environment and Planning D: Society and Space, 34(6), 990–1006. https://doi.org/10.1177/0263775816633195",Data colonialism through accumulation by dispossession: New metaphors for daily data,Extractive,Collecting vast amounts of data to train AI systems,Critical theory/Historical background,ML System Design & Development,"Data Selection, Collection & Annotation",Multi-era,DC,"A: none (indirect implications); D: conceptualizes everyday data capture and licensing as “accumulation by dispossession”; C: argues dispossession commodifies subjects and concentrates control, producing social harms and governance concerns","White (published journal papers, conference proceedings, books)",Iterative keyword search,USA/Global South; data colonialism; accumulation by dispossession,Not regionally specific,Academic,North America,"University of Washington, Tacoma, USA","University of California, Berkeley, USA; Portland State University, USA
","Develops “data colonialism” as a metaphor for how everyday technologies extract value by dispossessing individuals of their data through opaque terms and infrastructures. Links routine capture to prediction and control in digital markets. The framework clarifies how large-scale dataset creation and reuse enable commodification and governance over subjects, informing critiques of AI systems dependent on such corpora.",
"The Tierra Común Network, 2023",The Tierra Común Network. (2023). Resisting Data Colonialism: A Practical Intervention (INC Theory on Demand #50). Institute of Network Cultures. https://networkcultures.org/wp-content/uploads/2023/12/ResistingDataColonialism_INC2023_TOD50.pdf,Resisting Data Colonialism: A Practical Intervention,Extractive,Collecting vast amounts of data to train AI systems,"Critical theory/Historical background, Community impacts and relations",Problem Understanding & Formulation,Institutional Prioritization & Funding,Era 3,DC,A: none; D: theorizes and documents data colonialism and extraction infrastructures; C: catalogs grassroots resistance and community strategies in Latin America and beyond,"Grey (Reports, blogs, white papers, policy documents, theses, conference papers)",Citation/reference snowballing,LatAm; data colonialism; matrix of power; resistance,"LatAm (includes Central America, South America & Carribbean)",Mixed,"LatAm (includes Central America, South America & Carribbean)","London School of Economics, UK; Tierra Comun Network, global coalition LatAm focused","Tierra Común brings together activists, citizens and scholars who want data to be decolonized. Our specific focus is Latin America, but our horizon is the Global South, and everyone anywhere who rejects data colonialism as the latest manifestation in modernity of the Global North’s desire for domination.","Defines data colonialism as pervasive extraction by firms and states, mapping a “matrix of power” that reproduces inequalities of race, gender, and class. Compiles practical pathways of resistance—organizing, consent infrastructures, legal strategies—grounded in Latin American experiences with relevance to the Global South. Links extractive data practices to lived harms and proposes community-centered countermeasures to reassert control over data lifeworlds.",
"Theodorou et al., 2021","Theodorou, L., Massiceti, D., Zintgraf, L., Stumpf, S., Morrison, C., Cutrell, E., Harris, M. T., & Hofmann, K. (2021). Disability-first Dataset Creation: Lessons from Constructing a Dataset for Teachable Object Recognition with Blind and Low Vision Data Collectors. Proceedings of the 23rd International ACM SIGACCESS Conference on Computers and Accessibility, 1–12. https://doi.org/10.1145/3441852.3471225",Disability-first Dataset Creation: Lessons from Constructing a Dataset for Teachable Object Recognition with Blind and Low Vision Data Collectors,Practices less-extractive,Creating culturally inclusive datasets,"Data practices, Community impacts and relations",ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,ADC,"A: applies teachable object recognition for assistive AI; D: develops a video-based, community-oriented data collection procedure; C: centers blind/low-vision collectors’ needs and agency","White (published journal papers, conference proceedings, books)",Database search,"teachable object recognition, disability-first dataset, blind and low vision",Not regionally specific,Mixed,EU/UK,"Centre for HCI Design City, University of London, United Kingdom","Microsoft Research, United Kingdom; University of Oxford, United Kingdom; Centre for HCI Design City, University of London, United Kingdom; Microsoft Research, USA","Multidisciplinary team co-developed a dataset for teachable object recognition with blind/low-vision participants as data collectors. Method emphasizes video capture over still images to increase example quality and reduce burden. Iterative phases refined guidance, validation, and risk mitigation. Findings show disability-first procedures improve relevance, control, and downstream model utility for assistive AI. Paper contributes a practical protocol and reflexive questions for inclusive dataset creation.",
"Timcke, 2024","Timcke, Scott. (2024, July 11). AI and the digital scramble for Africa. Review of African Political Economy. https://roape.net/2024/07/11/ai-and-the-digital-scramble-for-africa/ 
","AI and the digital scramble for Africa
",Extractive,Ethics dumping in less-regulated contexts,"Community impacts and relations, Critical theory/Historical background",Deployment & Impact,Product Launch,Era 3,ADC,"A: analyzes implications of AI for African governance and democracy; D: critiques extractive practices in data, labor, and resources; C: centers African institutions, civil society, and worker protections","Grey (Reports, blogs, white papers, policy documents, theses, conference papers)",Iterative keyword search,"Africa, AI, digital colonialism, data governance",Africa,Mixed,Africa,ROAPE team (group of scholars and activists in the UK and Africa),,"Examines how AI development in Africa intersects with histories of colonial exploitation and contemporary neoliberal policies. Discusses mineral extraction, data monopolization, and precarious digital labor as forms of a “digital scramble.” Highlights African universities, think tanks, and the African Union as actors shaping democratic responses. Calls for stronger labor protections, regional cooperation, and governance frameworks to resist digital colonialism and ensure communities retain benefits from AI and data infrastructures",
"Timko et al., 2023","Timko, C., Niederstadt, M., Goel, N., & Faltings, B. (2023). Incentive Mechanism Design for Responsible Data Governance: A Large-scale Field Experiment. J. Data and Information Quality, 15(2), 16:1-16:18. https://doi.org/10.1145/3592617",Incentive Mechanism Design for Responsible Data Governance: A Large-scale Field Experiment,Practices less-extractive,Establishing consent and contextually appropriate compensation,Data practices,ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,AD,A: builds trustworthy AI applications from fitness data; D: tests incentive-compatible mechanisms for quality data collection; C: none (indirect implications),"White (published journal papers, conference proceedings, books)",Citation/reference snowballing,"fitness data, incentive mechanisms, data quality",Not regionally specific,Academic,EU/UK,"Ruhr-Universität Bochum, Germany","University of Oxford, Oxford, UK; EPFL, Lausanne, Switzerland","Tests incentive schemes for contributed fitness data (N=691), finding peer-based, incentive-compatible mechanisms elicit high-quality data with good user experience. Provides actionable guidance for data-collection governance relevant to AI datasets dependent on volunteered personal signals.",
"Tonja et al., 2024","Tonja, A. L., Dossou, B. F. P., Ojo, J., Rajab, J., Thior, F., Wairagala, E. P., Aremu, A., Moiloa, P., Abbott, J., Marivate, V., & Rosman, B. (2024). InkubaLM: A small language model for low-resource African languages (No. arXiv:2408.17024). arXiv. https://doi.org/10.48550/arXiv.2408.17024 
",InkubaLM: A small language model for low-resource African languages,Practices less-extractive,Creating culturally inclusive datasets,"Data practices, Community impacts and relations",ML System Design & Development,Model Training & Evaluation,Era 3,ADC,"A: presents a new LM + evaluations; D: dataset curation/training pipeline for low-resource langs; C: positions benefits for African language communities (access, openness)","Grey (Reports, blogs, white papers, policy documents, theses, conference papers)","Existing networks, relevant organizations and conferences","Africa, low resource languages, small models, model evaluation",Africa,Mixed,Multiple areas,"Lelapa AI, South AFrica; MBZUAI, UAE; McGill University & Mila Quebec AI Institute, Canada","DSFSI - University of Pretoria; RAIL Lab - University of the Witwatersrand, South Africa","Presents InkubaLM (≈0.4B parameters) targeting under-resourced African languages. Reports competitive performance on machine translation, sentiment, and QA with transparent data curation and training pipeline. Argues smaller, open models plus locally relevant corpora can expand access, reduce compute barriers, and better serve African language communities than monolithic, externally trained systems.",
"Truong et al., 2024","Truong, S., Nguyen, D., Nguyen, T., Le, D., Truong, N., Quan, T., & Koyejo, S. (2024). Crossing Linguistic Horizons: Finetuning and Comprehensive Evaluation of Vietnamese Large Language Models. In K. Duh, H. Gomez, & S. Bethard (Eds.), Findings of the Association for Computational Linguistics: NAACL 2024 (pp. 2849–2900). Association for Computational Linguistics. https://doi.org/10.18653/v1/2024.findings-naacl.182",Crossing Linguistic Horizons: Finetuning and Comprehensive Evaluation of Vietnamese Large Language Models,Practices less-extractive,Creating culturally inclusive datasets,Data practices,ML System Design & Development,Model Training & Evaluation,Era 3,ADC,A: fine-tunes and evaluates LLMs for Vietnamese; D: builds benchmark datasets and metrics; C: addresses exclusion of Vietnamese speakers in multilingual AI,"White (published journal papers, conference proceedings, books)",Citation/reference snowballing,"Vietnam, large language models, finetuning, benchmarks, inclusion",APAC (Asia-Pacific Region),Academic,APAC (Asia-Pacific Region),"Stanford University, USA; Ho Chi Minh City University of Technology, VNU-HCM, Vietnam",first four authors equal contribution,"Presents Vietnamese-specific finetuning and a 10-task, 31-metric evaluation suite. Shows cross-lingual transfer benefits but also bias/uncalibrated outputs in larger models. Emphasizes dataset quality as the primary driver of performance, motivating targeted finetuning and rigorous benchmarks to improve access and reliability for Vietnamese speakers.",
"Tsing, 2012","Tsing, A. L. (2012). On nonscalability: The living world is not amenable to precision-nested scales. Common knowledge, 18(3), 505-524. https://doi.org/10.1215/0961754X-1630424","On Nonscalability: The Living World Is Not Amenable to Precision-Nested
Scales",Extractive,Collecting vast amounts of data to train AI systems,Critical theory/Historical background,Problem Understanding & Formulation,Product Conception & Design,Multi-era,DC,A: none; D: critiques scalability projects that render worlds static for expansion; C: traces social–ecological ruins left by scalability logics,"White (published journal papers, conference proceedings, books)",Citation/reference snowballing,scalability; model; colonial construct; nonscalability,Not regionally specific,Academic,North America,"University of California, Santa Cruz, USA",,"Develops “nonscalability theory,” arguing scalable projects require coercive simplifications that erase context and difference. Historicizes plantation logics as templates for later scalability regimes. Offers a lens to interrogate data accumulation and modeling practices that privilege expansion over situatedness, highlighting the social and ecological debris scalability leaves behind.",
"Tubaro et al., 2025","Tubaro, P., Casilli, A. A., Cornet, M., Ludec, C. L., & Cierpe, J. T. (2025). Where does AI come from? A global case study across Europe, Africa, and Latin America. https://doi.org/10.1080/13563467.2025.2462137","Where does AI come from? A global case study across Europe, Africa, and Latin America",Extractive,Keeping communities in the dark through opaque data practices,"Data labor, Community impacts and relations",ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,ADC,A: maps global data-work supply chains; D: reveals platformized procurement and firm-like arrangements; C: documents precarity and North–South inequalities,"White (published journal papers, conference proceedings, books)",Citation/reference snowballing,AI supply chain; data work; platform economy,Not regionally specific,Academic,EU/UK,"Institut Polytechnique de Paris, France","National Centre for Scientific Research (CNRS) and National School of Economics and Statistics (ENSAE), France; Telecom Paris, the telecommunication school of the Polytechnic Institute of Paris, and the Interdisciplinary Institute on Innovation (i3), France;. Telecom Paris, France; CERSA, Université Paris-Panthéon-Assas, France; LaborIA, Inria, France","Traces AI’s human supply chains across France, Madagascar, and Venezuela. Shows how platform marketplaces and intermediaries source annotation and moderation under precarious conditions. Illuminates opacity around sourcing and accountability, linking data-work organization to persistent inequality in AI production.",
"Tuck & Yang, 2012","Tuck, E., & Yang, K. W. (2012). Decolonization is not a metaphor. Decolonization: Indigeneity, Education & Society, 1(1), Article 1. https://jps.library.utoronto.ca/index.php/des/article/view/18630",Decolonization is not a metaphor,Principles less-extractive,Other/NA (conceptual framing),Critical theory/Historical background,Problem Understanding & Formulation,Product Conception & Design,Multi-era,C,A: none; D: critiques metaphorical uses of “decolonization” that obscure land and resource return; C: centers Indigenous sovereignty and futurity as irreducible commitments.,"White (published journal papers, conference proceedings, books)",Database search,settler colonialism; decolonization; indigenous sovereignty,Not regionally specific,Academic,North America,"State University of New York, USA",,"Argues that decolonization, the repatriation of Indigenous land and life, is frequently misused as a metaphor for other social justice projects. The authors contend that settler colonialism, with its unique structure of settler-native-slave relations, requires a distinct approach to decolonization that moves beyond metaphorical interpretations. They illustrate how the metaphorization of decolonization enables “settler moves to innocence,” strategies employed by settlers to alleviate guilt without relinquishing land or power. These moves, including settler nativism and adoption fantasies, perpetuate the erasure of Indigenous peoples and the perpetuation of settler colonialism. Tuck and Yang urge a shift from reconciliation to an “ethic of incommensurability,” acknowledging the irreconcilable differences between settler colonialism and other struggles, and emphasizing the need for decolonization to center Indigenous sovereignty and futurity.",
"Üstün et al., 2024","Üstün, A., Aryabumi, V., Yong, Z., Ko, W.-Y., D’souza, D., Onilude, G., Bhandari, N., Singh, S., Ooi, H.-L., Kayid, A., Vargus, F., Blunsom, P., Longpre, S., Muennighoff, N., Fadaee, M., Kreutzer, J., & Hooker, S. (2024). Aya Model: An Instruction Finetuned Open-Access Multilingual Language Model. In L.-W. Ku, A. Martins, & V. Srikumar (Eds.), Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) (pp. 15894–15939). Association for Computational Linguistics. https://doi.org/10.18653/v1/2024.acl-long.845 
",Aya Model: An Instruction Finetuned Open-Access Multilingual Language Model,Practices less-extractive,Creating culturally inclusive datasets,"Data practices, Community impacts and relations",ML System Design & Development,Model Training & Evaluation,Era 3,ADC,A: presents open multilingual instruction-tuned LLM; D: compiles diverse multilingual instruction data; C: broadens access for low-resource languages,"White (published journal papers, conference proceedings, books)",Database search,global; multilingual LLM; instruction tuning; openness,Multiple areas,Mixed,Multiple areas,"Cohere For AI, Canada","Cohere For AI; Brown University; Cohere; Cohere For AI Community; Carnegie Mellon University; MIT, USA","Develops Aya, a massively multilingual instruction-tuned LLM covering 101 languages (over half low-resourced). Methods include new evaluation suites across 99 languages, human assessments, and simulated win rates, plus analyses of finetuning-mix composition and data pruning. Findings show competitive gains over mT0/BLOOMZ with broader language coverage and measured bias/toxicity/safety. Links improved data/eval design to more inclusive AI performance and community impact across under-represented languages.",
"Vaani, n.d.","Vaani. (n.d.). Retrieved September 7, 2025, from https://vaani.iisc.ac.in/",Vaani,Practices less-extractive,"Community engaged data production, Creating culturally inclusive datasets","Community impacts and relations, Data practices",ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,ADC,"A: develops speech datasets for Indian languages; D: collects 150,000 hours of diverse speech data; C: supports inclusion and representation across India’s linguistic communities","Grey (Reports, blogs, white papers, policy documents, theses, conference papers)",Citation/reference snowballing,"India, speech datasets, linguistic diversity, digital inclusion",APAC (Asia-Pacific Region),NGO/Non-profit,APAC (Asia-Pacific Region),"IISc Bangalore; ARTPARK, India",,"Collects 150,000+ hours of natural speech from 1 million speakers across all Indian districts. Curates datasets with linguistic, urban-rural, gender, and age diversity. Open-sourced via Bhashini to support inclusive Digital India. Positions large-scale community-engaged collection as key to equitable speech AI.",
"Varoquaux et al., 2025","Varoquaux, G., Luccioni, A. S., & Whittaker, M. (2025). Hype, Sustainability, and the Price of the Bigger-is-Better Paradigm in AI (No. arXiv:2409.14160). arXiv. https://arxiv.org/abs/2409.14160v1","Hype, Sustainability, and the Price of the Bigger-is-Better Paradigm in AI ",Extractive,"Prioritizing data wants over community needs, Collecting vast amounts of data to train AI systems",Data practices,ML System Design & Development,Model Training & Evaluation,Era 3,AD,"A: critiques scaling assumptions driving data-hungry AI; D: analyzes compute, cost, and sustainability limits; C: none","White (published journal papers, conference proceedings, books)",Database search,scaling; sustainability; environment,Not regionally specific,Mixed,EU/UK,"Inria, Saclay, France","Equal-contribution note across Inria, Hugging Face, Signal, and U. Western Australia","Critically assesses the large-scale paradigm in AI. Shows compute and cost grow faster than performance, concentrating power and sidelining socially valuable problems. Links scaling incentives to resource-intensive data production and environmental burden, challenging assumptions that bigger datasets and models inherently yield better outcomes.",
"Vincent et al., 2021","Vincent, N., Li, H., Tilly, N., Chancellor, S., & Hecht, B. (2021). Data Leverage: A Framework for Empowering the Public in its Relationship with Technology Companies. Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency, 215–227. https://doi.org/10.1145/3442188.3445885",Data Leverage: A Framework for Empowering the Public in its Relationship with Technology Companies,Principles less-extractive,Participatory data ownership & governance,Ethics frameworks,Problem Understanding & Formulation,Product Conception & Design,Era 3,AD,"A: theorizes leverage over data-dependent AI systems; D: specifies levers (strikes, poisoning, contribution); C: none","White (published journal papers, conference proceedings, books)",Database search,user data; leverage; governance,Not regionally specific,Academic,North America,"Northwestern University, USA",,"Introduces the concept of “data leverage” to empower users in their relationship with powerful technology companies. Data leverage refers to the influence individuals have over tech companies due to these companies’ dependence on user-generated data. The authors identify three main “data levers” individuals can utilize: data strikes, which involve withholding or deleting data; data poisoning, which involves injecting inaccurate data to disrupt algorithms; and conscious data contribution, which involves providing data to competitors or alternative platforms. ",
"Wagner, 2017","Wagner, T. (2017, July 14). Fair Trade Data. Global Design Futures. https://medium.com/global-design-futures/fair-trade-data-db2bca6d08b9",Fair Trade Data. Global Design Futures,Principles less-extractive,Participatory data ownership & governance,Ethics frameworks,ML System Design & Development,"Data Selection, Collection & Annotation",Era 2,ADC,A: anticipates AI-relevant IoT data flows; D: proposes labeling/contracting for user-set terms; C: seeks transparency and user control,"Grey (Reports, blogs, white papers, policy documents, theses, conference papers)",Iterative keyword search,EU/UK; IoT data; labeling; user control,Not regionally specific,Industry,EU/UK,"Infarm, Germany",,"Explores the potential consequences of the burgeoning Internet of Things (IoT) on user privacy. Wagner argues that the increasing prevalence of internet-connected devices, while offering convenience, poses a significant threat to user privacy as companies collect vast amounts of personal data. He highlights several examples of data misuse and argues for greater transparency and user control over data collection practices. To combat these concerns, Wagner proposes “Fair Trade Data,” a hypothetical labeling system and service that empowers users to set their own data privacy preferences, compelling companies to comply with these terms for data usage. ",
"Walter et al., 2021","Walter, M., Kukutai, T., Carroll, S. R., & Rodriguez-Lonebear, D. (Eds.). (2021). Indigenous Data Sovereignty and Policy. Taylor & Francis. https://doi.org/10.4324/9780429273957",Indigenous Data Sovereignty and Policy,Principles less-extractive,Participatory data ownership & governance,"Critical theory/Historical background, Community impacts and relations",ML System Design & Development,"Data Selection, Collection & Annotation",Multi-era,DC,"A: none; D: conceptualizes IDS as framework for decolonizing data practices; C: emphasizes Indigenous-led control, methodologies, and cultural property","White (published journal papers, conference proceedings, books)",Database search,"global, Indigenous data sovereignty, decolonizing data practices",Oceania,Academic,Oceania,"University of Tasmania, Australia",,"Brings together global scholarship on Indigenous Data Sovereignty (IDS) as both movement and framework. Argues that data are not neutral and that statistics have historically reinforced colonial narratives. Proposes IDS as a means to decolonize data practices by embedding Indigenous governance, methodologies, and infrastructures. Highlights cultural property and community rights as central to data futures. Positions IDS as a pathway to self-determination through greater control over collection, interpretation, and use",
"Wanjawa et al., 2023","Wanjawa, B., Wanzare, L., Indede, F., McOnyango, O., Ombui, E., & Muchemi, L. (2023). Kencorpus: A Kenyan Language Corpus of Swahili, Dholuo and Luhya for Natural Language Processing Tasks. In C. Wartena (Ed.), Journal for Language Technology and Computational Linguistics, Vol. 36 No. 2 (pp. 1–27). German Society for Computational Lingustics and Language Technology. https://doi.org/10.21248/jlcl.36.2023.243 
","Kencorpus: A Kenyan Language Corpus of Swahili, Dholuo and Luhya for Natural Language Processing Tasks",Practices less-extractive,"Creating culturally inclusive datasets, Community engaged data production","Community impacts and relations, Data practices",ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,ADC,"A: addresses data scarcity for Kenyan languages in NLP; D: collects text and speech corpora with derived POS, QA, and MT sets; C: supports multilingual access and research","White (published journal papers, conference proceedings, books)",Database search,"Africa, Kenya; language corpus; text; speech",Africa,Academic,Africa,"Dept. of Computer Science, University of Nairobi, Kenya","Dept. of Computer Science, Maseno University, Kenya; Dept. of Kiswahili and Other African Languages, Maseno University, Kenya; Dept. of Computer Science, Africa Nazarene University, Kenya","A text and speech corpus covering Swahili, Dholuo, and Luhya. Researchers collected data from communities, schools, media, and publishers, producing 5.6 million words and 177 hours of audio, with derived POS, QA, and translation datasets. Baseline experiments demonstrate usability for ASR and question answering, while challenges included cleaning, resource limitations, and pandemic constraints. The project highlights the feasibility of creating public, locally led resources for under-served languages. Kencorpus links corpus development to AI data production by enabling downstream NLP applications and supporting multilingual access in Kenyan research and education.",
"Weidinger et al., 2022","Weidinger, L., Uesato, J., Rauh, M., Griffin, C., Huang, P.-S., Mellor, J., Glaese, A., Cheng, M., Balle, B., Kasirzadeh, A., Biles, C., Brown, S., Kenton, Z., Hawkins, W., Stepleton, T., Birhane, A., Hendricks, L. A., Rimell, L., Isaac, W., … Gabriel, I. (2022). Taxonomy of Risks posed by Language Models. 2022 ACM Conference on Fairness, Accountability, and Transparency, 214–229. https://doi.org/10.1145/3531146.3533088",Taxonomy of Risks posed by Language Models,Extractive,"""Deploying AI systems that lack local, contextual data""",Data practices,Deployment & Impact,Product Launch,Era 3,ADC,A: system-level taxonomy of risks; D: none; C: identifies societal harms and mitigation needs,"White (published journal papers, conference proceedings, books)",Hand-searching key journals,"global, risks, LLMs, causal mechanism",Not regionally specific,Mixed,EU/UK,"DeepMind, United Kingdom","Caltech, USA; University of Toronto, Canada; University College Dublin, Ireland","Develops a taxonomy of 21 risks associated with large language models, spanning discrimination, misinformation, malicious use, HCI harms, and environmental costs. Draws from computer science, linguistics, and social science. Discusses observed and anticipated risks, linking harms to causal mechanisms and offering mitigation strategies. Highlights organizational responsibility for risk evaluation. Provides a structured framework to anticipate and address LM risks at launch and deployment.",
"Weinberg, 2022","Weinberg, L. (2022). Rethinking Fairness: An Interdisciplinary Survey of Critiques of Hegemonic ML Fairness Approaches. J. Artif. Int. Res., 74. https://doi.org/10.1613/jair.1.13196",Rethinking Fairness: An Interdisciplinary Survey of Critiques of Hegemonic ML Fairness Approaches,Extractive,"Soliciting data without reciprocal benefits, Biased pre-processing and category erasure",Data practices,Problem Understanding & Formulation,Product Conception & Design,Era 3,AC,A: surveys interdisciplinary critiques of ML fairness approaches; D: identifies biases in data/problem formulation; C: shows marginalization via fairness framings,"White (published journal papers, conference proceedings, books)",Database search,"fairness, hegemonic ML, tech solutionism",Not regionally specific,Academic,North America,"Purdue University, USA",,"Synthesizes critiques of ML fairness interventions across philosophy, STS, law, feminist, and race studies. Identifies nine critique clusters, including problem framing, abstraction, racial classification, ethics washing, and exclusion from participation. Highlights how fairness methods entrench bias, predatory inclusion, and lack long-term accountability. Concludes with directions for fairness research that disrupt entrenched structural injustices and support more democratic and inclusive AI practices.",
"Welles, 2014","Welles, B. F. (2014). On minorities and outliers: The case for making Big Data small. Big Data & Society, 1(1), 205395171454061. https://doi.org/10.1177/2053951714540613 ",On minorities and outliers: The case for making Big Data small,Extractive,Collecting vast amounts of data to train AI systems,"Data practices, Community impacts and relations",ML System Design & Development,"Data Selection, Collection & Annotation",Era 2,DC,A: none; D: argues for methodological shifts in dataset design; C: foregrounds risks of marginalizing minority groups,"White (published journal papers, conference proceedings, books)",Citation/reference snowballing,big data; outlier; minority; sampling,Not regionally specific,Academic,North America,"Northeastern University, USA",,"Argues that Big Data practices erase minorities and outliers by prioritizing scale over nuance. Advocates purposeful “small data” sampling to capture marginalized experiences and reduce harm. Reframes dataset construction as a methodological choice with equity implications, informing AI training regimes that often inherit exclusionary biases from large, homogeneous corpora.",
"Wenzel & Kaufman, 2023","Wenzel, K., & Kaufman, G. (2023). Challenges in Designing Racially Inclusive Language Technologies (No. arXiv:2303.13546). arXiv. http://arxiv.org/abs/2303.13546",Challenges in Designing Racially Inclusive Language Technologies ,Extractive,Excluding underrepresented groups from decision-making,Community impacts and relations,ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,DC,A: none; D: examines challenges of data inclusivity and surveillance risks; C: highlights harms for marginalized users,"Grey (Reports, blogs, white papers, policy documents, theses, conference papers)",Database search,"inclusivity, marginalized groups, conversational agents",Not regionally specific,Academic,North America,"Carnegie Mellon University, USA",,"Analyzes risks of designing “inclusive” conversational technologies. Identifies three challenges: collecting representative data without harm, avoiding surveillance risks for vulnerable populations, and tackling racism beyond technical fixes. Warns that without structural change, inclusivity efforts may replicate racialized harms in voice assistants and related tools.",
"Whang et al., 2023","Whang, S. E., Roh, Y., Song, H., & Lee, J.-G. (2023). Data collection and quality challenges in deep learning: A data-centric AI perspective. The VLDB Journal, 32(4), 791–813. https://doi.org/10.1007/s00778-022-00775-9",Data collection and quality challenges in deep learning: A data-centric AI perspective,Extractive,Biased pre-processing and category erasure,Data practices,ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,AD,"A: surveys data-centric AI needs in DL; D: details collection, validation, cleaning, integration, and bias mitigation; C: none (indirect implications)","White (published journal papers, conference proceedings, books)",Database search,data-centric AI; data management; dataset quality,Not regionally specific,Mixed,APAC (Asia-Pacific Region),"KAIST, Daejeon, South Korea",,"Reviews data-centric AI for deep learning, emphasizing data as a first-class concern. Synthesizes techniques for collection, validation, cleaning, integration, and robustness to imperfect data. Discusses fairness metrics and mitigations across pipeline stages, linking data work quality to model performance and reliability in practice.",
"Whitman et al., 2018","Whitman, M., Hsiang, C., & Roark, K. (2018). Potential for participatory big data ethics and algorithm design: A scoping mapping review. Proceedings of the 15th Participatory Design Conference: Short Papers, Situated Actions, Workshops and Tutorial - Volume 2, 1–6. https://doi.org/10.1145/3210604.3210644",Potential for participatory big data ethics and algorithm design: A scoping mapping review,Principles less-extractive,Other/NA (conceptual framing),"Critical theory/Historical background, Data practices",Problem Understanding & Formulation,Institutional Prioritization & Funding,Multi-era,ADC,A: surveys participatory approaches to algorithm design; D: maps governance and data ethics practices; C: foregrounds democratic control and affected publics,"White (published journal papers, conference proceedings, books)",Database search,"participatory design, algorithm governance, democratic control",Not regionally specific,Academic,North America,"Purdue University, USA",,"Scoping review of participatory approaches to big data and algorithm design/governance. Synthesizes methods where publics shape objectives, data collection, and oversight, and catalogs sites of decision-making. Argues participatory structures can counter opaque, expert-led processes and improve accountability across data lifecycles. Provides a foundation for integrating community voice into AI pipeline design and evaluation.",
"Whitney & Norman, 2024","Whitney, C. D., & Norman, J. (2024). Real Risks of Fake Data: Synthetic Data, Diversity-Washing and Consent Circumvention. The 2024 ACM Conference on Fairness, Accountability, and Transparency, 1733–1744. https://doi.org/10.1145/3630106.3659002 ","Real Risks of Fake Data: Synthetic Data, Diversity-Washing and Consent Circumvention",Extractive,Reproducing biases through synthetic data generation,"Data practices, Community impacts and relations",ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,ADC,A: examines facial recognition evaluation using synthetic datasets; D: analyzes synthetic data generation and usage practices; C: identifies false confidence in diversity representation and consent circumvention affecting impacted communities,"White (published journal papers, conference proceedings, books)",Database search,"synthetic data, diversity washing, consent",Not regionally specific,Academic,North America,"University of California, Berkeley Berkeley, California, USA",,Identifies key risks in synthetic data usage including false confidence when increasing dataset diversity and consent circumvention. Examines facial recognition evaluation case study showing synthetic datasets create illusion of representation. Argues synthetic data consolidates power away from those most impacted by algorithmic harm.,
"Widder et al., 2024","Widder, D. G., Whittaker, M., & West, S. M. (2024). Why ‘open’ AI systems are actually closed, and why this matters. Nature, 635(8040), 827–833. https://doi.org/10.1038/s41586-024-08141-1","Why ‘open’ AI systems are actually closed, and why this matters",Extractive,Keeping communities in the dark through opaque data practices,Data practices,Cross-pipeline,Cross-pipeline,Era 3,AD,"A: analyzes components of AI systems and industry concentration; D: examines what openness means across models, data, labor, and computational power; C: none (indirect implications)","White (published journal papers, conference proceedings, books)",Citation/reference snowballing,"open AI, corporate concentration, transparency, EU AI Act",Not regionally specific,Mixed,North America,"Cornell University, USA","Signal Foundation, Mountain View, CA, USA; AI Now Institute, New York City, NY, USA","Critically examines the notion of ""open AI,"" arguing that it's often imprecisely defined and masks significant industry concentration. It analyzes the components of AI systems, such as models, data, labor, frameworks, and computational power, to determine what ""openness"" can realistically offer in AI. The authors find that while ""open"" AI can provide transparency, reusability, and extensibility, it doesn't necessarily challenge the dominance of major corporate actors. Ultimately, the paper contends that focusing solely on ""openness"" distracts from critical questions about power dynamics, policy implications, and the need for alternatives that prioritize public needs over commercial interests.",
"Widder, 2023","Widder, D. G., West, S., & Whittaker, M. (2023). Open (For Business): Big Tech, Concentrated Power, and the Political Economy of Open AI (SSRN Scholarly Paper No. 4543807). https://doi.org/10.2139/ssrn.4543807","Open (For Business): Big Tech, Concentrated Power, and the Political Economy of Open AI",Extractive,Keeping communities in the dark through opaque data practices,Data practices,Cross-pipeline,Cross-pipeline,Multi-era,ADC,"A: interrogates “open” AI claims and access asymmetries; D: analyzes how compute, data, and governance concentrate in firms; C: assesses societal impacts of enclosure and limited accountability","White (published journal papers, conference proceedings, books)",Citation/reference snowballing,open AI; political economy; regulation,Not regionally specific,Mixed,North America,"Carnegie Mellon University, USA","AI Now Institute; Signal Foundation, USA","Problematizes the concept of “open” AI, arguing that the term is often used in misleading ways. While some “open” AI systems offer valuable transparency and reusability, the resources required to build and deploy large AI models remain concentrated in the hands of powerful tech companies. Traces the history of open source software, highlighting how corporations have captured and profited from it. Argues that “open” AI, far from democratizing AI development, risks reinforcing existing power structures and enabling exploitation. Calls for a nuanced understanding of “open” AI, recognizing both its potential benefits and its limitations in challenging corporate dominance in the AI industry.",
"Widder, 2024","Widder, D. G. (2024). Epistemic Power in AI Ethics Labor: Legitimizing Located Complaints. The 2024 ACM Conference on Fairness, Accountability, and Transparency, 1295–1304. https://doi.org/10.1145/3630106.3658973",Epistemic Power in AI Ethics Labor: Legitimizing Located Complaints,Principles less-extractive,Decentering Western ontologies,Data practices,ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,AC,A: critiques dominant tools that privilege quantification; D: none; C: elevates located complaints and embodied knowledge in ethics labor,"White (published journal papers, conference proceedings, books)",Hand-searching key journals,AI ethics; epistemic power; lived experience,Not regionally specific,Academic,North America,"Digitial life initative & Cornell Tech, USA",,Shows how AI ethics practices that equate objectivity with quantification marginalize situated complaints from affected communities. Draws on feminist and critical race theory to argue for humble technical practices that acknowledge limits and value lived experience. Links documentation choices and evaluation norms to whose knowledge counts in AI data workflows.,
"Wiehn, 2024","Wiehn, T. (2024). Synthetic Data: From Data Scarcity to Data Pollution. Surveillance & Society, 22(4). https://doi.org/10.24908/ss.v22i4.18327 
",Synthetic Data: From Data Scarcity to Data Pollution,Extractive,Reproducing biases through synthetic data generation,"Data practices, Community impacts and relations",ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,DC,A: none; D: examines synthetic data generation and datafication logics; C: analyzes impacts of data pollution and contamination on broader society,"White (published journal papers, conference proceedings, books)",Database search,"synthetic data, datafication, data pollution",Not regionally specific,Academic,EU/UK,"Roskilde University, Denmark",,Examines synthetic data's role in perpetuating datafication logics while promising solutions to data scarcity. Argues synthetic data de-politicizes critique of AI-driven technologies through notions of efficiency and precision. Calls for critical understanding of synthetic data as living information requiring analysis of generation conditions.,
"Wilcox et al., 2023","Wilcox, L., Brewer, R., & Diaz, F. (2023). AI Consent Futures: A Case Study on Voice Data Collection with Clinicians. Proc. ACM Hum.-Comput. Interact., 7(CSCW2), 316:1-316:30. https://doi.org/10.1145/3610107",AI Consent Futures: A Case Study on Voice Data Collection with Clinicians,Practices less-extractive,"Community engaged data production, Establishing consent and contextually appropriate compensation",Data practices,ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,ADC,A: probes AI documentation assistants; D: elicits consent expectations and risk perceptions; C: surfaces clinician-identified harms and design needs,"White (published journal papers, conference proceedings, books)",Database search,North America; clinical voice data; consent; risk,North America,Industry,North America,"Google Research, USA",,"Uses design-fiction informed interviews with physicians to explore voice-capture for AI assistants. Identifies eight risk classes (e.g., workflow disruption, self-censorship, eligibility errors). Reconsiders evaluation criteria and consent processes to align data collection with clinicians’ needs and patient safety.",
"Williams et al., 2022","Williams, A., Miceli, M., & Gebru, T. (2022). The Exploited Labor Behind Artificial Intelligence. https://www.noemamag.com/the-exploited-labor-behind-artificial-intelligence 
",The Exploited Labor Behind Artificial Intelligence,Extractive,Exploitative and invisible data labor,Data practices,ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,ADC,A: situates invisible annotation labor in AI production; D: describes exploitative global outsourcing models; C: emphasizes worker precarity and need for organizing,"Grey (Reports, blogs, white papers, policy documents, theses, conference papers)",Citation/reference snowballing,"Global South, data annotation, invisible labor, worker precarity",Multiple areas,Journalist/Other/Not Sure,North America,"Noema, published by the Berggruen
Institute, USA",,"Reports how contemporary AI depends on low-paid, globally outsourced data work—labeling, moderation, and transcription—performed under opaque contracts and weak protections. Describes wage suppression, psychological toll, and asymmetries between platform clients and dispersed workers. Calls for procurement standards, living wages, and transnational organizing as prerequisites for “ethical AI.” Links invisible data labor to model quality and public trust, showing how current pipelines externalize risk and concentrate value away from contributing communities.",
"Wu, 2024","Wu, Y.-H. (2024). Capturing the unobservable in AI development: Proposal to account for AI developer practices with ethnographic audit trails (EATs). AI and Ethics. https://doi.org/10.1007/s43681-024-00535-1
",Capturing the unobservable in AI development: Proposal to account for AI developer practices with ethnographic audit trails (EATs),Principles less-extractive,Building public visibility in dataset development,"Data practices, Ethics frameworks",Cross-pipeline,Cross-pipeline,Era 3,AD,A: accountability across AI dev lifecycle; D: embedded “audit trails” for day-to-day data/model decisions; C: none,"White (published journal papers, conference proceedings, books)","Existing networks, relevant organizations and conferences",Audit trail; developer practice; accountability,Not regionally specific,Academic,EU/UK,"Graduate Institute of International and Development Studies, Geneva, Switzerland",,"Audits focused on post-hoc compliance miss everyday decisions shaping data and models. Drawing on an AI lab case, the paper shows how developer values and interactions drive design choices. It proposes ethnographic audit trails (EATs)—embedded, contemporaneous documentation of daily work—to surface sociotechnical dynamics in data production and strengthen accountability across the AI lifecycle.",
"Yang et al., 2018","Yang, K., Stoyanovich, J., Asudeh, A., Howe, B., Jagadish, H. V., & Miklau, G. (2018). A Nutritional Label for Rankings. Proceedings of the 2018 International Conference on Management of Data, 1773–1776. https://doi.org/10.1145/3183713.3193568 
",A Nutritional Label for Rankings,Practices less-extractive,Building public visibility in dataset development,Data practices,ML System Design & Development,Model Training & Evaluation,Multi-era,AD,A: creates web tool to communicate ranking methodology; D: introduces “nutritional labels” for transparency and fairness; C: none,"White (published journal papers, conference proceedings, books)",Database search,"USA, ranking algorithms, transparency, fairness",Not regionally specific,Academic,North America,"Drexel University, USA","Drexel University; University of Michigan; University of Washington; University of Massachusetts Amherst, USA","Demonstrates Ranking Facts, a web application that generates “nutritional labels” for rankings. Visual widgets communicate methodology, stability, fairness, and output details across domains (education, risk assessment, finance). Links transparency tooling to clearer accountability for data choices underlying ranked outcomes. Focuses on model explanation rather than community co-governance, improving visibility into data/parameter effects.",
"Young et al., 2024","Young, M., Ehsan, U., Singh, R., Tafesse, E., Gilman, M., Harrington, C., & Metcalf, J. (2024). Participation versus scale: Tensions in the practical demands on participatory AI. First Monday. https://doi.org/10.5210/fm.v29i4.13642",Participation versus scale: Tensions in the practical demands on participatory AI,Principles less-extractive,Early co-design and participatory initiatives,Community impacts and relations,Problem Understanding & Formulation,Institutional Prioritization & Funding,Era 3,ADC,A: situates participatory AI within commercial scaling; D: analyzes infrastructural demands for participatory methods; C: highlights affected communities’ constrained but necessary roles.,"White (published journal papers, conference proceedings, books)","Existing networks, relevant organizations and conferences",global; participatory AI; infrastructure; public input,Not regionally specific,Mixed,North America,"Data & Society Research Institute, USA","Georgia Institute of Technology, USA; University of Baltimore School of Law, USA; Carnegie Mellon University, USA","Investigates tensions between participatory methods and global AI scale. Reviews legal, civic, and technical approaches. Identifies fault lines between centralized/distributed development, calculable/self-identified publics, and instrumental/intrinsic valuations of input. Argues tensions are contingent and infrastructural investments can scale participation alongside AI. Frames scaling participation as essential to power-shifting involvement.",
"Young, 2020","Young, R. J. C. (2020). Postcolonialism: A Very Short Introduction (2nd ed.). Oxford University Press. https://doi.org/10.1093/actrade/9780198856832.001.0001",Postcolonialism: A Very Short Introduction,Principles less-extractive,Other/NA (conceptual framing),Critical theory/Historical background,Cross-pipeline,Cross-pipeline,Multi-era,C,"A: none; D: none; C: synthesizes postcolonial perspectives on power, colonial histories, and subaltern knowledge relevant to data and research","White (published journal papers, conference proceedings, books)",Iterative keyword search,"global, colonialism, subaltern perspective",Not regionally specific,Academic,North America,"New York University, USA",,"Concise yet comprehensive overview of themes like subaltern perspectives, the process of decolonization, and the enduring effects of slavery and racial hierarchies. Examines how history and power dynamics shape our understanding of colonialism in a range of contexts including national identity, cultural hybridity, and the role of gender in postcolonial societies. ",
"Zhang et al., 2022","Zhang, S., Frey, B., & Bansal, M. (2022). How can NLP Help Revitalize Endangered Languages? A Case Study and Roadmap for the Cherokee Language. Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), 1529–1541. https://doi.org/10.18653/v1/2022.acl-long.108",How can NLP Help Revitalize Endangered Languages? A Case Study and Roadmap for the Cherokee Language,Practices less-extractive,"Community engaged data production, Early co-design and participatory initiatives, Participatory data ownership & governance",Community impacts and relations,ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,ADC,A: proposes NLP tools for an endangered language; D: outlines community-based corpus building and tooling; C: foregrounds Cherokee priorities and collaboration,"White (published journal papers, conference proceedings, books)",Hand-searching key journals,North America; Cherokee NLP; community roadmap; revitalization,North America,Academic,North America,"UNC Chapel Hill, USA",Authors note cross-community collaboration; Frey is a Cherokee Nation citizen and second-language speaker; community interlocutors acknowledged,"Presents a community-aligned roadmap for Cherokee: corpus enrichment, MT, OCR, ASR/TTS, tokenization, morphology, POS, parsing. Emphasizes decolonizing methodology, respect for speaker community goals, and collaborative data collection to build sustainable resources and tools for revitalization.",
"Zhao et al., 2024","Zhao, D., Scheuerman, M. K., Chitre, P., Andrews, J. T. A., Panagiotidou, G., Walker, S., Pine, K. H., & Xiang, A. (2024). A Taxonomy of Challenges to Curating Fair Datasets (No. arXiv:2406.06407; Version 1). arXiv. http://arxiv.org/abs/2406.06407",A Taxonomy of Challenges to Curating Fair Datasets,Extractive,Biased pre-processing and category erasure,Data practices,ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,AD,A: studies fairness in dataset curation; D: identifies lifecycle and organizational barriers via 30 curator interviews; C: none (indirect implications),"White (published journal papers, conference proceedings, books)",Citation/reference snowballing,"dataset curation; fairness challenge; curator interview,",Not regionally specific,Mixed,North America,"Stanford University, CA, USA","Sony AI; Arizona State University, USA; King’s College London, UK","Interviews 30 dataset curators to map challenges across requirements, design, implementation, evaluation, and maintenance, as well as individual-to-socio-political contexts. Argues fairness depends on process, not only final composition. Offers systemic recommendations to support fair dataset curation in practice.",
"Ziems et al., 2022","Ziems, C., Chen, J., Harris, C., Anderson, J., & Yang, D. (2022). VALUE: Understanding Dialect Disparity in NLU. In S. Muresan, P. Nakov, & A. Villavicencio (Eds.), Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) (pp. 3701–3720). Association for Computational Linguistics. https://doi.org/10.18653/v1/2022.acl-long.258",VALUE: Understanding Dialect Disparity in NLU,Practices less-extractive,Creating culturally inclusive datasets,"Community impacts and relations, Data practices",ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,ADC,A: evaluates model disparities; D: develops VALUE benchmark from AAVE rules; C: centers community dialect knowledge in participatory validation,"White (published journal papers, conference proceedings, books)",Citation/reference snowballing,"USA, dialect disparity, AAVE, NLU, benchmark",North America,Academic,North America,"
Georgia Institute of Technology, USA",,"Introduces VALUE, a benchmark to evaluate NLU across dialects, focusing on African American Vernacular English (AAVE). Applies 11 transformation rules validated by fluent speakers via participatory design. Shows performance drops in state-of-the-art models, exposing inequities when benchmarks only test Standard American English. Demonstrates that inclusive dataset design can identify disparities and encourage more dialect-competent NLU systems.",
"Zong & Matias, 2024","Zong, J., & Matias, J. N. (2024). Data Refusal from Below: A Framework for Understanding, Evaluating, and Envisioning Refusal as Design. ACM Journal on Responsible Computing, 1(1), 1–23. https://doi.org/10.1145/3630107","Data Refusal from Below: A Framework for Understanding, Evaluating, and Envisioning Refusal as Design",Principles less-extractive,Taking a needs-based approach to developing AI,Community impacts and relations,ML System Design & Development,"Data Selection, Collection & Annotation",Era 3,DC,A: theorizes refusal as design concept relevant to AI data; D: develops dimensions of autonomy/time/power/cost; C: foregrounds agency of individuals/communities,"White (published journal papers, conference proceedings, books)",Hand-searching key journals,data refusal; autonomy; participatory design,Not regionally specific,Academic,North America,"Massachusetts Institute of Technology, USA",,"Presents a framework for understanding how and why people refuse to participate in data collection. The authors argue that refusal is a form of design, in which individuals and communities assert their agency to reshape the impact of data systems on their lives. The framework centers on four key dimensions of refusal: autonomy, which considers individual and collective interests; time, meaning whether the refusal is reactive or proactive; power, or the extent to which refusal can create systemic change; and cost, acknowledging the potential burdens placed upon those who refuse. Through analyzing cases of data refusal, the authors illustrate how these facets can help describe, evaluate, and inspire new forms of resistance against data systems that perpetuate harm.",
"Zytko et al., 2022","Zytko, D., J. Wisniewski, P., Guha, S., P. S. Baumer, E., & Lee, M. K. (2022). Participatory Design of AI Systems: Opportunities and Challenges Across Diverse Users, Relationships, and Application Domains. CHI Conference on Human Factors in Computing Systems Extended Abstracts, 1–4. https://doi.org/10.1145/3491101.3516506","Participatory Design of AI Systems: Opportunities and Challenges Across Diverse Users, Relationships, and Application Domains",Principles less-extractive,Early co-design and participatory initiatives,Community impacts and relations,Cross-pipeline,Cross-pipeline,Era 3,ADC,A: discusses PD’s potential in AI system development; D: examines co-design methods across technical domains; C: stresses inclusion of diverse and vulnerable groups.,"Grey (Reports, blogs, white papers, policy documents, theses, conference papers)",Database search,global; participatory design; AI system; vulnerable group,Not regionally specific,Academic,North America,"Oakland University, USA",,"Position paper on participatory design (PD) in AI. Emphasizes diverse stakeholder involvement to mitigate harms and support positive change. Raises design questions: what system aspects suit PD, how to facilitate collaboration, and how to evaluate ethical use of co-design outcomes. Identifies challenges but argues PD can democratize AI development for vulnerable groups.",
